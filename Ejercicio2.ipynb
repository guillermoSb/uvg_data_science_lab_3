{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diesel_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-76576.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86033.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-137814.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114863.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-54753.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diesel_diff\n",
       "0    -76576.19\n",
       "1     86033.88\n",
       "2   -137814.26\n",
       "3    114863.71\n",
       "4    -54753.87"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diesel = pd.read_csv('data/data_diesel_diff.csv', sep=',')\n",
    "data_diesel = data_diesel.drop(['anio', 'mes'], axis=1)\n",
    "data_diesel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_diesel_scaled = scaler.fit_transform(data_diesel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "# calculando los indices de particionamiento\n",
    "entrenamiento = round(0.6 * len(data_diesel_scaled))\n",
    "val_prueba = round(0.2 * len(data_diesel_scaled))\n",
    "\n",
    "# Particionando los datos\n",
    "train = data_diesel_scaled[:entrenamiento]\n",
    "validation = data_diesel_scaled[entrenamiento:entrenamiento+val_prueba]\n",
    "test = data_diesel_scaled[entrenamiento+val_prueba:]\n",
    "\n",
    "train = np.insert(train, 0, 0)\n",
    "train = train.reshape(-1, 1)\n",
    "\n",
    "print(len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisada(serie,retrasos = 1):\n",
    "    serie_x = []\n",
    "    serie_y = []\n",
    "    for i in range(len(serie)-retrasos):\n",
    "        valor = serie[i:(i+retrasos),0]\n",
    "        valor_sig = serie[i+retrasos,0]\n",
    "        serie_x.append(valor)\n",
    "        serie_y.append(valor_sig)\n",
    "    return np.array(serie_x), np.array(serie_y)\n",
    "\n",
    "x_train,y_train = supervisada(train)\n",
    "x_val,y_val = supervisada(validation)\n",
    "x_test,y_test = supervisada(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.reshape(x_train,(x_train.shape[0],1,1))\n",
    "x_val = np.reshape(x_val, (x_val.shape[0],1,1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],1,1))\n",
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (1, 1)                    12        \n",
      "                                                                 \n",
      " dense (Dense)               (1, 1)                    2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo1 = Sequential()\n",
    "lote = 1\n",
    "paso = 1\n",
    "caracteristicas = 1\n",
    "modelo1.add(LSTM(lote, batch_input_shape=(lote, paso, caracteristicas), stateful=True))\n",
    "modelo1.add(Dense(1))\n",
    "modelo1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo1.compile(loss='mean_squared_error',optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "161/161 [==============================] - 0s 883us/step - loss: 0.5762 - val_loss: 0.7940\n",
      "Epoch 2/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5699 - val_loss: 0.7929\n",
      "Epoch 3/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5700 - val_loss: 0.7926\n",
      "Epoch 4/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.5699 - val_loss: 0.7925\n",
      "Epoch 5/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5698 - val_loss: 0.7923\n",
      "Epoch 6/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.5697 - val_loss: 0.7922\n",
      "Epoch 7/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5697 - val_loss: 0.7921\n",
      "Epoch 8/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5696 - val_loss: 0.7920\n",
      "Epoch 9/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5695 - val_loss: 0.7918\n",
      "Epoch 10/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5694 - val_loss: 0.7917\n",
      "Epoch 11/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.5693 - val_loss: 0.7916\n",
      "Epoch 12/1000\n",
      "161/161 [==============================] - 0s 787us/step - loss: 0.5692 - val_loss: 0.7915\n",
      "Epoch 13/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.5691 - val_loss: 0.7914\n",
      "Epoch 14/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5691 - val_loss: 0.7912\n",
      "Epoch 15/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5690 - val_loss: 0.7911\n",
      "Epoch 16/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5689 - val_loss: 0.7910\n",
      "Epoch 17/1000\n",
      "161/161 [==============================] - 0s 808us/step - loss: 0.5688 - val_loss: 0.7909\n",
      "Epoch 18/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5687 - val_loss: 0.7908\n",
      "Epoch 19/1000\n",
      "161/161 [==============================] - 0s 787us/step - loss: 0.5686 - val_loss: 0.7907\n",
      "Epoch 20/1000\n",
      "161/161 [==============================] - 0s 905us/step - loss: 0.5685 - val_loss: 0.7906\n",
      "Epoch 21/1000\n",
      "161/161 [==============================] - 0s 871us/step - loss: 0.5684 - val_loss: 0.7904\n",
      "Epoch 22/1000\n",
      "161/161 [==============================] - 0s 947us/step - loss: 0.5683 - val_loss: 0.7903\n",
      "Epoch 23/1000\n",
      "161/161 [==============================] - 0s 866us/step - loss: 0.5682 - val_loss: 0.7902\n",
      "Epoch 24/1000\n",
      "161/161 [==============================] - 0s 796us/step - loss: 0.5681 - val_loss: 0.7901\n",
      "Epoch 25/1000\n",
      "161/161 [==============================] - 0s 818us/step - loss: 0.5680 - val_loss: 0.7900\n",
      "Epoch 26/1000\n",
      "161/161 [==============================] - 0s 833us/step - loss: 0.5679 - val_loss: 0.7899\n",
      "Epoch 27/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5678 - val_loss: 0.7898\n",
      "Epoch 28/1000\n",
      "161/161 [==============================] - 0s 781us/step - loss: 0.5677 - val_loss: 0.7896\n",
      "Epoch 29/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5676 - val_loss: 0.7895\n",
      "Epoch 30/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5675 - val_loss: 0.7894\n",
      "Epoch 31/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5674 - val_loss: 0.7893\n",
      "Epoch 32/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5673 - val_loss: 0.7892\n",
      "Epoch 33/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5672 - val_loss: 0.7891\n",
      "Epoch 34/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5671 - val_loss: 0.7889\n",
      "Epoch 35/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5670 - val_loss: 0.7888\n",
      "Epoch 36/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5669 - val_loss: 0.7887\n",
      "Epoch 37/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5669 - val_loss: 0.7886\n",
      "Epoch 38/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5668 - val_loss: 0.7885\n",
      "Epoch 39/1000\n",
      "161/161 [==============================] - 0s 827us/step - loss: 0.5667 - val_loss: 0.7883\n",
      "Epoch 40/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5666 - val_loss: 0.7882\n",
      "Epoch 41/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5665 - val_loss: 0.7881\n",
      "Epoch 42/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5664 - val_loss: 0.7880\n",
      "Epoch 43/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5663 - val_loss: 0.7879\n",
      "Epoch 44/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5662 - val_loss: 0.7878\n",
      "Epoch 45/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5661 - val_loss: 0.7876\n",
      "Epoch 46/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5660 - val_loss: 0.7875\n",
      "Epoch 47/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5659 - val_loss: 0.7874\n",
      "Epoch 48/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5658 - val_loss: 0.7873\n",
      "Epoch 49/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5657 - val_loss: 0.7872\n",
      "Epoch 50/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5656 - val_loss: 0.7870\n",
      "Epoch 51/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5655 - val_loss: 0.7869\n",
      "Epoch 52/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.5654 - val_loss: 0.7868\n",
      "Epoch 53/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5653 - val_loss: 0.7867\n",
      "Epoch 54/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5652 - val_loss: 0.7866\n",
      "Epoch 55/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5651 - val_loss: 0.7864\n",
      "Epoch 56/1000\n",
      "161/161 [==============================] - 0s 829us/step - loss: 0.5650 - val_loss: 0.7863\n",
      "Epoch 57/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5649 - val_loss: 0.7862\n",
      "Epoch 58/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5648 - val_loss: 0.7861\n",
      "Epoch 59/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5647 - val_loss: 0.7860\n",
      "Epoch 60/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5646 - val_loss: 0.7859\n",
      "Epoch 61/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5645 - val_loss: 0.7857\n",
      "Epoch 62/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5644 - val_loss: 0.7856\n",
      "Epoch 63/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5643 - val_loss: 0.7855\n",
      "Epoch 64/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5642 - val_loss: 0.7854\n",
      "Epoch 65/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5641 - val_loss: 0.7853\n",
      "Epoch 66/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5640 - val_loss: 0.7851\n",
      "Epoch 67/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5639 - val_loss: 0.7850\n",
      "Epoch 68/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5638 - val_loss: 0.7849\n",
      "Epoch 69/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5637 - val_loss: 0.7848\n",
      "Epoch 70/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5636 - val_loss: 0.7847\n",
      "Epoch 71/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5635 - val_loss: 0.7845\n",
      "Epoch 72/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5634 - val_loss: 0.7844\n",
      "Epoch 73/1000\n",
      "161/161 [==============================] - 0s 831us/step - loss: 0.5633 - val_loss: 0.7843\n",
      "Epoch 74/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5632 - val_loss: 0.7842\n",
      "Epoch 75/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5631 - val_loss: 0.7841\n",
      "Epoch 76/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5630 - val_loss: 0.7839\n",
      "Epoch 77/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5629 - val_loss: 0.7838\n",
      "Epoch 78/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5628 - val_loss: 0.7837\n",
      "Epoch 79/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5627 - val_loss: 0.7836\n",
      "Epoch 80/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5626 - val_loss: 0.7835\n",
      "Epoch 81/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5625 - val_loss: 0.7833\n",
      "Epoch 82/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5624 - val_loss: 0.7832\n",
      "Epoch 83/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5623 - val_loss: 0.7831\n",
      "Epoch 84/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5623 - val_loss: 0.7830\n",
      "Epoch 85/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5622 - val_loss: 0.7828\n",
      "Epoch 86/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5621 - val_loss: 0.7827\n",
      "Epoch 87/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5620 - val_loss: 0.7826\n",
      "Epoch 88/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5619 - val_loss: 0.7825\n",
      "Epoch 89/1000\n",
      "161/161 [==============================] - 0s 810us/step - loss: 0.5618 - val_loss: 0.7824\n",
      "Epoch 90/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5617 - val_loss: 0.7822\n",
      "Epoch 91/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5616 - val_loss: 0.7821\n",
      "Epoch 92/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5615 - val_loss: 0.7820\n",
      "Epoch 93/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5614 - val_loss: 0.7819\n",
      "Epoch 94/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5613 - val_loss: 0.7818\n",
      "Epoch 95/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5612 - val_loss: 0.7816\n",
      "Epoch 96/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5611 - val_loss: 0.7815\n",
      "Epoch 97/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5610 - val_loss: 0.7814\n",
      "Epoch 98/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5609 - val_loss: 0.7813\n",
      "Epoch 99/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5608 - val_loss: 0.7812\n",
      "Epoch 100/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5607 - val_loss: 0.7810\n",
      "Epoch 101/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5606 - val_loss: 0.7809\n",
      "Epoch 102/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5606 - val_loss: 0.7808\n",
      "Epoch 103/1000\n",
      "161/161 [==============================] - 0s 742us/step - loss: 0.5605 - val_loss: 0.7807\n",
      "Epoch 104/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5604 - val_loss: 0.7806\n",
      "Epoch 105/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.5603 - val_loss: 0.7804\n",
      "Epoch 106/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5602 - val_loss: 0.7803\n",
      "Epoch 107/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5601 - val_loss: 0.7802\n",
      "Epoch 108/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5600 - val_loss: 0.7801\n",
      "Epoch 109/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5599 - val_loss: 0.7799\n",
      "Epoch 110/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5598 - val_loss: 0.7798\n",
      "Epoch 111/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5597 - val_loss: 0.7797\n",
      "Epoch 112/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5596 - val_loss: 0.7796\n",
      "Epoch 113/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5595 - val_loss: 0.7795\n",
      "Epoch 114/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5594 - val_loss: 0.7793\n",
      "Epoch 115/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5594 - val_loss: 0.7792\n",
      "Epoch 116/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5593 - val_loss: 0.7791\n",
      "Epoch 117/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5592 - val_loss: 0.7790\n",
      "Epoch 118/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5591 - val_loss: 0.7789\n",
      "Epoch 119/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5590 - val_loss: 0.7787\n",
      "Epoch 120/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5589 - val_loss: 0.7786\n",
      "Epoch 121/1000\n",
      "161/161 [==============================] - 0s 806us/step - loss: 0.5588 - val_loss: 0.7785\n",
      "Epoch 122/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5587 - val_loss: 0.7784\n",
      "Epoch 123/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5586 - val_loss: 0.7782\n",
      "Epoch 124/1000\n",
      "161/161 [==============================] - 0s 740us/step - loss: 0.5585 - val_loss: 0.7781\n",
      "Epoch 125/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5585 - val_loss: 0.7780\n",
      "Epoch 126/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.5584 - val_loss: 0.7779\n",
      "Epoch 127/1000\n",
      "161/161 [==============================] - 0s 736us/step - loss: 0.5583 - val_loss: 0.7778\n",
      "Epoch 128/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5582 - val_loss: 0.7776\n",
      "Epoch 129/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5581 - val_loss: 0.7775\n",
      "Epoch 130/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5580 - val_loss: 0.7774\n",
      "Epoch 131/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5579 - val_loss: 0.7773\n",
      "Epoch 132/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5578 - val_loss: 0.7772\n",
      "Epoch 133/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5577 - val_loss: 0.7770\n",
      "Epoch 134/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5577 - val_loss: 0.7769\n",
      "Epoch 135/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5576 - val_loss: 0.7768\n",
      "Epoch 136/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5575 - val_loss: 0.7767\n",
      "Epoch 137/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.5574 - val_loss: 0.7765\n",
      "Epoch 138/1000\n",
      "161/161 [==============================] - 0s 807us/step - loss: 0.5573 - val_loss: 0.7764\n",
      "Epoch 139/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5572 - val_loss: 0.7763\n",
      "Epoch 140/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5571 - val_loss: 0.7762\n",
      "Epoch 141/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5570 - val_loss: 0.7761\n",
      "Epoch 142/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5570 - val_loss: 0.7759\n",
      "Epoch 143/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5569 - val_loss: 0.7758\n",
      "Epoch 144/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5568 - val_loss: 0.7757\n",
      "Epoch 145/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5567 - val_loss: 0.7756\n",
      "Epoch 146/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5566 - val_loss: 0.7755\n",
      "Epoch 147/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5565 - val_loss: 0.7753\n",
      "Epoch 148/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.5565 - val_loss: 0.7752\n",
      "Epoch 149/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5564 - val_loss: 0.7751\n",
      "Epoch 150/1000\n",
      "161/161 [==============================] - 0s 932us/step - loss: 0.5563 - val_loss: 0.7750\n",
      "Epoch 151/1000\n",
      "161/161 [==============================] - 0s 822us/step - loss: 0.5562 - val_loss: 0.7748\n",
      "Epoch 152/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5561 - val_loss: 0.7747\n",
      "Epoch 153/1000\n",
      "161/161 [==============================] - 0s 815us/step - loss: 0.5560 - val_loss: 0.7746\n",
      "Epoch 154/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5559 - val_loss: 0.7745\n",
      "Epoch 155/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5559 - val_loss: 0.7744\n",
      "Epoch 156/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5558 - val_loss: 0.7742\n",
      "Epoch 157/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5557 - val_loss: 0.7741\n",
      "Epoch 158/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5556 - val_loss: 0.7740\n",
      "Epoch 159/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5555 - val_loss: 0.7739\n",
      "Epoch 160/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5555 - val_loss: 0.7738\n",
      "Epoch 161/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5554 - val_loss: 0.7736\n",
      "Epoch 162/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5553 - val_loss: 0.7735\n",
      "Epoch 163/1000\n",
      "161/161 [==============================] - 0s 743us/step - loss: 0.5552 - val_loss: 0.7734\n",
      "Epoch 164/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5551 - val_loss: 0.7733\n",
      "Epoch 165/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5550 - val_loss: 0.7731\n",
      "Epoch 166/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5550 - val_loss: 0.7730\n",
      "Epoch 167/1000\n",
      "161/161 [==============================] - 0s 802us/step - loss: 0.5549 - val_loss: 0.7729\n",
      "Epoch 168/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5548 - val_loss: 0.7728\n",
      "Epoch 169/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5547 - val_loss: 0.7727\n",
      "Epoch 170/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5546 - val_loss: 0.7725\n",
      "Epoch 171/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5546 - val_loss: 0.7724\n",
      "Epoch 172/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5545 - val_loss: 0.7723\n",
      "Epoch 173/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5544 - val_loss: 0.7722\n",
      "Epoch 174/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5543 - val_loss: 0.7721\n",
      "Epoch 175/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5543 - val_loss: 0.7719\n",
      "Epoch 176/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5542 - val_loss: 0.7718\n",
      "Epoch 177/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5541 - val_loss: 0.7717\n",
      "Epoch 178/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5540 - val_loss: 0.7716\n",
      "Epoch 179/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5539 - val_loss: 0.7715\n",
      "Epoch 180/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5539 - val_loss: 0.7713\n",
      "Epoch 181/1000\n",
      "161/161 [==============================] - 0s 825us/step - loss: 0.5538 - val_loss: 0.7712\n",
      "Epoch 182/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5537 - val_loss: 0.7711\n",
      "Epoch 183/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5536 - val_loss: 0.7710\n",
      "Epoch 184/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5536 - val_loss: 0.7709\n",
      "Epoch 185/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5535 - val_loss: 0.7707\n",
      "Epoch 186/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5534 - val_loss: 0.7706\n",
      "Epoch 187/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5533 - val_loss: 0.7705\n",
      "Epoch 188/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5533 - val_loss: 0.7704\n",
      "Epoch 189/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5532 - val_loss: 0.7703\n",
      "Epoch 190/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5531 - val_loss: 0.7701\n",
      "Epoch 191/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5530 - val_loss: 0.7700\n",
      "Epoch 192/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5530 - val_loss: 0.7699\n",
      "Epoch 193/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5529 - val_loss: 0.7698\n",
      "Epoch 194/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5528 - val_loss: 0.7697\n",
      "Epoch 195/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.5527 - val_loss: 0.7695\n",
      "Epoch 196/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5527 - val_loss: 0.7694\n",
      "Epoch 197/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5526 - val_loss: 0.7693\n",
      "Epoch 198/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5525 - val_loss: 0.7692\n",
      "Epoch 199/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5524 - val_loss: 0.7691\n",
      "Epoch 200/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5524 - val_loss: 0.7689\n",
      "Epoch 201/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5523 - val_loss: 0.7688\n",
      "Epoch 202/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5522 - val_loss: 0.7687\n",
      "Epoch 203/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5522 - val_loss: 0.7686\n",
      "Epoch 204/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5521 - val_loss: 0.7685\n",
      "Epoch 205/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5520 - val_loss: 0.7683\n",
      "Epoch 206/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5519 - val_loss: 0.7682\n",
      "Epoch 207/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5519 - val_loss: 0.7681\n",
      "Epoch 208/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5518 - val_loss: 0.7680\n",
      "Epoch 209/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5517 - val_loss: 0.7679\n",
      "Epoch 210/1000\n",
      "161/161 [==============================] - 0s 810us/step - loss: 0.5517 - val_loss: 0.7678\n",
      "Epoch 211/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5516 - val_loss: 0.7676\n",
      "Epoch 212/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5515 - val_loss: 0.7675\n",
      "Epoch 213/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5514 - val_loss: 0.7674\n",
      "Epoch 214/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5514 - val_loss: 0.7673\n",
      "Epoch 215/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5513 - val_loss: 0.7672\n",
      "Epoch 216/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5512 - val_loss: 0.7670\n",
      "Epoch 217/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5512 - val_loss: 0.7669\n",
      "Epoch 218/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5511 - val_loss: 0.7668\n",
      "Epoch 219/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5510 - val_loss: 0.7667\n",
      "Epoch 220/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5510 - val_loss: 0.7666\n",
      "Epoch 221/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5509 - val_loss: 0.7665\n",
      "Epoch 222/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5508 - val_loss: 0.7663\n",
      "Epoch 223/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5508 - val_loss: 0.7662\n",
      "Epoch 224/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5507 - val_loss: 0.7661\n",
      "Epoch 225/1000\n",
      "161/161 [==============================] - 0s 808us/step - loss: 0.5506 - val_loss: 0.7660\n",
      "Epoch 226/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5506 - val_loss: 0.7659\n",
      "Epoch 227/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5505 - val_loss: 0.7658\n",
      "Epoch 228/1000\n",
      "161/161 [==============================] - 0s 741us/step - loss: 0.5504 - val_loss: 0.7656\n",
      "Epoch 229/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5504 - val_loss: 0.7655\n",
      "Epoch 230/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5503 - val_loss: 0.7654\n",
      "Epoch 231/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5502 - val_loss: 0.7653\n",
      "Epoch 232/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5502 - val_loss: 0.7652\n",
      "Epoch 233/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5501 - val_loss: 0.7651\n",
      "Epoch 234/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5500 - val_loss: 0.7649\n",
      "Epoch 235/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5500 - val_loss: 0.7648\n",
      "Epoch 236/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5499 - val_loss: 0.7647\n",
      "Epoch 237/1000\n",
      "161/161 [==============================] - 0s 804us/step - loss: 0.5499 - val_loss: 0.7646\n",
      "Epoch 238/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5498 - val_loss: 0.7645\n",
      "Epoch 239/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5497 - val_loss: 0.7644\n",
      "Epoch 240/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5497 - val_loss: 0.7643\n",
      "Epoch 241/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5496 - val_loss: 0.7641\n",
      "Epoch 242/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5495 - val_loss: 0.7640\n",
      "Epoch 243/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5495 - val_loss: 0.7639\n",
      "Epoch 244/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5494 - val_loss: 0.7638\n",
      "Epoch 245/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5494 - val_loss: 0.7637\n",
      "Epoch 246/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5493 - val_loss: 0.7636\n",
      "Epoch 247/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5492 - val_loss: 0.7635\n",
      "Epoch 248/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5492 - val_loss: 0.7633\n",
      "Epoch 249/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5491 - val_loss: 0.7632\n",
      "Epoch 250/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5490 - val_loss: 0.7631\n",
      "Epoch 251/1000\n",
      "161/161 [==============================] - 0s 810us/step - loss: 0.5490 - val_loss: 0.7630\n",
      "Epoch 252/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5489 - val_loss: 0.7629\n",
      "Epoch 253/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5489 - val_loss: 0.7628\n",
      "Epoch 254/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5488 - val_loss: 0.7627\n",
      "Epoch 255/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5487 - val_loss: 0.7626\n",
      "Epoch 256/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5487 - val_loss: 0.7624\n",
      "Epoch 257/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5486 - val_loss: 0.7623\n",
      "Epoch 258/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5486 - val_loss: 0.7622\n",
      "Epoch 259/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5485 - val_loss: 0.7621\n",
      "Epoch 260/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5485 - val_loss: 0.7620\n",
      "Epoch 261/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5484 - val_loss: 0.7619\n",
      "Epoch 262/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5483 - val_loss: 0.7618\n",
      "Epoch 263/1000\n",
      "161/161 [==============================] - 0s 807us/step - loss: 0.5483 - val_loss: 0.7617\n",
      "Epoch 264/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5482 - val_loss: 0.7615\n",
      "Epoch 265/1000\n",
      "161/161 [==============================] - 0s 743us/step - loss: 0.5482 - val_loss: 0.7614\n",
      "Epoch 266/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5481 - val_loss: 0.7613\n",
      "Epoch 267/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.5481 - val_loss: 0.7612\n",
      "Epoch 268/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5480 - val_loss: 0.7611\n",
      "Epoch 269/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5479 - val_loss: 0.7610\n",
      "Epoch 270/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5479 - val_loss: 0.7609\n",
      "Epoch 271/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5478 - val_loss: 0.7608\n",
      "Epoch 272/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5478 - val_loss: 0.7607\n",
      "Epoch 273/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5477 - val_loss: 0.7606\n",
      "Epoch 274/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5477 - val_loss: 0.7604\n",
      "Epoch 275/1000\n",
      "161/161 [==============================] - 0s 806us/step - loss: 0.5476 - val_loss: 0.7603\n",
      "Epoch 276/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5475 - val_loss: 0.7602\n",
      "Epoch 277/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5475 - val_loss: 0.7601\n",
      "Epoch 278/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5474 - val_loss: 0.7600\n",
      "Epoch 279/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5474 - val_loss: 0.7599\n",
      "Epoch 280/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5473 - val_loss: 0.7598\n",
      "Epoch 281/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5473 - val_loss: 0.7597\n",
      "Epoch 282/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5472 - val_loss: 0.7596\n",
      "Epoch 283/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5472 - val_loss: 0.7595\n",
      "Epoch 284/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5471 - val_loss: 0.7594\n",
      "Epoch 285/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5471 - val_loss: 0.7593\n",
      "Epoch 286/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5470 - val_loss: 0.7591\n",
      "Epoch 287/1000\n",
      "161/161 [==============================] - 0s 815us/step - loss: 0.5470 - val_loss: 0.7590\n",
      "Epoch 288/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5469 - val_loss: 0.7589\n",
      "Epoch 289/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5469 - val_loss: 0.7588\n",
      "Epoch 290/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5468 - val_loss: 0.7587\n",
      "Epoch 291/1000\n",
      "161/161 [==============================] - 0s 742us/step - loss: 0.5468 - val_loss: 0.7586\n",
      "Epoch 292/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5467 - val_loss: 0.7585\n",
      "Epoch 293/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5466 - val_loss: 0.7584\n",
      "Epoch 294/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5466 - val_loss: 0.7583\n",
      "Epoch 295/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5465 - val_loss: 0.7582\n",
      "Epoch 296/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5465 - val_loss: 0.7581\n",
      "Epoch 297/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5464 - val_loss: 0.7580\n",
      "Epoch 298/1000\n",
      "161/161 [==============================] - 0s 743us/step - loss: 0.5464 - val_loss: 0.7579\n",
      "Epoch 299/1000\n",
      "161/161 [==============================] - 0s 801us/step - loss: 0.5463 - val_loss: 0.7578\n",
      "Epoch 300/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5463 - val_loss: 0.7577\n",
      "Epoch 301/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5462 - val_loss: 0.7576\n",
      "Epoch 302/1000\n",
      "161/161 [==============================] - 0s 742us/step - loss: 0.5462 - val_loss: 0.7575\n",
      "Epoch 303/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5461 - val_loss: 0.7573\n",
      "Epoch 304/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5461 - val_loss: 0.7572\n",
      "Epoch 305/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5460 - val_loss: 0.7571\n",
      "Epoch 306/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5460 - val_loss: 0.7570\n",
      "Epoch 307/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5459 - val_loss: 0.7569\n",
      "Epoch 308/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5459 - val_loss: 0.7568\n",
      "Epoch 309/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5459 - val_loss: 0.7567\n",
      "Epoch 310/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5458 - val_loss: 0.7566\n",
      "Epoch 311/1000\n",
      "161/161 [==============================] - 0s 808us/step - loss: 0.5458 - val_loss: 0.7565\n",
      "Epoch 312/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5457 - val_loss: 0.7564\n",
      "Epoch 313/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5457 - val_loss: 0.7563\n",
      "Epoch 314/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5456 - val_loss: 0.7562\n",
      "Epoch 315/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5456 - val_loss: 0.7561\n",
      "Epoch 316/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5455 - val_loss: 0.7560\n",
      "Epoch 317/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5455 - val_loss: 0.7559\n",
      "Epoch 318/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5454 - val_loss: 0.7558\n",
      "Epoch 319/1000\n",
      "161/161 [==============================] - 0s 742us/step - loss: 0.5454 - val_loss: 0.7557\n",
      "Epoch 320/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5453 - val_loss: 0.7556\n",
      "Epoch 321/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5453 - val_loss: 0.7555\n",
      "Epoch 322/1000\n",
      "161/161 [==============================] - 0s 810us/step - loss: 0.5452 - val_loss: 0.7554\n",
      "Epoch 323/1000\n",
      "161/161 [==============================] - 0s 741us/step - loss: 0.5452 - val_loss: 0.7553\n",
      "Epoch 324/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5452 - val_loss: 0.7552\n",
      "Epoch 325/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5451 - val_loss: 0.7551\n",
      "Epoch 326/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5451 - val_loss: 0.7550\n",
      "Epoch 327/1000\n",
      "161/161 [==============================] - 0s 740us/step - loss: 0.5450 - val_loss: 0.7549\n",
      "Epoch 328/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5450 - val_loss: 0.7548\n",
      "Epoch 329/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5449 - val_loss: 0.7547\n",
      "Epoch 330/1000\n",
      "161/161 [==============================] - 0s 741us/step - loss: 0.5449 - val_loss: 0.7546\n",
      "Epoch 331/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5448 - val_loss: 0.7545\n",
      "Epoch 332/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5448 - val_loss: 0.7544\n",
      "Epoch 333/1000\n",
      "161/161 [==============================] - 0s 800us/step - loss: 0.5447 - val_loss: 0.7543\n",
      "Epoch 334/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5447 - val_loss: 0.7542\n",
      "Epoch 335/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5447 - val_loss: 0.7541\n",
      "Epoch 336/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5446 - val_loss: 0.7540\n",
      "Epoch 337/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5446 - val_loss: 0.7539\n",
      "Epoch 338/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5445 - val_loss: 0.7538\n",
      "Epoch 339/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5445 - val_loss: 0.7537\n",
      "Epoch 340/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5444 - val_loss: 0.7536\n",
      "Epoch 341/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5444 - val_loss: 0.7535\n",
      "Epoch 342/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5444 - val_loss: 0.7534\n",
      "Epoch 343/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5443 - val_loss: 0.7533\n",
      "Epoch 344/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5443 - val_loss: 0.7532\n",
      "Epoch 345/1000\n",
      "161/161 [==============================] - 0s 833us/step - loss: 0.5442 - val_loss: 0.7531\n",
      "Epoch 346/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5442 - val_loss: 0.7530\n",
      "Epoch 347/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5442 - val_loss: 0.7530\n",
      "Epoch 348/1000\n",
      "161/161 [==============================] - 0s 787us/step - loss: 0.5441 - val_loss: 0.7529\n",
      "Epoch 349/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.5441 - val_loss: 0.7528\n",
      "Epoch 350/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5440 - val_loss: 0.7527\n",
      "Epoch 351/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5440 - val_loss: 0.7526\n",
      "Epoch 352/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5439 - val_loss: 0.7525\n",
      "Epoch 353/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5439 - val_loss: 0.7524\n",
      "Epoch 354/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5439 - val_loss: 0.7523\n",
      "Epoch 355/1000\n",
      "161/161 [==============================] - 0s 884us/step - loss: 0.5438 - val_loss: 0.7522\n",
      "Epoch 356/1000\n",
      "161/161 [==============================] - 0s 784us/step - loss: 0.5438 - val_loss: 0.7521\n",
      "Epoch 357/1000\n",
      "161/161 [==============================] - 0s 787us/step - loss: 0.5437 - val_loss: 0.7520\n",
      "Epoch 358/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.5437 - val_loss: 0.7519\n",
      "Epoch 359/1000\n",
      "161/161 [==============================] - 0s 806us/step - loss: 0.5437 - val_loss: 0.7518\n",
      "Epoch 360/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5436 - val_loss: 0.7517\n",
      "Epoch 361/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.5436 - val_loss: 0.7516\n",
      "Epoch 362/1000\n",
      "161/161 [==============================] - 0s 828us/step - loss: 0.5435 - val_loss: 0.7515\n",
      "Epoch 363/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5435 - val_loss: 0.7514\n",
      "Epoch 364/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5435 - val_loss: 0.7514\n",
      "Epoch 365/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.5434 - val_loss: 0.7513\n",
      "Epoch 366/1000\n",
      "161/161 [==============================] - 0s 870us/step - loss: 0.5434 - val_loss: 0.7512\n",
      "Epoch 367/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.5434 - val_loss: 0.7511\n",
      "Epoch 368/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.5433 - val_loss: 0.7510\n",
      "Epoch 369/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.5433 - val_loss: 0.7509\n",
      "Epoch 370/1000\n",
      "161/161 [==============================] - 0s 778us/step - loss: 0.5432 - val_loss: 0.7508\n",
      "Epoch 371/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.5432 - val_loss: 0.7507\n",
      "Epoch 372/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5432 - val_loss: 0.7506\n",
      "Epoch 373/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5431 - val_loss: 0.7505\n",
      "Epoch 374/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5431 - val_loss: 0.7504\n",
      "Epoch 375/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5431 - val_loss: 0.7503\n",
      "Epoch 376/1000\n",
      "161/161 [==============================] - 0s 821us/step - loss: 0.5430 - val_loss: 0.7503\n",
      "Epoch 377/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.5430 - val_loss: 0.7502\n",
      "Epoch 378/1000\n",
      "161/161 [==============================] - 0s 840us/step - loss: 0.5429 - val_loss: 0.7501\n",
      "Epoch 379/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.5429 - val_loss: 0.7500\n",
      "Epoch 380/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.5429 - val_loss: 0.7499\n",
      "Epoch 381/1000\n",
      "161/161 [==============================] - 0s 796us/step - loss: 0.5428 - val_loss: 0.7498\n",
      "Epoch 382/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.5428 - val_loss: 0.7497\n",
      "Epoch 383/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5428 - val_loss: 0.7496\n",
      "Epoch 384/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5427 - val_loss: 0.7495\n",
      "Epoch 385/1000\n",
      "161/161 [==============================] - 0s 831us/step - loss: 0.5427 - val_loss: 0.7494\n",
      "Epoch 386/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5427 - val_loss: 0.7494\n",
      "Epoch 387/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5426 - val_loss: 0.7493\n",
      "Epoch 388/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.5426 - val_loss: 0.7492\n",
      "Epoch 389/1000\n",
      "161/161 [==============================] - 0s 925us/step - loss: 0.5425 - val_loss: 0.7491\n",
      "Epoch 390/1000\n",
      "161/161 [==============================] - 0s 839us/step - loss: 0.5425 - val_loss: 0.7490\n",
      "Epoch 391/1000\n",
      "161/161 [==============================] - 0s 804us/step - loss: 0.5425 - val_loss: 0.7489\n",
      "Epoch 392/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.5424 - val_loss: 0.7488\n",
      "Epoch 393/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5424 - val_loss: 0.7487\n",
      "Epoch 394/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5424 - val_loss: 0.7487\n",
      "Epoch 395/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5423 - val_loss: 0.7486\n",
      "Epoch 396/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5423 - val_loss: 0.7485\n",
      "Epoch 397/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.5423 - val_loss: 0.7484\n",
      "Epoch 398/1000\n",
      "161/161 [==============================] - 0s 933us/step - loss: 0.5422 - val_loss: 0.7483\n",
      "Epoch 399/1000\n",
      "161/161 [==============================] - 0s 899us/step - loss: 0.5422 - val_loss: 0.7482\n",
      "Epoch 400/1000\n",
      "161/161 [==============================] - 0s 904us/step - loss: 0.5422 - val_loss: 0.7481\n",
      "Epoch 401/1000\n",
      "161/161 [==============================] - 0s 792us/step - loss: 0.5421 - val_loss: 0.7481\n",
      "Epoch 402/1000\n",
      "161/161 [==============================] - 0s 862us/step - loss: 0.5421 - val_loss: 0.7480\n",
      "Epoch 403/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5421 - val_loss: 0.7479\n",
      "Epoch 404/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5420 - val_loss: 0.7478\n",
      "Epoch 405/1000\n",
      "161/161 [==============================] - 0s 806us/step - loss: 0.5420 - val_loss: 0.7477\n",
      "Epoch 406/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5420 - val_loss: 0.7476\n",
      "Epoch 407/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5419 - val_loss: 0.7475\n",
      "Epoch 408/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5419 - val_loss: 0.7475\n",
      "Epoch 409/1000\n",
      "161/161 [==============================] - 0s 854us/step - loss: 0.5419 - val_loss: 0.7474\n",
      "Epoch 410/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5418 - val_loss: 0.7473\n",
      "Epoch 411/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5418 - val_loss: 0.7472\n",
      "Epoch 412/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5418 - val_loss: 0.7471\n",
      "Epoch 413/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5417 - val_loss: 0.7470\n",
      "Epoch 414/1000\n",
      "161/161 [==============================] - 0s 779us/step - loss: 0.5417 - val_loss: 0.7469\n",
      "Epoch 415/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5417 - val_loss: 0.7469\n",
      "Epoch 416/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5416 - val_loss: 0.7468\n",
      "Epoch 417/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5416 - val_loss: 0.7467\n",
      "Epoch 418/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5416 - val_loss: 0.7466\n",
      "Epoch 419/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.5415 - val_loss: 0.7465\n",
      "Epoch 420/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5415 - val_loss: 0.7464\n",
      "Epoch 421/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5415 - val_loss: 0.7464\n",
      "Epoch 422/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5415 - val_loss: 0.7463\n",
      "Epoch 423/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.5414 - val_loss: 0.7462\n",
      "Epoch 424/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5414 - val_loss: 0.7461\n",
      "Epoch 425/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5414 - val_loss: 0.7460\n",
      "Epoch 426/1000\n",
      "161/161 [==============================] - 0s 742us/step - loss: 0.5413 - val_loss: 0.7459\n",
      "Epoch 427/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5413 - val_loss: 0.7459\n",
      "Epoch 428/1000\n",
      "161/161 [==============================] - 0s 813us/step - loss: 0.5413 - val_loss: 0.7458\n",
      "Epoch 429/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5412 - val_loss: 0.7457\n",
      "Epoch 430/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5412 - val_loss: 0.7456\n",
      "Epoch 431/1000\n",
      "161/161 [==============================] - 0s 814us/step - loss: 0.5412 - val_loss: 0.7455\n",
      "Epoch 432/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5411 - val_loss: 0.7455\n",
      "Epoch 433/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5411 - val_loss: 0.7454\n",
      "Epoch 434/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5411 - val_loss: 0.7453\n",
      "Epoch 435/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5411 - val_loss: 0.7452\n",
      "Epoch 436/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5410 - val_loss: 0.7451\n",
      "Epoch 437/1000\n",
      "161/161 [==============================] - 0s 743us/step - loss: 0.5410 - val_loss: 0.7450\n",
      "Epoch 438/1000\n",
      "161/161 [==============================] - 0s 805us/step - loss: 0.5410 - val_loss: 0.7450\n",
      "Epoch 439/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5409 - val_loss: 0.7449\n",
      "Epoch 440/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5409 - val_loss: 0.7448\n",
      "Epoch 441/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5409 - val_loss: 0.7447\n",
      "Epoch 442/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5409 - val_loss: 0.7446\n",
      "Epoch 443/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5408 - val_loss: 0.7446\n",
      "Epoch 444/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5408 - val_loss: 0.7445\n",
      "Epoch 445/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5408 - val_loss: 0.7444\n",
      "Epoch 446/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5407 - val_loss: 0.7443\n",
      "Epoch 447/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5407 - val_loss: 0.7442\n",
      "Epoch 448/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5407 - val_loss: 0.7442\n",
      "Epoch 449/1000\n",
      "161/161 [==============================] - 0s 807us/step - loss: 0.5407 - val_loss: 0.7441\n",
      "Epoch 450/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5406 - val_loss: 0.7440\n",
      "Epoch 451/1000\n",
      "161/161 [==============================] - 0s 794us/step - loss: 0.5406 - val_loss: 0.7439\n",
      "Epoch 452/1000\n",
      "161/161 [==============================] - 0s 867us/step - loss: 0.5406 - val_loss: 0.7438\n",
      "Epoch 453/1000\n",
      "161/161 [==============================] - 0s 868us/step - loss: 0.5405 - val_loss: 0.7438\n",
      "Epoch 454/1000\n",
      "161/161 [==============================] - 0s 856us/step - loss: 0.5405 - val_loss: 0.7437\n",
      "Epoch 455/1000\n",
      "161/161 [==============================] - 0s 836us/step - loss: 0.5405 - val_loss: 0.7436\n",
      "Epoch 456/1000\n",
      "161/161 [==============================] - 0s 779us/step - loss: 0.5405 - val_loss: 0.7435\n",
      "Epoch 457/1000\n",
      "161/161 [==============================] - 0s 848us/step - loss: 0.5404 - val_loss: 0.7435\n",
      "Epoch 458/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5404 - val_loss: 0.7434\n",
      "Epoch 459/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5404 - val_loss: 0.7433\n",
      "Epoch 460/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5404 - val_loss: 0.7432\n",
      "Epoch 461/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5403 - val_loss: 0.7431\n",
      "Epoch 462/1000\n",
      "161/161 [==============================] - 0s 796us/step - loss: 0.5403 - val_loss: 0.7431\n",
      "Epoch 463/1000\n",
      "161/161 [==============================] - 0s 860us/step - loss: 0.5403 - val_loss: 0.7430\n",
      "Epoch 464/1000\n",
      "161/161 [==============================] - 0s 815us/step - loss: 0.5403 - val_loss: 0.7429\n",
      "Epoch 465/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5402 - val_loss: 0.7428\n",
      "Epoch 466/1000\n",
      "161/161 [==============================] - 0s 847us/step - loss: 0.5402 - val_loss: 0.7428\n",
      "Epoch 467/1000\n",
      "161/161 [==============================] - 0s 784us/step - loss: 0.5402 - val_loss: 0.7427\n",
      "Epoch 468/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5402 - val_loss: 0.7426\n",
      "Epoch 469/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5401 - val_loss: 0.7425\n",
      "Epoch 470/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5401 - val_loss: 0.7425\n",
      "Epoch 471/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5401 - val_loss: 0.7424\n",
      "Epoch 472/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5401 - val_loss: 0.7423\n",
      "Epoch 473/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5400 - val_loss: 0.7422\n",
      "Epoch 474/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5400 - val_loss: 0.7421\n",
      "Epoch 475/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5400 - val_loss: 0.7421\n",
      "Epoch 476/1000\n",
      "161/161 [==============================] - 0s 803us/step - loss: 0.5400 - val_loss: 0.7420\n",
      "Epoch 477/1000\n",
      "161/161 [==============================] - 0s 742us/step - loss: 0.5399 - val_loss: 0.7419\n",
      "Epoch 478/1000\n",
      "161/161 [==============================] - 0s 739us/step - loss: 0.5399 - val_loss: 0.7418\n",
      "Epoch 479/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5399 - val_loss: 0.7418\n",
      "Epoch 480/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5399 - val_loss: 0.7417\n",
      "Epoch 481/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5398 - val_loss: 0.7416\n",
      "Epoch 482/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5398 - val_loss: 0.7415\n",
      "Epoch 483/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5398 - val_loss: 0.7415\n",
      "Epoch 484/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5398 - val_loss: 0.7414\n",
      "Epoch 485/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5397 - val_loss: 0.7413\n",
      "Epoch 486/1000\n",
      "161/161 [==============================] - 0s 804us/step - loss: 0.5397 - val_loss: 0.7412\n",
      "Epoch 487/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5397 - val_loss: 0.7412\n",
      "Epoch 488/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5397 - val_loss: 0.7411\n",
      "Epoch 489/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5396 - val_loss: 0.7410\n",
      "Epoch 490/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5396 - val_loss: 0.7409\n",
      "Epoch 491/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5396 - val_loss: 0.7409\n",
      "Epoch 492/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5396 - val_loss: 0.7408\n",
      "Epoch 493/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5396 - val_loss: 0.7407\n",
      "Epoch 494/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5395 - val_loss: 0.7407\n",
      "Epoch 495/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5395 - val_loss: 0.7406\n",
      "Epoch 496/1000\n",
      "161/161 [==============================] - 0s 811us/step - loss: 0.5395 - val_loss: 0.7405\n",
      "Epoch 497/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5395 - val_loss: 0.7404\n",
      "Epoch 498/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5395 - val_loss: 0.7404\n",
      "Epoch 499/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5394 - val_loss: 0.7403\n",
      "Epoch 500/1000\n",
      "161/161 [==============================] - 0s 785us/step - loss: 0.5394 - val_loss: 0.7402\n",
      "Epoch 501/1000\n",
      "161/161 [==============================] - 0s 785us/step - loss: 0.5394 - val_loss: 0.7401\n",
      "Epoch 502/1000\n",
      "161/161 [==============================] - 0s 788us/step - loss: 0.5394 - val_loss: 0.7401\n",
      "Epoch 503/1000\n",
      "161/161 [==============================] - 0s 778us/step - loss: 0.5393 - val_loss: 0.7400\n",
      "Epoch 504/1000\n",
      "161/161 [==============================] - 0s 789us/step - loss: 0.5393 - val_loss: 0.7399\n",
      "Epoch 505/1000\n",
      "161/161 [==============================] - 0s 824us/step - loss: 0.5393 - val_loss: 0.7399\n",
      "Epoch 506/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.5393 - val_loss: 0.7398\n",
      "Epoch 507/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5393 - val_loss: 0.7397\n",
      "Epoch 508/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5392 - val_loss: 0.7396\n",
      "Epoch 509/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5392 - val_loss: 0.7396\n",
      "Epoch 510/1000\n",
      "161/161 [==============================] - 0s 783us/step - loss: 0.5392 - val_loss: 0.7395\n",
      "Epoch 511/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5392 - val_loss: 0.7394\n",
      "Epoch 512/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5392 - val_loss: 0.7394\n",
      "Epoch 513/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5392 - val_loss: 0.7393\n",
      "Epoch 514/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5391 - val_loss: 0.7392\n",
      "Epoch 515/1000\n",
      "161/161 [==============================] - 0s 826us/step - loss: 0.5391 - val_loss: 0.7391\n",
      "Epoch 516/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5391 - val_loss: 0.7391\n",
      "Epoch 517/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5391 - val_loss: 0.7390\n",
      "Epoch 518/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5391 - val_loss: 0.7389\n",
      "Epoch 519/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5390 - val_loss: 0.7389\n",
      "Epoch 520/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5390 - val_loss: 0.7388\n",
      "Epoch 521/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5390 - val_loss: 0.7387\n",
      "Epoch 522/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5390 - val_loss: 0.7387\n",
      "Epoch 523/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.5390 - val_loss: 0.7386\n",
      "Epoch 524/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5390 - val_loss: 0.7385\n",
      "Epoch 525/1000\n",
      "161/161 [==============================] - 0s 824us/step - loss: 0.5389 - val_loss: 0.7385\n",
      "Epoch 526/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5389 - val_loss: 0.7384\n",
      "Epoch 527/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5389 - val_loss: 0.7383\n",
      "Epoch 528/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5389 - val_loss: 0.7382\n",
      "Epoch 529/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5389 - val_loss: 0.7382\n",
      "Epoch 530/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5389 - val_loss: 0.7381\n",
      "Epoch 531/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5388 - val_loss: 0.7380\n",
      "Epoch 532/1000\n",
      "161/161 [==============================] - 0s 803us/step - loss: 0.5388 - val_loss: 0.7380\n",
      "Epoch 533/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5388 - val_loss: 0.7379\n",
      "Epoch 534/1000\n",
      "161/161 [==============================] - 0s 795us/step - loss: 0.5388 - val_loss: 0.7378\n",
      "Epoch 535/1000\n",
      "161/161 [==============================] - 0s 742us/step - loss: 0.5388 - val_loss: 0.7378\n",
      "Epoch 536/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5388 - val_loss: 0.7377\n",
      "Epoch 537/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5388 - val_loss: 0.7376\n",
      "Epoch 538/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.5387 - val_loss: 0.7376\n",
      "Epoch 539/1000\n",
      "161/161 [==============================] - 0s 794us/step - loss: 0.5387 - val_loss: 0.7375\n",
      "Epoch 540/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5387 - val_loss: 0.7374\n",
      "Epoch 541/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5387 - val_loss: 0.7374\n",
      "Epoch 542/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5387 - val_loss: 0.7373\n",
      "Epoch 543/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.5387 - val_loss: 0.7372\n",
      "Epoch 544/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5387 - val_loss: 0.7372\n",
      "Epoch 545/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5387 - val_loss: 0.7371\n",
      "Epoch 546/1000\n",
      "161/161 [==============================] - 0s 873us/step - loss: 0.5386 - val_loss: 0.7370\n",
      "Epoch 547/1000\n",
      "161/161 [==============================] - 0s 837us/step - loss: 0.5386 - val_loss: 0.7370\n",
      "Epoch 548/1000\n",
      "161/161 [==============================] - 0s 836us/step - loss: 0.5386 - val_loss: 0.7369\n",
      "Epoch 549/1000\n",
      "161/161 [==============================] - 0s 841us/step - loss: 0.5386 - val_loss: 0.7369\n",
      "Epoch 550/1000\n",
      "161/161 [==============================] - 0s 935us/step - loss: 0.5386 - val_loss: 0.7368\n",
      "Epoch 551/1000\n",
      "161/161 [==============================] - 0s 926us/step - loss: 0.5386 - val_loss: 0.7367\n",
      "Epoch 552/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.5386 - val_loss: 0.7367\n",
      "Epoch 553/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.5386 - val_loss: 0.7366\n",
      "Epoch 554/1000\n",
      "161/161 [==============================] - 0s 914us/step - loss: 0.5386 - val_loss: 0.7365\n",
      "Epoch 555/1000\n",
      "161/161 [==============================] - 0s 888us/step - loss: 0.5386 - val_loss: 0.7365\n",
      "Epoch 556/1000\n",
      "161/161 [==============================] - 0s 942us/step - loss: 0.5385 - val_loss: 0.7364\n",
      "Epoch 557/1000\n",
      "161/161 [==============================] - 0s 867us/step - loss: 0.5385 - val_loss: 0.7363\n",
      "Epoch 558/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.5385 - val_loss: 0.7363\n",
      "Epoch 559/1000\n",
      "161/161 [==============================] - 0s 925us/step - loss: 0.5385 - val_loss: 0.7362\n",
      "Epoch 560/1000\n",
      "161/161 [==============================] - 0s 939us/step - loss: 0.5385 - val_loss: 0.7362\n",
      "Epoch 561/1000\n",
      "161/161 [==============================] - 0s 884us/step - loss: 0.5385 - val_loss: 0.7361\n",
      "Epoch 562/1000\n",
      "161/161 [==============================] - 0s 870us/step - loss: 0.5385 - val_loss: 0.7360\n",
      "Epoch 563/1000\n",
      "161/161 [==============================] - 0s 825us/step - loss: 0.5385 - val_loss: 0.7360\n",
      "Epoch 564/1000\n",
      "161/161 [==============================] - 0s 848us/step - loss: 0.5385 - val_loss: 0.7359\n",
      "Epoch 565/1000\n",
      "161/161 [==============================] - 0s 928us/step - loss: 0.5385 - val_loss: 0.7359\n",
      "Epoch 566/1000\n",
      "161/161 [==============================] - 0s 823us/step - loss: 0.5385 - val_loss: 0.7358\n",
      "Epoch 567/1000\n",
      "161/161 [==============================] - 0s 831us/step - loss: 0.5385 - val_loss: 0.7357\n",
      "Epoch 568/1000\n",
      "161/161 [==============================] - 0s 854us/step - loss: 0.5385 - val_loss: 0.7357\n",
      "Epoch 569/1000\n",
      "161/161 [==============================] - 0s 847us/step - loss: 0.5385 - val_loss: 0.7356\n",
      "Epoch 570/1000\n",
      "161/161 [==============================] - 0s 834us/step - loss: 0.5385 - val_loss: 0.7356\n",
      "Epoch 571/1000\n",
      "161/161 [==============================] - 0s 860us/step - loss: 0.5385 - val_loss: 0.7355\n",
      "Epoch 572/1000\n",
      "161/161 [==============================] - 0s 922us/step - loss: 0.5384 - val_loss: 0.7354\n",
      "Epoch 573/1000\n",
      "161/161 [==============================] - 0s 847us/step - loss: 0.5384 - val_loss: 0.7354\n",
      "Epoch 574/1000\n",
      "161/161 [==============================] - 0s 860us/step - loss: 0.5384 - val_loss: 0.7353\n",
      "Epoch 575/1000\n",
      "161/161 [==============================] - 0s 852us/step - loss: 0.5384 - val_loss: 0.7353\n",
      "Epoch 576/1000\n",
      "161/161 [==============================] - 0s 870us/step - loss: 0.5384 - val_loss: 0.7352\n",
      "Epoch 577/1000\n",
      "161/161 [==============================] - 0s 844us/step - loss: 0.5384 - val_loss: 0.7351\n",
      "Epoch 578/1000\n",
      "161/161 [==============================] - 0s 856us/step - loss: 0.5384 - val_loss: 0.7351\n",
      "Epoch 579/1000\n",
      "161/161 [==============================] - 0s 913us/step - loss: 0.5384 - val_loss: 0.7350\n",
      "Epoch 580/1000\n",
      "161/161 [==============================] - 0s 831us/step - loss: 0.5384 - val_loss: 0.7350\n",
      "Epoch 581/1000\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.5384 - val_loss: 0.7349\n",
      "Epoch 582/1000\n",
      "161/161 [==============================] - 0s 845us/step - loss: 0.5384 - val_loss: 0.7349\n",
      "Epoch 583/1000\n",
      "161/161 [==============================] - 0s 842us/step - loss: 0.5384 - val_loss: 0.7348\n",
      "Epoch 584/1000\n",
      "161/161 [==============================] - 0s 841us/step - loss: 0.5384 - val_loss: 0.7347\n",
      "Epoch 585/1000\n",
      "161/161 [==============================] - 0s 842us/step - loss: 0.5384 - val_loss: 0.7347\n",
      "Epoch 586/1000\n",
      "161/161 [==============================] - 0s 915us/step - loss: 0.5384 - val_loss: 0.7346\n",
      "Epoch 587/1000\n",
      "161/161 [==============================] - 0s 851us/step - loss: 0.5384 - val_loss: 0.7346\n",
      "Epoch 588/1000\n",
      "161/161 [==============================] - 0s 832us/step - loss: 0.5384 - val_loss: 0.7345\n",
      "Epoch 589/1000\n",
      "161/161 [==============================] - 0s 856us/step - loss: 0.5384 - val_loss: 0.7345\n",
      "Epoch 590/1000\n",
      "161/161 [==============================] - 0s 848us/step - loss: 0.5384 - val_loss: 0.7344\n",
      "Epoch 591/1000\n",
      "161/161 [==============================] - 0s 853us/step - loss: 0.5384 - val_loss: 0.7344\n",
      "Epoch 592/1000\n",
      "161/161 [==============================] - 0s 837us/step - loss: 0.5384 - val_loss: 0.7343\n",
      "Epoch 593/1000\n",
      "161/161 [==============================] - 0s 919us/step - loss: 0.5384 - val_loss: 0.7343\n",
      "Epoch 594/1000\n",
      "161/161 [==============================] - 0s 843us/step - loss: 0.5384 - val_loss: 0.7342\n",
      "Epoch 595/1000\n",
      "161/161 [==============================] - 0s 826us/step - loss: 0.5384 - val_loss: 0.7341\n",
      "Epoch 596/1000\n",
      "161/161 [==============================] - 0s 937us/step - loss: 0.5385 - val_loss: 0.7341\n",
      "Epoch 597/1000\n",
      "161/161 [==============================] - 0s 826us/step - loss: 0.5385 - val_loss: 0.7340\n",
      "Epoch 598/1000\n",
      "161/161 [==============================] - 0s 838us/step - loss: 0.5385 - val_loss: 0.7340\n",
      "Epoch 599/1000\n",
      "161/161 [==============================] - 0s 827us/step - loss: 0.5385 - val_loss: 0.7339\n",
      "Epoch 600/1000\n",
      "161/161 [==============================] - 0s 925us/step - loss: 0.5385 - val_loss: 0.7339\n",
      "Epoch 601/1000\n",
      "161/161 [==============================] - 0s 859us/step - loss: 0.5385 - val_loss: 0.7338\n",
      "Epoch 602/1000\n",
      "161/161 [==============================] - 0s 839us/step - loss: 0.5385 - val_loss: 0.7338\n",
      "Epoch 603/1000\n",
      "161/161 [==============================] - 0s 840us/step - loss: 0.5385 - val_loss: 0.7337\n",
      "Epoch 604/1000\n",
      "161/161 [==============================] - 0s 822us/step - loss: 0.5385 - val_loss: 0.7337\n",
      "Epoch 605/1000\n",
      "161/161 [==============================] - 0s 823us/step - loss: 0.5385 - val_loss: 0.7336\n",
      "Epoch 606/1000\n",
      "161/161 [==============================] - 0s 839us/step - loss: 0.5385 - val_loss: 0.7336\n",
      "Epoch 607/1000\n",
      "161/161 [==============================] - 0s 831us/step - loss: 0.5385 - val_loss: 0.7335\n",
      "Epoch 608/1000\n",
      "161/161 [==============================] - 0s 914us/step - loss: 0.5385 - val_loss: 0.7335\n",
      "Epoch 609/1000\n",
      "161/161 [==============================] - 0s 814us/step - loss: 0.5385 - val_loss: 0.7334\n",
      "Epoch 610/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.5385 - val_loss: 0.7334\n",
      "Epoch 611/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5386 - val_loss: 0.7333\n",
      "Epoch 612/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5386 - val_loss: 0.7333\n",
      "Epoch 613/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5386 - val_loss: 0.7332\n",
      "Epoch 614/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5386 - val_loss: 0.7332\n",
      "Epoch 615/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5386 - val_loss: 0.7331\n",
      "Epoch 616/1000\n",
      "161/161 [==============================] - 0s 820us/step - loss: 0.5386 - val_loss: 0.7331\n",
      "Epoch 617/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5386 - val_loss: 0.7330\n",
      "Epoch 618/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5386 - val_loss: 0.7330\n",
      "Epoch 619/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5386 - val_loss: 0.7329\n",
      "Epoch 620/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5387 - val_loss: 0.7329\n",
      "Epoch 621/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5387 - val_loss: 0.7329\n",
      "Epoch 622/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5387 - val_loss: 0.7328\n",
      "Epoch 623/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5387 - val_loss: 0.7328\n",
      "Epoch 624/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5387 - val_loss: 0.7327\n",
      "Epoch 625/1000\n",
      "161/161 [==============================] - 0s 806us/step - loss: 0.5387 - val_loss: 0.7327\n",
      "Epoch 626/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5387 - val_loss: 0.7326\n",
      "Epoch 627/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5388 - val_loss: 0.7326\n",
      "Epoch 628/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5388 - val_loss: 0.7325\n",
      "Epoch 629/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5388 - val_loss: 0.7325\n",
      "Epoch 630/1000\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.5388 - val_loss: 0.7324\n",
      "Epoch 631/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.5388 - val_loss: 0.7324\n",
      "Epoch 632/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5388 - val_loss: 0.7324\n",
      "Epoch 633/1000\n",
      "161/161 [==============================] - 0s 827us/step - loss: 0.5388 - val_loss: 0.7323\n",
      "Epoch 634/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5389 - val_loss: 0.7323\n",
      "Epoch 635/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5389 - val_loss: 0.7322\n",
      "Epoch 636/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5389 - val_loss: 0.7322\n",
      "Epoch 637/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5389 - val_loss: 0.7321\n",
      "Epoch 638/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5389 - val_loss: 0.7321\n",
      "Epoch 639/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5390 - val_loss: 0.7321\n",
      "Epoch 640/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5390 - val_loss: 0.7320\n",
      "Epoch 641/1000\n",
      "161/161 [==============================] - 0s 827us/step - loss: 0.5390 - val_loss: 0.7320\n",
      "Epoch 642/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5390 - val_loss: 0.7319\n",
      "Epoch 643/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5390 - val_loss: 0.7319\n",
      "Epoch 644/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5390 - val_loss: 0.7319\n",
      "Epoch 645/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5391 - val_loss: 0.7318\n",
      "Epoch 646/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5391 - val_loss: 0.7318\n",
      "Epoch 647/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5391 - val_loss: 0.7317\n",
      "Epoch 648/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5391 - val_loss: 0.7317\n",
      "Epoch 649/1000\n",
      "161/161 [==============================] - 0s 802us/step - loss: 0.5391 - val_loss: 0.7316\n",
      "Epoch 650/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5392 - val_loss: 0.7316\n",
      "Epoch 651/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5392 - val_loss: 0.7316\n",
      "Epoch 652/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5392 - val_loss: 0.7315\n",
      "Epoch 653/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5392 - val_loss: 0.7315\n",
      "Epoch 654/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5393 - val_loss: 0.7315\n",
      "Epoch 655/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5393 - val_loss: 0.7314\n",
      "Epoch 656/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5393 - val_loss: 0.7314\n",
      "Epoch 657/1000\n",
      "161/161 [==============================] - 0s 812us/step - loss: 0.5393 - val_loss: 0.7313\n",
      "Epoch 658/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5393 - val_loss: 0.7313\n",
      "Epoch 659/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5394 - val_loss: 0.7313\n",
      "Epoch 660/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5394 - val_loss: 0.7312\n",
      "Epoch 661/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5394 - val_loss: 0.7312\n",
      "Epoch 662/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5394 - val_loss: 0.7311\n",
      "Epoch 663/1000\n",
      "161/161 [==============================] - 0s 843us/step - loss: 0.5394 - val_loss: 0.7311\n",
      "Epoch 664/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5395 - val_loss: 0.7311\n",
      "Epoch 665/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.5395 - val_loss: 0.7310\n",
      "Epoch 666/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5395 - val_loss: 0.7310\n",
      "Epoch 667/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5395 - val_loss: 0.7310\n",
      "Epoch 668/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5396 - val_loss: 0.7309\n",
      "Epoch 669/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5396 - val_loss: 0.7309\n",
      "Epoch 670/1000\n",
      "161/161 [==============================] - 0s 742us/step - loss: 0.5396 - val_loss: 0.7308\n",
      "Epoch 671/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5396 - val_loss: 0.7308\n",
      "Epoch 672/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5397 - val_loss: 0.7308\n",
      "Epoch 673/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.5397 - val_loss: 0.7307\n",
      "Epoch 674/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5397 - val_loss: 0.7307\n",
      "Epoch 675/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5397 - val_loss: 0.7307\n",
      "Epoch 676/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5397 - val_loss: 0.7306\n",
      "Epoch 677/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5398 - val_loss: 0.7306\n",
      "Epoch 678/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5398 - val_loss: 0.7306\n",
      "Epoch 679/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5398 - val_loss: 0.7305\n",
      "Epoch 680/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5398 - val_loss: 0.7305\n",
      "Epoch 681/1000\n",
      "161/161 [==============================] - 0s 805us/step - loss: 0.5399 - val_loss: 0.7305\n",
      "Epoch 682/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5399 - val_loss: 0.7304\n",
      "Epoch 683/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5399 - val_loss: 0.7304\n",
      "Epoch 684/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5399 - val_loss: 0.7303\n",
      "Epoch 685/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5399 - val_loss: 0.7303\n",
      "Epoch 686/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5400 - val_loss: 0.7303\n",
      "Epoch 687/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5400 - val_loss: 0.7302\n",
      "Epoch 688/1000\n",
      "161/161 [==============================] - 0s 825us/step - loss: 0.5400 - val_loss: 0.7302\n",
      "Epoch 689/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5400 - val_loss: 0.7302\n",
      "Epoch 690/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5401 - val_loss: 0.7301\n",
      "Epoch 691/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5401 - val_loss: 0.7301\n",
      "Epoch 692/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5401 - val_loss: 0.7301\n",
      "Epoch 693/1000\n",
      "161/161 [==============================] - 0s 741us/step - loss: 0.5401 - val_loss: 0.7300\n",
      "Epoch 694/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5401 - val_loss: 0.7300\n",
      "Epoch 695/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5402 - val_loss: 0.7300\n",
      "Epoch 696/1000\n",
      "161/161 [==============================] - 0s 826us/step - loss: 0.5402 - val_loss: 0.7299\n",
      "Epoch 697/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5402 - val_loss: 0.7299\n",
      "Epoch 698/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5402 - val_loss: 0.7299\n",
      "Epoch 699/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5403 - val_loss: 0.7298\n",
      "Epoch 700/1000\n",
      "161/161 [==============================] - 0s 743us/step - loss: 0.5403 - val_loss: 0.7298\n",
      "Epoch 701/1000\n",
      "161/161 [==============================] - 0s 864us/step - loss: 0.5403 - val_loss: 0.7298\n",
      "Epoch 702/1000\n",
      "161/161 [==============================] - 0s 826us/step - loss: 0.5403 - val_loss: 0.7297\n",
      "Epoch 703/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5403 - val_loss: 0.7297\n",
      "Epoch 704/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5404 - val_loss: 0.7297\n",
      "Epoch 705/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5404 - val_loss: 0.7296\n",
      "Epoch 706/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5404 - val_loss: 0.7296\n",
      "Epoch 707/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5404 - val_loss: 0.7296\n",
      "Epoch 708/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5404 - val_loss: 0.7295\n",
      "Epoch 709/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5405 - val_loss: 0.7295\n",
      "Epoch 710/1000\n",
      "161/161 [==============================] - 0s 803us/step - loss: 0.5405 - val_loss: 0.7295\n",
      "Epoch 711/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5405 - val_loss: 0.7294\n",
      "Epoch 712/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5405 - val_loss: 0.7294\n",
      "Epoch 713/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5405 - val_loss: 0.7294\n",
      "Epoch 714/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5406 - val_loss: 0.7293\n",
      "Epoch 715/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5406 - val_loss: 0.7293\n",
      "Epoch 716/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5406 - val_loss: 0.7293\n",
      "Epoch 717/1000\n",
      "161/161 [==============================] - 0s 808us/step - loss: 0.5406 - val_loss: 0.7292\n",
      "Epoch 718/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5406 - val_loss: 0.7292\n",
      "Epoch 719/1000\n",
      "161/161 [==============================] - 0s 739us/step - loss: 0.5407 - val_loss: 0.7292\n",
      "Epoch 720/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5407 - val_loss: 0.7291\n",
      "Epoch 721/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5407 - val_loss: 0.7291\n",
      "Epoch 722/1000\n",
      "161/161 [==============================] - 0s 743us/step - loss: 0.5407 - val_loss: 0.7291\n",
      "Epoch 723/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5407 - val_loss: 0.7291\n",
      "Epoch 724/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5408 - val_loss: 0.7290\n",
      "Epoch 725/1000\n",
      "161/161 [==============================] - 0s 805us/step - loss: 0.5408 - val_loss: 0.7290\n",
      "Epoch 726/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5408 - val_loss: 0.7290\n",
      "Epoch 727/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5408 - val_loss: 0.7289\n",
      "Epoch 728/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5408 - val_loss: 0.7289\n",
      "Epoch 729/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5408 - val_loss: 0.7289\n",
      "Epoch 730/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5409 - val_loss: 0.7288\n",
      "Epoch 731/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5409 - val_loss: 0.7288\n",
      "Epoch 732/1000\n",
      "161/161 [==============================] - 0s 806us/step - loss: 0.5409 - val_loss: 0.7288\n",
      "Epoch 733/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5409 - val_loss: 0.7287\n",
      "Epoch 734/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5409 - val_loss: 0.7287\n",
      "Epoch 735/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5409 - val_loss: 0.7287\n",
      "Epoch 736/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5410 - val_loss: 0.7286\n",
      "Epoch 737/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5410 - val_loss: 0.7286\n",
      "Epoch 738/1000\n",
      "161/161 [==============================] - 0s 743us/step - loss: 0.5410 - val_loss: 0.7286\n",
      "Epoch 739/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5410 - val_loss: 0.7285\n",
      "Epoch 740/1000\n",
      "161/161 [==============================] - 0s 807us/step - loss: 0.5410 - val_loss: 0.7285\n",
      "Epoch 741/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5410 - val_loss: 0.7285\n",
      "Epoch 742/1000\n",
      "161/161 [==============================] - 0s 839us/step - loss: 0.5410 - val_loss: 0.7285\n",
      "Epoch 743/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5411 - val_loss: 0.7284\n",
      "Epoch 744/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5411 - val_loss: 0.7284\n",
      "Epoch 745/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5411 - val_loss: 0.7284\n",
      "Epoch 746/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.5411 - val_loss: 0.7283\n",
      "Epoch 747/1000\n",
      "161/161 [==============================] - 0s 804us/step - loss: 0.5411 - val_loss: 0.7283\n",
      "Epoch 748/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5411 - val_loss: 0.7283\n",
      "Epoch 749/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5411 - val_loss: 0.7282\n",
      "Epoch 750/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5411 - val_loss: 0.7282\n",
      "Epoch 751/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5412 - val_loss: 0.7282\n",
      "Epoch 752/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5412 - val_loss: 0.7281\n",
      "Epoch 753/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5412 - val_loss: 0.7281\n",
      "Epoch 754/1000\n",
      "161/161 [==============================] - 0s 806us/step - loss: 0.5412 - val_loss: 0.7281\n",
      "Epoch 755/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5412 - val_loss: 0.7280\n",
      "Epoch 756/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5412 - val_loss: 0.7280\n",
      "Epoch 757/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5412 - val_loss: 0.7280\n",
      "Epoch 758/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5412 - val_loss: 0.7280\n",
      "Epoch 759/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5412 - val_loss: 0.7279\n",
      "Epoch 760/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5413 - val_loss: 0.7279\n",
      "Epoch 761/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5413 - val_loss: 0.7279\n",
      "Epoch 762/1000\n",
      "161/161 [==============================] - 0s 807us/step - loss: 0.5413 - val_loss: 0.7278\n",
      "Epoch 763/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5413 - val_loss: 0.7278\n",
      "Epoch 764/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5413 - val_loss: 0.7278\n",
      "Epoch 765/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5413 - val_loss: 0.7277\n",
      "Epoch 766/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5413 - val_loss: 0.7277\n",
      "Epoch 767/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5413 - val_loss: 0.7277\n",
      "Epoch 768/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5413 - val_loss: 0.7276\n",
      "Epoch 769/1000\n",
      "161/161 [==============================] - 0s 819us/step - loss: 0.5413 - val_loss: 0.7276\n",
      "Epoch 770/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5413 - val_loss: 0.7276\n",
      "Epoch 771/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5414 - val_loss: 0.7276\n",
      "Epoch 772/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5414 - val_loss: 0.7275\n",
      "Epoch 773/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5414 - val_loss: 0.7275\n",
      "Epoch 774/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5414 - val_loss: 0.7275\n",
      "Epoch 775/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5414 - val_loss: 0.7274\n",
      "Epoch 776/1000\n",
      "161/161 [==============================] - 0s 807us/step - loss: 0.5414 - val_loss: 0.7274\n",
      "Epoch 777/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5414 - val_loss: 0.7274\n",
      "Epoch 778/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5414 - val_loss: 0.7273\n",
      "Epoch 779/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5414 - val_loss: 0.7273\n",
      "Epoch 780/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5414 - val_loss: 0.7273\n",
      "Epoch 781/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5414 - val_loss: 0.7273\n",
      "Epoch 782/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5414 - val_loss: 0.7272\n",
      "Epoch 783/1000\n",
      "161/161 [==============================] - 0s 811us/step - loss: 0.5414 - val_loss: 0.7272\n",
      "Epoch 784/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5414 - val_loss: 0.7272\n",
      "Epoch 785/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5415 - val_loss: 0.7271\n",
      "Epoch 786/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5415 - val_loss: 0.7271\n",
      "Epoch 787/1000\n",
      "161/161 [==============================] - 0s 838us/step - loss: 0.5415 - val_loss: 0.7271\n",
      "Epoch 788/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5415 - val_loss: 0.7270\n",
      "Epoch 789/1000\n",
      "161/161 [==============================] - 0s 822us/step - loss: 0.5415 - val_loss: 0.7270\n",
      "Epoch 790/1000\n",
      "161/161 [==============================] - 0s 919us/step - loss: 0.5415 - val_loss: 0.7270\n",
      "Epoch 791/1000\n",
      "161/161 [==============================] - 0s 865us/step - loss: 0.5415 - val_loss: 0.7270\n",
      "Epoch 792/1000\n",
      "161/161 [==============================] - 0s 850us/step - loss: 0.5415 - val_loss: 0.7269\n",
      "Epoch 793/1000\n",
      "161/161 [==============================] - 0s 851us/step - loss: 0.5415 - val_loss: 0.7269\n",
      "Epoch 794/1000\n",
      "161/161 [==============================] - 0s 854us/step - loss: 0.5415 - val_loss: 0.7269\n",
      "Epoch 795/1000\n",
      "161/161 [==============================] - 0s 923us/step - loss: 0.5415 - val_loss: 0.7268\n",
      "Epoch 796/1000\n",
      "161/161 [==============================] - 0s 881us/step - loss: 0.5415 - val_loss: 0.7268\n",
      "Epoch 797/1000\n",
      "161/161 [==============================] - 0s 842us/step - loss: 0.5415 - val_loss: 0.7268\n",
      "Epoch 798/1000\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.5415 - val_loss: 0.7268\n",
      "Epoch 799/1000\n",
      "161/161 [==============================] - 0s 829us/step - loss: 0.5415 - val_loss: 0.7267\n",
      "Epoch 800/1000\n",
      "161/161 [==============================] - 0s 927us/step - loss: 0.5415 - val_loss: 0.7267\n",
      "Epoch 801/1000\n",
      "161/161 [==============================] - 0s 824us/step - loss: 0.5415 - val_loss: 0.7267\n",
      "Epoch 802/1000\n",
      "161/161 [==============================] - 0s 925us/step - loss: 0.5415 - val_loss: 0.7266\n",
      "Epoch 803/1000\n",
      "161/161 [==============================] - 0s 849us/step - loss: 0.5415 - val_loss: 0.7266\n",
      "Epoch 804/1000\n",
      "161/161 [==============================] - 0s 857us/step - loss: 0.5415 - val_loss: 0.7266\n",
      "Epoch 805/1000\n",
      "161/161 [==============================] - 0s 844us/step - loss: 0.5415 - val_loss: 0.7265\n",
      "Epoch 806/1000\n",
      "161/161 [==============================] - 0s 853us/step - loss: 0.5415 - val_loss: 0.7265\n",
      "Epoch 807/1000\n",
      "161/161 [==============================] - 0s 854us/step - loss: 0.5415 - val_loss: 0.7265\n",
      "Epoch 808/1000\n",
      "161/161 [==============================] - 0s 909us/step - loss: 0.5415 - val_loss: 0.7265\n",
      "Epoch 809/1000\n",
      "161/161 [==============================] - 0s 837us/step - loss: 0.5415 - val_loss: 0.7264\n",
      "Epoch 810/1000\n",
      "161/161 [==============================] - 0s 823us/step - loss: 0.5415 - val_loss: 0.7264\n",
      "Epoch 811/1000\n",
      "161/161 [==============================] - 0s 856us/step - loss: 0.5415 - val_loss: 0.7264\n",
      "Epoch 812/1000\n",
      "161/161 [==============================] - 0s 843us/step - loss: 0.5415 - val_loss: 0.7263\n",
      "Epoch 813/1000\n",
      "161/161 [==============================] - 0s 840us/step - loss: 0.5415 - val_loss: 0.7263\n",
      "Epoch 814/1000\n",
      "161/161 [==============================] - 0s 793us/step - loss: 0.5415 - val_loss: 0.7263\n",
      "Epoch 815/1000\n",
      "161/161 [==============================] - 0s 834us/step - loss: 0.5415 - val_loss: 0.7263\n",
      "Epoch 816/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5415 - val_loss: 0.7262\n",
      "Epoch 817/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5415 - val_loss: 0.7262\n",
      "Epoch 818/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5415 - val_loss: 0.7262\n",
      "Epoch 819/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.5415 - val_loss: 0.7261\n",
      "Epoch 820/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5415 - val_loss: 0.7261\n",
      "Epoch 821/1000\n",
      "161/161 [==============================] - 0s 781us/step - loss: 0.5415 - val_loss: 0.7261\n",
      "Epoch 822/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.5415 - val_loss: 0.7261\n",
      "Epoch 823/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.5415 - val_loss: 0.7260\n",
      "Epoch 824/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5415 - val_loss: 0.7260\n",
      "Epoch 825/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5415 - val_loss: 0.7260\n",
      "Epoch 826/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5415 - val_loss: 0.7259\n",
      "Epoch 827/1000\n",
      "161/161 [==============================] - 0s 794us/step - loss: 0.5415 - val_loss: 0.7259\n",
      "Epoch 828/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.5415 - val_loss: 0.7259\n",
      "Epoch 829/1000\n",
      "161/161 [==============================] - 0s 825us/step - loss: 0.5415 - val_loss: 0.7259\n",
      "Epoch 830/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5415 - val_loss: 0.7258\n",
      "Epoch 831/1000\n",
      "161/161 [==============================] - 0s 784us/step - loss: 0.5415 - val_loss: 0.7258\n",
      "Epoch 832/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.5415 - val_loss: 0.7258\n",
      "Epoch 833/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.5415 - val_loss: 0.7257\n",
      "Epoch 834/1000\n",
      "161/161 [==============================] - 0s 785us/step - loss: 0.5415 - val_loss: 0.7257\n",
      "Epoch 835/1000\n",
      "161/161 [==============================] - 0s 830us/step - loss: 0.5415 - val_loss: 0.7257\n",
      "Epoch 836/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.5415 - val_loss: 0.7257\n",
      "Epoch 837/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5415 - val_loss: 0.7256\n",
      "Epoch 838/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.5415 - val_loss: 0.7256\n",
      "Epoch 839/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.5415 - val_loss: 0.7256\n",
      "Epoch 840/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.5415 - val_loss: 0.7255\n",
      "Epoch 841/1000\n",
      "161/161 [==============================] - 0s 822us/step - loss: 0.5415 - val_loss: 0.7255\n",
      "Epoch 842/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5415 - val_loss: 0.7255\n",
      "Epoch 843/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5415 - val_loss: 0.7255\n",
      "Epoch 844/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5415 - val_loss: 0.7254\n",
      "Epoch 845/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5415 - val_loss: 0.7254\n",
      "Epoch 846/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5415 - val_loss: 0.7254\n",
      "Epoch 847/1000\n",
      "161/161 [==============================] - 0s 816us/step - loss: 0.5415 - val_loss: 0.7253\n",
      "Epoch 848/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5415 - val_loss: 0.7253\n",
      "Epoch 849/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5415 - val_loss: 0.7253\n",
      "Epoch 850/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5415 - val_loss: 0.7253\n",
      "Epoch 851/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5415 - val_loss: 0.7252\n",
      "Epoch 852/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5415 - val_loss: 0.7252\n",
      "Epoch 853/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5415 - val_loss: 0.7252\n",
      "Epoch 854/1000\n",
      "161/161 [==============================] - 0s 825us/step - loss: 0.5415 - val_loss: 0.7252\n",
      "Epoch 855/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5415 - val_loss: 0.7251\n",
      "Epoch 856/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5415 - val_loss: 0.7251\n",
      "Epoch 857/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5414 - val_loss: 0.7251\n",
      "Epoch 858/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5414 - val_loss: 0.7250\n",
      "Epoch 859/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.5414 - val_loss: 0.7250\n",
      "Epoch 860/1000\n",
      "161/161 [==============================] - 0s 816us/step - loss: 0.5414 - val_loss: 0.7250\n",
      "Epoch 861/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5414 - val_loss: 0.7250\n",
      "Epoch 862/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5414 - val_loss: 0.7249\n",
      "Epoch 863/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5414 - val_loss: 0.7249\n",
      "Epoch 864/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5414 - val_loss: 0.7249\n",
      "Epoch 865/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5414 - val_loss: 0.7249\n",
      "Epoch 866/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5414 - val_loss: 0.7248\n",
      "Epoch 867/1000\n",
      "161/161 [==============================] - 0s 800us/step - loss: 0.5414 - val_loss: 0.7248\n",
      "Epoch 868/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.5414 - val_loss: 0.7248\n",
      "Epoch 869/1000\n",
      "161/161 [==============================] - 0s 795us/step - loss: 0.5414 - val_loss: 0.7248\n",
      "Epoch 870/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.5414 - val_loss: 0.7247\n",
      "Epoch 871/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5414 - val_loss: 0.7247\n",
      "Epoch 872/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5414 - val_loss: 0.7247\n",
      "Epoch 873/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5414 - val_loss: 0.7246\n",
      "Epoch 874/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5414 - val_loss: 0.7246\n",
      "Epoch 875/1000\n",
      "161/161 [==============================] - 0s 811us/step - loss: 0.5414 - val_loss: 0.7246\n",
      "Epoch 876/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5414 - val_loss: 0.7246\n",
      "Epoch 877/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5414 - val_loss: 0.7245\n",
      "Epoch 878/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5413 - val_loss: 0.7245\n",
      "Epoch 879/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5413 - val_loss: 0.7245\n",
      "Epoch 880/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5413 - val_loss: 0.7245\n",
      "Epoch 881/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5413 - val_loss: 0.7244\n",
      "Epoch 882/1000\n",
      "161/161 [==============================] - 0s 805us/step - loss: 0.5413 - val_loss: 0.7244\n",
      "Epoch 883/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5413 - val_loss: 0.7244\n",
      "Epoch 884/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5413 - val_loss: 0.7244\n",
      "Epoch 885/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5413 - val_loss: 0.7243\n",
      "Epoch 886/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5413 - val_loss: 0.7243\n",
      "Epoch 887/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5413 - val_loss: 0.7243\n",
      "Epoch 888/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.5413 - val_loss: 0.7243\n",
      "Epoch 889/1000\n",
      "161/161 [==============================] - 0s 743us/step - loss: 0.5413 - val_loss: 0.7242\n",
      "Epoch 890/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5413 - val_loss: 0.7242\n",
      "Epoch 891/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5413 - val_loss: 0.7242\n",
      "Epoch 892/1000\n",
      "161/161 [==============================] - 0s 835us/step - loss: 0.5413 - val_loss: 0.7242\n",
      "Epoch 893/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5413 - val_loss: 0.7241\n",
      "Epoch 894/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.5413 - val_loss: 0.7241\n",
      "Epoch 895/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5412 - val_loss: 0.7241\n",
      "Epoch 896/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5412 - val_loss: 0.7241\n",
      "Epoch 897/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.5412 - val_loss: 0.7240\n",
      "Epoch 898/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5412 - val_loss: 0.7240\n",
      "Epoch 899/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5412 - val_loss: 0.7240\n",
      "Epoch 900/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5412 - val_loss: 0.7239\n",
      "Epoch 901/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5412 - val_loss: 0.7239\n",
      "Epoch 902/1000\n",
      "161/161 [==============================] - 0s 805us/step - loss: 0.5412 - val_loss: 0.7239\n",
      "Epoch 903/1000\n",
      "161/161 [==============================] - 0s 741us/step - loss: 0.5412 - val_loss: 0.7239\n",
      "Epoch 904/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5412 - val_loss: 0.7239\n",
      "Epoch 905/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5412 - val_loss: 0.7238\n",
      "Epoch 906/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5412 - val_loss: 0.7238\n",
      "Epoch 907/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5412 - val_loss: 0.7238\n",
      "Epoch 908/1000\n",
      "161/161 [==============================] - 0s 802us/step - loss: 0.5412 - val_loss: 0.7238\n",
      "Epoch 909/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5412 - val_loss: 0.7237\n",
      "Epoch 910/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5412 - val_loss: 0.7237\n",
      "Epoch 911/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5411 - val_loss: 0.7237\n",
      "Epoch 912/1000\n",
      "161/161 [==============================] - 0s 742us/step - loss: 0.5411 - val_loss: 0.7237\n",
      "Epoch 913/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5411 - val_loss: 0.7236\n",
      "Epoch 914/1000\n",
      "161/161 [==============================] - 0s 812us/step - loss: 0.5411 - val_loss: 0.7236\n",
      "Epoch 915/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5411 - val_loss: 0.7236\n",
      "Epoch 916/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5411 - val_loss: 0.7236\n",
      "Epoch 917/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5411 - val_loss: 0.7235\n",
      "Epoch 918/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5411 - val_loss: 0.7235\n",
      "Epoch 919/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5411 - val_loss: 0.7235\n",
      "Epoch 920/1000\n",
      "161/161 [==============================] - 0s 835us/step - loss: 0.5411 - val_loss: 0.7235\n",
      "Epoch 921/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5411 - val_loss: 0.7234\n",
      "Epoch 922/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5411 - val_loss: 0.7234\n",
      "Epoch 923/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5411 - val_loss: 0.7234\n",
      "Epoch 924/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5411 - val_loss: 0.7234\n",
      "Epoch 925/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5411 - val_loss: 0.7233\n",
      "Epoch 926/1000\n",
      "161/161 [==============================] - 0s 802us/step - loss: 0.5410 - val_loss: 0.7233\n",
      "Epoch 927/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5410 - val_loss: 0.7233\n",
      "Epoch 928/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5410 - val_loss: 0.7233\n",
      "Epoch 929/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5410 - val_loss: 0.7232\n",
      "Epoch 930/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5410 - val_loss: 0.7232\n",
      "Epoch 931/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5410 - val_loss: 0.7232\n",
      "Epoch 932/1000\n",
      "161/161 [==============================] - 0s 801us/step - loss: 0.5410 - val_loss: 0.7232\n",
      "Epoch 933/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5410 - val_loss: 0.7232\n",
      "Epoch 934/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5410 - val_loss: 0.7231\n",
      "Epoch 935/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5410 - val_loss: 0.7231\n",
      "Epoch 936/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5410 - val_loss: 0.7231\n",
      "Epoch 937/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5410 - val_loss: 0.7231\n",
      "Epoch 938/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5410 - val_loss: 0.7230\n",
      "Epoch 939/1000\n",
      "161/161 [==============================] - 0s 812us/step - loss: 0.5410 - val_loss: 0.7230\n",
      "Epoch 940/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5409 - val_loss: 0.7230\n",
      "Epoch 941/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5409 - val_loss: 0.7230\n",
      "Epoch 942/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5409 - val_loss: 0.7229\n",
      "Epoch 943/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5409 - val_loss: 0.7229\n",
      "Epoch 944/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5409 - val_loss: 0.7229\n",
      "Epoch 945/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5409 - val_loss: 0.7229\n",
      "Epoch 946/1000\n",
      "161/161 [==============================] - 0s 814us/step - loss: 0.5409 - val_loss: 0.7229\n",
      "Epoch 947/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5409 - val_loss: 0.7228\n",
      "Epoch 948/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5409 - val_loss: 0.7228\n",
      "Epoch 949/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5409 - val_loss: 0.7228\n",
      "Epoch 950/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5409 - val_loss: 0.7228\n",
      "Epoch 951/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5409 - val_loss: 0.7227\n",
      "Epoch 952/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.5409 - val_loss: 0.7227\n",
      "Epoch 953/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.5409 - val_loss: 0.7227\n",
      "Epoch 954/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5409 - val_loss: 0.7227\n",
      "Epoch 955/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5408 - val_loss: 0.7227\n",
      "Epoch 956/1000\n",
      "161/161 [==============================] - 0s 751us/step - loss: 0.5408 - val_loss: 0.7226\n",
      "Epoch 957/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5408 - val_loss: 0.7226\n",
      "Epoch 958/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5408 - val_loss: 0.7226\n",
      "Epoch 959/1000\n",
      "161/161 [==============================] - 0s 798us/step - loss: 0.5408 - val_loss: 0.7226\n",
      "Epoch 960/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5408 - val_loss: 0.7225\n",
      "Epoch 961/1000\n",
      "161/161 [==============================] - 0s 743us/step - loss: 0.5408 - val_loss: 0.7225\n",
      "Epoch 962/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5408 - val_loss: 0.7225\n",
      "Epoch 963/1000\n",
      "161/161 [==============================] - 0s 742us/step - loss: 0.5408 - val_loss: 0.7225\n",
      "Epoch 964/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5408 - val_loss: 0.7225\n",
      "Epoch 965/1000\n",
      "161/161 [==============================] - 0s 842us/step - loss: 0.5408 - val_loss: 0.7224\n",
      "Epoch 966/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5408 - val_loss: 0.7224\n",
      "Epoch 967/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5408 - val_loss: 0.7224\n",
      "Epoch 968/1000\n",
      "161/161 [==============================] - 0s 743us/step - loss: 0.5408 - val_loss: 0.7224\n",
      "Epoch 969/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5407 - val_loss: 0.7224\n",
      "Epoch 970/1000\n",
      "161/161 [==============================] - 0s 741us/step - loss: 0.5407 - val_loss: 0.7223\n",
      "Epoch 971/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5407 - val_loss: 0.7223\n",
      "Epoch 972/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.5407 - val_loss: 0.7223\n",
      "Epoch 973/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5407 - val_loss: 0.7223\n",
      "Epoch 974/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5407 - val_loss: 0.7222\n",
      "Epoch 975/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.5407 - val_loss: 0.7222\n",
      "Epoch 976/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5407 - val_loss: 0.7222\n",
      "Epoch 977/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5407 - val_loss: 0.7222\n",
      "Epoch 978/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5407 - val_loss: 0.7222\n",
      "Epoch 979/1000\n",
      "161/161 [==============================] - 0s 745us/step - loss: 0.5407 - val_loss: 0.7221\n",
      "Epoch 980/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5407 - val_loss: 0.7221\n",
      "Epoch 981/1000\n",
      "161/161 [==============================] - 0s 796us/step - loss: 0.5407 - val_loss: 0.7221\n",
      "Epoch 982/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5407 - val_loss: 0.7221\n",
      "Epoch 983/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5407 - val_loss: 0.7221\n",
      "Epoch 984/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5406 - val_loss: 0.7220\n",
      "Epoch 985/1000\n",
      "161/161 [==============================] - 0s 748us/step - loss: 0.5406 - val_loss: 0.7220\n",
      "Epoch 986/1000\n",
      "161/161 [==============================] - 0s 739us/step - loss: 0.5406 - val_loss: 0.7220\n",
      "Epoch 987/1000\n",
      "161/161 [==============================] - 0s 798us/step - loss: 0.5406 - val_loss: 0.7220\n",
      "Epoch 988/1000\n",
      "161/161 [==============================] - 0s 747us/step - loss: 0.5406 - val_loss: 0.7220\n",
      "Epoch 989/1000\n",
      "161/161 [==============================] - 0s 746us/step - loss: 0.5406 - val_loss: 0.7219\n",
      "Epoch 990/1000\n",
      "161/161 [==============================] - 0s 739us/step - loss: 0.5406 - val_loss: 0.7219\n",
      "Epoch 991/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5406 - val_loss: 0.7219\n",
      "Epoch 992/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5406 - val_loss: 0.7219\n",
      "Epoch 993/1000\n",
      "161/161 [==============================] - 0s 800us/step - loss: 0.5406 - val_loss: 0.7219\n",
      "Epoch 994/1000\n",
      "161/161 [==============================] - 0s 750us/step - loss: 0.5406 - val_loss: 0.7218\n",
      "Epoch 995/1000\n",
      "161/161 [==============================] - 0s 744us/step - loss: 0.5406 - val_loss: 0.7218\n",
      "Epoch 996/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.5406 - val_loss: 0.7218\n",
      "Epoch 997/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5406 - val_loss: 0.7218\n",
      "Epoch 998/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5406 - val_loss: 0.7218\n",
      "Epoch 999/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5405 - val_loss: 0.7217\n",
      "Epoch 1000/1000\n",
      "161/161 [==============================] - 0s 749us/step - loss: 0.5405 - val_loss: 0.7217\n"
     ]
    }
   ],
   "source": [
    "epocas = 1000\n",
    "history= modelo1.fit(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size = lote,\n",
    "    epochs = epocas,\n",
    "    shuffle = False,\n",
    "    validation_data = (x_val,y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ac207b90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida en Entrenamiento\n",
      "161/161 [==============================] - 0s 512us/step - loss: 0.5320\n",
      "Pérdida en Validación\n",
      "53/53 [==============================] - 0s 430us/step - loss: 0.7221\n",
      "Pérdida en Prueba\n",
      "52/52 [==============================] - 0s 438us/step - loss: 0.5223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.522267758846283"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Pérdida en Entrenamiento\")\n",
    "modelo1.evaluate(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size=1\n",
    ")\n",
    "print(\"Pérdida en Validación\")\n",
    "modelo1.evaluate(\n",
    "    x = x_val,\n",
    "    y = y_val,\n",
    "    batch_size=1\n",
    ")\n",
    "print(\"Pérdida en Prueba\")\n",
    "modelo1.evaluate(\n",
    "    x = x_test,\n",
    "    y = y_test,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (1, 1, 1)                 12        \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (1, 1, 1)                 12        \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (1, 1, 1)                 12        \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (1, 1)                    12        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, 1)                    2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50 (200.00 Byte)\n",
      "Trainable params: 50 (200.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo2 = Sequential()\n",
    "\n",
    "lote = 1\n",
    "paso = 1\n",
    "caracteristicas = 1\n",
    "\n",
    "modelo2.add(LSTM(lote, batch_input_shape=(lote, paso, caracteristicas), stateful=True, return_sequences=True))\n",
    "modelo2.add(LSTM(lote, return_sequences=True, stateful=True))\n",
    "modelo2.add(LSTM(lote, return_sequences=True, stateful=True))\n",
    "modelo2.add(LSTM(lote, stateful=True))\n",
    "modelo2.add(Dense(1))\n",
    "modelo2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo2.compile(loss='mean_squared_error',optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "161/161 [==============================] - 3s 6ms/step - loss: 1.0125 - val_loss: 1.2004\n",
      "Epoch 2/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0125 - val_loss: 1.2003\n",
      "Epoch 3/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0124 - val_loss: 1.2002\n",
      "Epoch 4/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0124 - val_loss: 1.2002\n",
      "Epoch 5/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0123 - val_loss: 1.2001\n",
      "Epoch 6/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0123 - val_loss: 1.2001\n",
      "Epoch 7/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0122 - val_loss: 1.2000\n",
      "Epoch 8/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0121 - val_loss: 1.1999\n",
      "Epoch 9/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0119 - val_loss: 1.1998\n",
      "Epoch 10/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0117 - val_loss: 1.1997\n",
      "Epoch 11/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 1.0115 - val_loss: 1.1996\n",
      "Epoch 12/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0111 - val_loss: 1.1993\n",
      "Epoch 13/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0106 - val_loss: 1.1988\n",
      "Epoch 14/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0099 - val_loss: 1.1980\n",
      "Epoch 15/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0090 - val_loss: 1.1968\n",
      "Epoch 16/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0078 - val_loss: 1.1950\n",
      "Epoch 17/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0064 - val_loss: 1.1927\n",
      "Epoch 18/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0046 - val_loss: 1.1897\n",
      "Epoch 19/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0023 - val_loss: 1.1860\n",
      "Epoch 20/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.1815\n",
      "Epoch 21/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 1.1760\n",
      "Epoch 22/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9911 - val_loss: 1.1696\n",
      "Epoch 23/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9856 - val_loss: 1.1619\n",
      "Epoch 24/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9789 - val_loss: 1.1528\n",
      "Epoch 25/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9708 - val_loss: 1.1422\n",
      "Epoch 26/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9617 - val_loss: 1.1303\n",
      "Epoch 27/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 1.1170\n",
      "Epoch 28/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9409 - val_loss: 1.1024\n",
      "Epoch 29/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 1.0869\n",
      "Epoch 30/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 1.0709\n",
      "Epoch 31/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9069 - val_loss: 1.0549\n",
      "Epoch 32/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8957 - val_loss: 1.0393\n",
      "Epoch 33/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8849 - val_loss: 1.0244\n",
      "Epoch 34/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8730 - val_loss: 1.0104\n",
      "Epoch 35/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8592 - val_loss: 0.9972\n",
      "Epoch 36/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8473 - val_loss: 0.9850\n",
      "Epoch 37/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8375 - val_loss: 0.9743\n",
      "Epoch 38/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8289 - val_loss: 0.9648\n",
      "Epoch 39/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8213 - val_loss: 0.9567\n",
      "Epoch 40/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8145 - val_loss: 0.9496\n",
      "Epoch 41/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8085 - val_loss: 0.9435\n",
      "Epoch 42/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8031 - val_loss: 0.9382\n",
      "Epoch 43/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7982 - val_loss: 0.9337\n",
      "Epoch 44/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7939 - val_loss: 0.9298\n",
      "Epoch 45/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7901 - val_loss: 0.9265\n",
      "Epoch 46/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7868 - val_loss: 0.9237\n",
      "Epoch 47/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7840 - val_loss: 0.9213\n",
      "Epoch 48/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7815 - val_loss: 0.9194\n",
      "Epoch 49/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7792 - val_loss: 0.9177\n",
      "Epoch 50/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7772 - val_loss: 0.9164\n",
      "Epoch 51/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7754 - val_loss: 0.9153\n",
      "Epoch 52/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7738 - val_loss: 0.9144\n",
      "Epoch 53/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7724 - val_loss: 0.9137\n",
      "Epoch 54/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7711 - val_loss: 0.9131\n",
      "Epoch 55/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7698 - val_loss: 0.9127\n",
      "Epoch 56/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7687 - val_loss: 0.9124\n",
      "Epoch 57/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7677 - val_loss: 0.9122\n",
      "Epoch 58/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7667 - val_loss: 0.9121\n",
      "Epoch 59/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7658 - val_loss: 0.9120\n",
      "Epoch 60/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7649 - val_loss: 0.9120\n",
      "Epoch 61/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7641 - val_loss: 0.9120\n",
      "Epoch 62/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7633 - val_loss: 0.9121\n",
      "Epoch 63/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7625 - val_loss: 0.9122\n",
      "Epoch 64/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7618 - val_loss: 0.9124\n",
      "Epoch 65/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7611 - val_loss: 0.9126\n",
      "Epoch 66/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7605 - val_loss: 0.9129\n",
      "Epoch 67/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7599 - val_loss: 0.9132\n",
      "Epoch 68/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7593 - val_loss: 0.9136\n",
      "Epoch 69/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7588 - val_loss: 0.9140\n",
      "Epoch 70/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7582 - val_loss: 0.9145\n",
      "Epoch 71/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7578 - val_loss: 0.9150\n",
      "Epoch 72/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7573 - val_loss: 0.9155\n",
      "Epoch 73/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7569 - val_loss: 0.9161\n",
      "Epoch 74/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7565 - val_loss: 0.9168\n",
      "Epoch 75/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7561 - val_loss: 0.9174\n",
      "Epoch 76/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7557 - val_loss: 0.9182\n",
      "Epoch 77/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7554 - val_loss: 0.9189\n",
      "Epoch 78/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7550 - val_loss: 0.9197\n",
      "Epoch 79/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7547 - val_loss: 0.9205\n",
      "Epoch 80/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7544 - val_loss: 0.9213\n",
      "Epoch 81/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7541 - val_loss: 0.9222\n",
      "Epoch 82/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7538 - val_loss: 0.9231\n",
      "Epoch 83/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7536 - val_loss: 0.9240\n",
      "Epoch 84/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7533 - val_loss: 0.9249\n",
      "Epoch 85/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7530 - val_loss: 0.9258\n",
      "Epoch 86/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7528 - val_loss: 0.9267\n",
      "Epoch 87/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7525 - val_loss: 0.9277\n",
      "Epoch 88/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7523 - val_loss: 0.9286\n",
      "Epoch 89/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7520 - val_loss: 0.9296\n",
      "Epoch 90/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7518 - val_loss: 0.9305\n",
      "Epoch 91/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7516 - val_loss: 0.9315\n",
      "Epoch 92/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7513 - val_loss: 0.9324\n",
      "Epoch 93/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7511 - val_loss: 0.9334\n",
      "Epoch 94/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7509 - val_loss: 0.9343\n",
      "Epoch 95/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7506 - val_loss: 0.9353\n",
      "Epoch 96/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7504 - val_loss: 0.9362\n",
      "Epoch 97/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7501 - val_loss: 0.9372\n",
      "Epoch 98/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7499 - val_loss: 0.9381\n",
      "Epoch 99/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7496 - val_loss: 0.9390\n",
      "Epoch 100/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7494 - val_loss: 0.9399\n",
      "Epoch 101/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7491 - val_loss: 0.9408\n",
      "Epoch 102/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7489 - val_loss: 0.9417\n",
      "Epoch 103/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7486 - val_loss: 0.9426\n",
      "Epoch 104/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7484 - val_loss: 0.9435\n",
      "Epoch 105/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7481 - val_loss: 0.9443\n",
      "Epoch 106/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7479 - val_loss: 0.9451\n",
      "Epoch 107/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7476 - val_loss: 0.9459\n",
      "Epoch 108/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7474 - val_loss: 0.9467\n",
      "Epoch 109/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7471 - val_loss: 0.9475\n",
      "Epoch 110/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7469 - val_loss: 0.9482\n",
      "Epoch 111/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7466 - val_loss: 0.9489\n",
      "Epoch 112/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7463 - val_loss: 0.9496\n",
      "Epoch 113/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7460 - val_loss: 0.9503\n",
      "Epoch 114/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7458 - val_loss: 0.9510\n",
      "Epoch 115/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7455 - val_loss: 0.9516\n",
      "Epoch 116/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7452 - val_loss: 0.9522\n",
      "Epoch 117/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7449 - val_loss: 0.9528\n",
      "Epoch 118/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7446 - val_loss: 0.9534\n",
      "Epoch 119/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7444 - val_loss: 0.9539\n",
      "Epoch 120/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7441 - val_loss: 0.9544\n",
      "Epoch 121/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7438 - val_loss: 0.9549\n",
      "Epoch 122/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7434 - val_loss: 0.9554\n",
      "Epoch 123/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7431 - val_loss: 0.9558\n",
      "Epoch 124/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7428 - val_loss: 0.9563\n",
      "Epoch 125/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7425 - val_loss: 0.9567\n",
      "Epoch 126/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7422 - val_loss: 0.9571\n",
      "Epoch 127/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7418 - val_loss: 0.9575\n",
      "Epoch 128/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7415 - val_loss: 0.9579\n",
      "Epoch 129/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7411 - val_loss: 0.9582\n",
      "Epoch 130/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7408 - val_loss: 0.9586\n",
      "Epoch 131/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7404 - val_loss: 0.9589\n",
      "Epoch 132/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7400 - val_loss: 0.9592\n",
      "Epoch 133/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7397 - val_loss: 0.9595\n",
      "Epoch 134/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7393 - val_loss: 0.9598\n",
      "Epoch 135/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7389 - val_loss: 0.9601\n",
      "Epoch 136/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7385 - val_loss: 0.9604\n",
      "Epoch 137/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7381 - val_loss: 0.9607\n",
      "Epoch 138/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7377 - val_loss: 0.9609\n",
      "Epoch 139/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7373 - val_loss: 0.9612\n",
      "Epoch 140/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7369 - val_loss: 0.9615\n",
      "Epoch 141/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7365 - val_loss: 0.9617\n",
      "Epoch 142/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7361 - val_loss: 0.9620\n",
      "Epoch 143/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7357 - val_loss: 0.9622\n",
      "Epoch 144/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7352 - val_loss: 0.9625\n",
      "Epoch 145/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7348 - val_loss: 0.9627\n",
      "Epoch 146/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7344 - val_loss: 0.9630\n",
      "Epoch 147/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7340 - val_loss: 0.9632\n",
      "Epoch 148/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7336 - val_loss: 0.9635\n",
      "Epoch 149/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7331 - val_loss: 0.9638\n",
      "Epoch 150/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7327 - val_loss: 0.9640\n",
      "Epoch 151/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7323 - val_loss: 0.9643\n",
      "Epoch 152/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7319 - val_loss: 0.9646\n",
      "Epoch 153/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7315 - val_loss: 0.9649\n",
      "Epoch 154/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7311 - val_loss: 0.9652\n",
      "Epoch 155/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7307 - val_loss: 0.9655\n",
      "Epoch 156/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7304 - val_loss: 0.9658\n",
      "Epoch 157/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7300 - val_loss: 0.9661\n",
      "Epoch 158/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7296 - val_loss: 0.9665\n",
      "Epoch 159/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7293 - val_loss: 0.9668\n",
      "Epoch 160/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7289 - val_loss: 0.9672\n",
      "Epoch 161/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7286 - val_loss: 0.9675\n",
      "Epoch 162/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7283 - val_loss: 0.9679\n",
      "Epoch 163/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7279 - val_loss: 0.9683\n",
      "Epoch 164/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7276 - val_loss: 0.9687\n",
      "Epoch 165/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7273 - val_loss: 0.9691\n",
      "Epoch 166/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7270 - val_loss: 0.9695\n",
      "Epoch 167/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7267 - val_loss: 0.9699\n",
      "Epoch 168/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7265 - val_loss: 0.9703\n",
      "Epoch 169/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7262 - val_loss: 0.9707\n",
      "Epoch 170/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7259 - val_loss: 0.9711\n",
      "Epoch 171/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7257 - val_loss: 0.9716\n",
      "Epoch 172/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7254 - val_loss: 0.9720\n",
      "Epoch 173/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7252 - val_loss: 0.9724\n",
      "Epoch 174/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7250 - val_loss: 0.9728\n",
      "Epoch 175/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7247 - val_loss: 0.9733\n",
      "Epoch 176/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7245 - val_loss: 0.9737\n",
      "Epoch 177/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7243 - val_loss: 0.9741\n",
      "Epoch 178/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7241 - val_loss: 0.9745\n",
      "Epoch 179/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7239 - val_loss: 0.9750\n",
      "Epoch 180/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7237 - val_loss: 0.9754\n",
      "Epoch 181/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7235 - val_loss: 0.9758\n",
      "Epoch 182/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7233 - val_loss: 0.9762\n",
      "Epoch 183/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7231 - val_loss: 0.9766\n",
      "Epoch 184/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7229 - val_loss: 0.9770\n",
      "Epoch 185/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7227 - val_loss: 0.9774\n",
      "Epoch 186/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7226 - val_loss: 0.9778\n",
      "Epoch 187/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7224 - val_loss: 0.9781\n",
      "Epoch 188/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7222 - val_loss: 0.9785\n",
      "Epoch 189/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7221 - val_loss: 0.9789\n",
      "Epoch 190/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7219 - val_loss: 0.9792\n",
      "Epoch 191/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7217 - val_loss: 0.9795\n",
      "Epoch 192/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7216 - val_loss: 0.9799\n",
      "Epoch 193/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7214 - val_loss: 0.9802\n",
      "Epoch 194/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7213 - val_loss: 0.9805\n",
      "Epoch 195/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7211 - val_loss: 0.9808\n",
      "Epoch 196/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7210 - val_loss: 0.9811\n",
      "Epoch 197/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7208 - val_loss: 0.9814\n",
      "Epoch 198/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7207 - val_loss: 0.9817\n",
      "Epoch 199/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7206 - val_loss: 0.9820\n",
      "Epoch 200/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7204 - val_loss: 0.9822\n",
      "Epoch 201/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7203 - val_loss: 0.9825\n",
      "Epoch 202/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7202 - val_loss: 0.9827\n",
      "Epoch 203/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7200 - val_loss: 0.9830\n",
      "Epoch 204/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7199 - val_loss: 0.9832\n",
      "Epoch 205/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7198 - val_loss: 0.9834\n",
      "Epoch 206/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7196 - val_loss: 0.9836\n",
      "Epoch 207/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7195 - val_loss: 0.9838\n",
      "Epoch 208/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7194 - val_loss: 0.9840\n",
      "Epoch 209/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7193 - val_loss: 0.9842\n",
      "Epoch 210/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7191 - val_loss: 0.9844\n",
      "Epoch 211/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7190 - val_loss: 0.9845\n",
      "Epoch 212/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7189 - val_loss: 0.9847\n",
      "Epoch 213/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7188 - val_loss: 0.9848\n",
      "Epoch 214/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7187 - val_loss: 0.9850\n",
      "Epoch 215/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7185 - val_loss: 0.9851\n",
      "Epoch 216/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7184 - val_loss: 0.9852\n",
      "Epoch 217/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7183 - val_loss: 0.9853\n",
      "Epoch 218/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7182 - val_loss: 0.9854\n",
      "Epoch 219/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7181 - val_loss: 0.9855\n",
      "Epoch 220/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7179 - val_loss: 0.9856\n",
      "Epoch 221/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7178 - val_loss: 0.9857\n",
      "Epoch 222/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7177 - val_loss: 0.9858\n",
      "Epoch 223/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7176 - val_loss: 0.9858\n",
      "Epoch 224/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7175 - val_loss: 0.9859\n",
      "Epoch 225/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7173 - val_loss: 0.9860\n",
      "Epoch 226/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7172 - val_loss: 0.9860\n",
      "Epoch 227/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7171 - val_loss: 0.9861\n",
      "Epoch 228/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7170 - val_loss: 0.9861\n",
      "Epoch 229/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7169 - val_loss: 0.9861\n",
      "Epoch 230/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7167 - val_loss: 0.9861\n",
      "Epoch 231/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7166 - val_loss: 0.9862\n",
      "Epoch 232/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7165 - val_loss: 0.9862\n",
      "Epoch 233/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7164 - val_loss: 0.9862\n",
      "Epoch 234/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7162 - val_loss: 0.9862\n",
      "Epoch 235/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7161 - val_loss: 0.9862\n",
      "Epoch 236/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7160 - val_loss: 0.9861\n",
      "Epoch 237/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7159 - val_loss: 0.9861\n",
      "Epoch 238/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7157 - val_loss: 0.9861\n",
      "Epoch 239/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7156 - val_loss: 0.9861\n",
      "Epoch 240/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7155 - val_loss: 0.9860\n",
      "Epoch 241/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7153 - val_loss: 0.9860\n",
      "Epoch 242/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7152 - val_loss: 0.9860\n",
      "Epoch 243/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7151 - val_loss: 0.9859\n",
      "Epoch 244/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7149 - val_loss: 0.9859\n",
      "Epoch 245/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7148 - val_loss: 0.9858\n",
      "Epoch 246/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7147 - val_loss: 0.9858\n",
      "Epoch 247/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7145 - val_loss: 0.9857\n",
      "Epoch 248/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7144 - val_loss: 0.9857\n",
      "Epoch 249/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7142 - val_loss: 0.9856\n",
      "Epoch 250/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7141 - val_loss: 0.9855\n",
      "Epoch 251/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7140 - val_loss: 0.9855\n",
      "Epoch 252/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7138 - val_loss: 0.9854\n",
      "Epoch 253/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7137 - val_loss: 0.9853\n",
      "Epoch 254/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7135 - val_loss: 0.9853\n",
      "Epoch 255/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7134 - val_loss: 0.9852\n",
      "Epoch 256/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7132 - val_loss: 0.9851\n",
      "Epoch 257/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7131 - val_loss: 0.9850\n",
      "Epoch 258/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7129 - val_loss: 0.9850\n",
      "Epoch 259/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7128 - val_loss: 0.9849\n",
      "Epoch 260/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7126 - val_loss: 0.9848\n",
      "Epoch 261/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7125 - val_loss: 0.9847\n",
      "Epoch 262/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7123 - val_loss: 0.9846\n",
      "Epoch 263/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7122 - val_loss: 0.9846\n",
      "Epoch 264/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7120 - val_loss: 0.9845\n",
      "Epoch 265/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7119 - val_loss: 0.9844\n",
      "Epoch 266/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7117 - val_loss: 0.9843\n",
      "Epoch 267/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7115 - val_loss: 0.9843\n",
      "Epoch 268/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7114 - val_loss: 0.9842\n",
      "Epoch 269/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7112 - val_loss: 0.9841\n",
      "Epoch 270/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7111 - val_loss: 0.9840\n",
      "Epoch 271/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7109 - val_loss: 0.9840\n",
      "Epoch 272/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7107 - val_loss: 0.9839\n",
      "Epoch 273/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7106 - val_loss: 0.9838\n",
      "Epoch 274/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7104 - val_loss: 0.9838\n",
      "Epoch 275/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7102 - val_loss: 0.9837\n",
      "Epoch 276/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7101 - val_loss: 0.9837\n",
      "Epoch 277/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7099 - val_loss: 0.9836\n",
      "Epoch 278/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7097 - val_loss: 0.9835\n",
      "Epoch 279/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7096 - val_loss: 0.9835\n",
      "Epoch 280/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7094 - val_loss: 0.9834\n",
      "Epoch 281/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7093 - val_loss: 0.9834\n",
      "Epoch 282/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7091 - val_loss: 0.9833\n",
      "Epoch 283/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7089 - val_loss: 0.9833\n",
      "Epoch 284/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7088 - val_loss: 0.9832\n",
      "Epoch 285/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7086 - val_loss: 0.9832\n",
      "Epoch 286/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7084 - val_loss: 0.9831\n",
      "Epoch 287/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7082 - val_loss: 0.9831\n",
      "Epoch 288/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7081 - val_loss: 0.9831\n",
      "Epoch 289/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7079 - val_loss: 0.9830\n",
      "Epoch 290/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7077 - val_loss: 0.9830\n",
      "Epoch 291/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7076 - val_loss: 0.9830\n",
      "Epoch 292/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7074 - val_loss: 0.9829\n",
      "Epoch 293/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7072 - val_loss: 0.9829\n",
      "Epoch 294/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7071 - val_loss: 0.9829\n",
      "Epoch 295/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7069 - val_loss: 0.9828\n",
      "Epoch 296/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7067 - val_loss: 0.9828\n",
      "Epoch 297/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7066 - val_loss: 0.9828\n",
      "Epoch 298/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7064 - val_loss: 0.9828\n",
      "Epoch 299/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7062 - val_loss: 0.9828\n",
      "Epoch 300/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7061 - val_loss: 0.9827\n",
      "Epoch 301/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7059 - val_loss: 0.9827\n",
      "Epoch 302/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7057 - val_loss: 0.9827\n",
      "Epoch 303/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7055 - val_loss: 0.9827\n",
      "Epoch 304/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7054 - val_loss: 0.9827\n",
      "Epoch 305/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7052 - val_loss: 0.9827\n",
      "Epoch 306/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7050 - val_loss: 0.9826\n",
      "Epoch 307/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7049 - val_loss: 0.9826\n",
      "Epoch 308/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7047 - val_loss: 0.9826\n",
      "Epoch 309/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7045 - val_loss: 0.9826\n",
      "Epoch 310/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7044 - val_loss: 0.9826\n",
      "Epoch 311/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7042 - val_loss: 0.9826\n",
      "Epoch 312/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7040 - val_loss: 0.9826\n",
      "Epoch 313/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7038 - val_loss: 0.9825\n",
      "Epoch 314/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7037 - val_loss: 0.9825\n",
      "Epoch 315/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7035 - val_loss: 0.9825\n",
      "Epoch 316/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7033 - val_loss: 0.9825\n",
      "Epoch 317/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7031 - val_loss: 0.9825\n",
      "Epoch 318/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7030 - val_loss: 0.9825\n",
      "Epoch 319/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7028 - val_loss: 0.9824\n",
      "Epoch 320/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7026 - val_loss: 0.9824\n",
      "Epoch 321/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7024 - val_loss: 0.9824\n",
      "Epoch 322/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7022 - val_loss: 0.9824\n",
      "Epoch 323/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7020 - val_loss: 0.9823\n",
      "Epoch 324/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7019 - val_loss: 0.9823\n",
      "Epoch 325/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7017 - val_loss: 0.9823\n",
      "Epoch 326/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 0.9823\n",
      "Epoch 327/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7013 - val_loss: 0.9822\n",
      "Epoch 328/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7011 - val_loss: 0.9822\n",
      "Epoch 329/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7009 - val_loss: 0.9821\n",
      "Epoch 330/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7007 - val_loss: 0.9821\n",
      "Epoch 331/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7005 - val_loss: 0.9820\n",
      "Epoch 332/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7003 - val_loss: 0.9820\n",
      "Epoch 333/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7001 - val_loss: 0.9819\n",
      "Epoch 334/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6999 - val_loss: 0.9819\n",
      "Epoch 335/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6997 - val_loss: 0.9818\n",
      "Epoch 336/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6995 - val_loss: 0.9817\n",
      "Epoch 337/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6993 - val_loss: 0.9817\n",
      "Epoch 338/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6990 - val_loss: 0.9816\n",
      "Epoch 339/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6988 - val_loss: 0.9815\n",
      "Epoch 340/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6986 - val_loss: 0.9814\n",
      "Epoch 341/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6984 - val_loss: 0.9813\n",
      "Epoch 342/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6982 - val_loss: 0.9812\n",
      "Epoch 343/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6979 - val_loss: 0.9811\n",
      "Epoch 344/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6977 - val_loss: 0.9810\n",
      "Epoch 345/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6975 - val_loss: 0.9809\n",
      "Epoch 346/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6972 - val_loss: 0.9808\n",
      "Epoch 347/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6970 - val_loss: 0.9806\n",
      "Epoch 348/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6967 - val_loss: 0.9805\n",
      "Epoch 349/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6965 - val_loss: 0.9803\n",
      "Epoch 350/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6962 - val_loss: 0.9802\n",
      "Epoch 351/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 0.9800\n",
      "Epoch 352/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6957 - val_loss: 0.9798\n",
      "Epoch 353/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6954 - val_loss: 0.9797\n",
      "Epoch 354/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6952 - val_loss: 0.9795\n",
      "Epoch 355/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6949 - val_loss: 0.9792\n",
      "Epoch 356/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6946 - val_loss: 0.9790\n",
      "Epoch 357/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6944 - val_loss: 0.9788\n",
      "Epoch 358/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6941 - val_loss: 0.9785\n",
      "Epoch 359/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6938 - val_loss: 0.9783\n",
      "Epoch 360/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6935 - val_loss: 0.9780\n",
      "Epoch 361/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6932 - val_loss: 0.9777\n",
      "Epoch 362/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6929 - val_loss: 0.9774\n",
      "Epoch 363/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6926 - val_loss: 0.9770\n",
      "Epoch 364/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6923 - val_loss: 0.9767\n",
      "Epoch 365/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6920 - val_loss: 0.9763\n",
      "Epoch 366/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6917 - val_loss: 0.9759\n",
      "Epoch 367/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6914 - val_loss: 0.9754\n",
      "Epoch 368/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6911 - val_loss: 0.9750\n",
      "Epoch 369/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6908 - val_loss: 0.9745\n",
      "Epoch 370/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6905 - val_loss: 0.9740\n",
      "Epoch 371/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6902 - val_loss: 0.9734\n",
      "Epoch 372/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.9728\n",
      "Epoch 373/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6895 - val_loss: 0.9722\n",
      "Epoch 374/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6892 - val_loss: 0.9715\n",
      "Epoch 375/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6888 - val_loss: 0.9708\n",
      "Epoch 376/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6885 - val_loss: 0.9701\n",
      "Epoch 377/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6882 - val_loss: 0.9693\n",
      "Epoch 378/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6878 - val_loss: 0.9684\n",
      "Epoch 379/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6874 - val_loss: 0.9675\n",
      "Epoch 380/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6871 - val_loss: 0.9665\n",
      "Epoch 381/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6867 - val_loss: 0.9654\n",
      "Epoch 382/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6863 - val_loss: 0.9643\n",
      "Epoch 383/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6859 - val_loss: 0.9631\n",
      "Epoch 384/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6855 - val_loss: 0.9618\n",
      "Epoch 385/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6851 - val_loss: 0.9605\n",
      "Epoch 386/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6846 - val_loss: 0.9590\n",
      "Epoch 387/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6841 - val_loss: 0.9574\n",
      "Epoch 388/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6837 - val_loss: 0.9558\n",
      "Epoch 389/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6831 - val_loss: 0.9540\n",
      "Epoch 390/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6826 - val_loss: 0.9521\n",
      "Epoch 391/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6820 - val_loss: 0.9501\n",
      "Epoch 392/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6814 - val_loss: 0.9480\n",
      "Epoch 393/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6807 - val_loss: 0.9458\n",
      "Epoch 394/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6800 - val_loss: 0.9434\n",
      "Epoch 395/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6793 - val_loss: 0.9410\n",
      "Epoch 396/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6785 - val_loss: 0.9384\n",
      "Epoch 397/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6777 - val_loss: 0.9356\n",
      "Epoch 398/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6768 - val_loss: 0.9328\n",
      "Epoch 399/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6759 - val_loss: 0.9299\n",
      "Epoch 400/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6749 - val_loss: 0.9268\n",
      "Epoch 401/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6739 - val_loss: 0.9237\n",
      "Epoch 402/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6729 - val_loss: 0.9205\n",
      "Epoch 403/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6718 - val_loss: 0.9172\n",
      "Epoch 404/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6707 - val_loss: 0.9139\n",
      "Epoch 405/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6696 - val_loss: 0.9105\n",
      "Epoch 406/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6684 - val_loss: 0.9071\n",
      "Epoch 407/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6672 - val_loss: 0.9037\n",
      "Epoch 408/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6660 - val_loss: 0.9003\n",
      "Epoch 409/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6647 - val_loss: 0.8969\n",
      "Epoch 410/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6634 - val_loss: 0.8935\n",
      "Epoch 411/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6622 - val_loss: 0.8902\n",
      "Epoch 412/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6609 - val_loss: 0.8870\n",
      "Epoch 413/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6595 - val_loss: 0.8838\n",
      "Epoch 414/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6582 - val_loss: 0.8807\n",
      "Epoch 415/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6569 - val_loss: 0.8777\n",
      "Epoch 416/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6556 - val_loss: 0.8748\n",
      "Epoch 417/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6543 - val_loss: 0.8719\n",
      "Epoch 418/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6530 - val_loss: 0.8692\n",
      "Epoch 419/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6518 - val_loss: 0.8666\n",
      "Epoch 420/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6506 - val_loss: 0.8641\n",
      "Epoch 421/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6494 - val_loss: 0.8617\n",
      "Epoch 422/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6482 - val_loss: 0.8595\n",
      "Epoch 423/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6471 - val_loss: 0.8573\n",
      "Epoch 424/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6460 - val_loss: 0.8552\n",
      "Epoch 425/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6449 - val_loss: 0.8533\n",
      "Epoch 426/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6439 - val_loss: 0.8514\n",
      "Epoch 427/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6430 - val_loss: 0.8496\n",
      "Epoch 428/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6421 - val_loss: 0.8479\n",
      "Epoch 429/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6412 - val_loss: 0.8463\n",
      "Epoch 430/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6404 - val_loss: 0.8448\n",
      "Epoch 431/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6396 - val_loss: 0.8433\n",
      "Epoch 432/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6389 - val_loss: 0.8419\n",
      "Epoch 433/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6382 - val_loss: 0.8406\n",
      "Epoch 434/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6375 - val_loss: 0.8394\n",
      "Epoch 435/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6369 - val_loss: 0.8382\n",
      "Epoch 436/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6363 - val_loss: 0.8371\n",
      "Epoch 437/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6358 - val_loss: 0.8360\n",
      "Epoch 438/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6353 - val_loss: 0.8350\n",
      "Epoch 439/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6348 - val_loss: 0.8340\n",
      "Epoch 440/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6343 - val_loss: 0.8330\n",
      "Epoch 441/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6339 - val_loss: 0.8321\n",
      "Epoch 442/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6335 - val_loss: 0.8312\n",
      "Epoch 443/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6331 - val_loss: 0.8304\n",
      "Epoch 444/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6328 - val_loss: 0.8296\n",
      "Epoch 445/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6324 - val_loss: 0.8288\n",
      "Epoch 446/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6321 - val_loss: 0.8281\n",
      "Epoch 447/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6318 - val_loss: 0.8273\n",
      "Epoch 448/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6316 - val_loss: 0.8266\n",
      "Epoch 449/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8260\n",
      "Epoch 450/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8253\n",
      "Epoch 451/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8247\n",
      "Epoch 452/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8241\n",
      "Epoch 453/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.8235\n",
      "Epoch 454/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.8229\n",
      "Epoch 455/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.8224\n",
      "Epoch 456/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6300 - val_loss: 0.8218\n",
      "Epoch 457/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.8213\n",
      "Epoch 458/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.8208\n",
      "Epoch 459/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.8204\n",
      "Epoch 460/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.8199\n",
      "Epoch 461/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6293 - val_loss: 0.8194\n",
      "Epoch 462/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.8190\n",
      "Epoch 463/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.8186\n",
      "Epoch 464/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.8182\n",
      "Epoch 465/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8178\n",
      "Epoch 466/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8174\n",
      "Epoch 467/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.8170\n",
      "Epoch 468/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.8167\n",
      "Epoch 469/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8164\n",
      "Epoch 470/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8160\n",
      "Epoch 471/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8157\n",
      "Epoch 472/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8154\n",
      "Epoch 473/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8151\n",
      "Epoch 474/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8148\n",
      "Epoch 475/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8145\n",
      "Epoch 476/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8143\n",
      "Epoch 477/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.8140\n",
      "Epoch 478/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.8138\n",
      "Epoch 479/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8135\n",
      "Epoch 480/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8133\n",
      "Epoch 481/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8131\n",
      "Epoch 482/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8129\n",
      "Epoch 483/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8126\n",
      "Epoch 484/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8124\n",
      "Epoch 485/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8123\n",
      "Epoch 486/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8121\n",
      "Epoch 487/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8119\n",
      "Epoch 488/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8117\n",
      "Epoch 489/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8115\n",
      "Epoch 490/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8114\n",
      "Epoch 491/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.8112\n",
      "Epoch 492/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.8111\n",
      "Epoch 493/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.8109\n",
      "Epoch 494/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8108\n",
      "Epoch 495/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8107\n",
      "Epoch 496/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8105\n",
      "Epoch 497/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.8104\n",
      "Epoch 498/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.8103\n",
      "Epoch 499/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.8102\n",
      "Epoch 500/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.8100\n",
      "Epoch 501/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.8099\n",
      "Epoch 502/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6293 - val_loss: 0.8098\n",
      "Epoch 503/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6293 - val_loss: 0.8097\n",
      "Epoch 504/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6293 - val_loss: 0.8096\n",
      "Epoch 505/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.8095\n",
      "Epoch 506/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.8094\n",
      "Epoch 507/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6295 - val_loss: 0.8093\n",
      "Epoch 508/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6295 - val_loss: 0.8093\n",
      "Epoch 509/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.8092\n",
      "Epoch 510/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.8091\n",
      "Epoch 511/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.8090\n",
      "Epoch 512/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.8089\n",
      "Epoch 513/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.8089\n",
      "Epoch 514/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.8088\n",
      "Epoch 515/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.8087\n",
      "Epoch 516/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.8087\n",
      "Epoch 517/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.8086\n",
      "Epoch 518/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.8085\n",
      "Epoch 519/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6300 - val_loss: 0.8085\n",
      "Epoch 520/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6300 - val_loss: 0.8084\n",
      "Epoch 521/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6300 - val_loss: 0.8084\n",
      "Epoch 522/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.8083\n",
      "Epoch 523/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.8083\n",
      "Epoch 524/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.8082\n",
      "Epoch 525/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6302 - val_loss: 0.8082\n",
      "Epoch 526/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6302 - val_loss: 0.8081\n",
      "Epoch 527/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.8081\n",
      "Epoch 528/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.8080\n",
      "Epoch 529/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.8080\n",
      "Epoch 530/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.8079\n",
      "Epoch 531/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.8079\n",
      "Epoch 532/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.8079\n",
      "Epoch 533/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.8078\n",
      "Epoch 534/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.8078\n",
      "Epoch 535/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.8077\n",
      "Epoch 536/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8077\n",
      "Epoch 537/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8077\n",
      "Epoch 538/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8076\n",
      "Epoch 539/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8076\n",
      "Epoch 540/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.8076\n",
      "Epoch 541/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.8076\n",
      "Epoch 542/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.8075\n",
      "Epoch 543/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8075\n",
      "Epoch 544/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8075\n",
      "Epoch 545/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8074\n",
      "Epoch 546/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8074\n",
      "Epoch 547/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8074\n",
      "Epoch 548/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8074\n",
      "Epoch 549/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8073\n",
      "Epoch 550/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8073\n",
      "Epoch 551/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8073\n",
      "Epoch 552/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8073\n",
      "Epoch 553/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8073\n",
      "Epoch 554/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8072\n",
      "Epoch 555/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8072\n",
      "Epoch 556/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8072\n",
      "Epoch 557/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8072\n",
      "Epoch 558/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8072\n",
      "Epoch 559/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8071\n",
      "Epoch 560/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8071\n",
      "Epoch 561/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8071\n",
      "Epoch 562/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8071\n",
      "Epoch 563/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8071\n",
      "Epoch 564/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8071\n",
      "Epoch 565/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8070\n",
      "Epoch 566/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8070\n",
      "Epoch 567/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8070\n",
      "Epoch 568/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8070\n",
      "Epoch 569/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8070\n",
      "Epoch 570/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8070\n",
      "Epoch 571/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8070\n",
      "Epoch 572/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8069\n",
      "Epoch 573/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8069\n",
      "Epoch 574/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8069\n",
      "Epoch 575/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8069\n",
      "Epoch 576/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8069\n",
      "Epoch 577/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8069\n",
      "Epoch 578/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8069\n",
      "Epoch 579/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8068\n",
      "Epoch 580/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8068\n",
      "Epoch 581/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8068\n",
      "Epoch 582/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8068\n",
      "Epoch 583/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8068\n",
      "Epoch 584/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8068\n",
      "Epoch 585/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8068\n",
      "Epoch 586/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8068\n",
      "Epoch 587/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8067\n",
      "Epoch 588/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8067\n",
      "Epoch 589/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8067\n",
      "Epoch 590/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8067\n",
      "Epoch 591/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8067\n",
      "Epoch 592/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8067\n",
      "Epoch 593/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8067\n",
      "Epoch 594/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8066\n",
      "Epoch 595/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8066\n",
      "Epoch 596/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8066\n",
      "Epoch 597/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8066\n",
      "Epoch 598/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8066\n",
      "Epoch 599/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8066\n",
      "Epoch 600/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8066\n",
      "Epoch 601/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8066\n",
      "Epoch 602/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8065\n",
      "Epoch 603/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8065\n",
      "Epoch 604/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8065\n",
      "Epoch 605/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8065\n",
      "Epoch 606/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8065\n",
      "Epoch 607/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8065\n",
      "Epoch 608/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8064\n",
      "Epoch 609/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8064\n",
      "Epoch 610/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8064\n",
      "Epoch 611/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8064\n",
      "Epoch 612/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8064\n",
      "Epoch 613/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8064\n",
      "Epoch 614/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8063\n",
      "Epoch 615/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8063\n",
      "Epoch 616/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8063\n",
      "Epoch 617/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8063\n",
      "Epoch 618/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8063\n",
      "Epoch 619/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8063\n",
      "Epoch 620/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8062\n",
      "Epoch 621/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8062\n",
      "Epoch 622/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8062\n",
      "Epoch 623/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8062\n",
      "Epoch 624/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8062\n",
      "Epoch 625/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8061\n",
      "Epoch 626/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8061\n",
      "Epoch 627/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8061\n",
      "Epoch 628/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.8061\n",
      "Epoch 629/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.8061\n",
      "Epoch 630/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.8060\n",
      "Epoch 631/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.8060\n",
      "Epoch 632/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8060\n",
      "Epoch 633/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8060\n",
      "Epoch 634/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8059\n",
      "Epoch 635/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8059\n",
      "Epoch 636/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.8059\n",
      "Epoch 637/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.8059\n",
      "Epoch 638/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.8059\n",
      "Epoch 639/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.8058\n",
      "Epoch 640/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.8058\n",
      "Epoch 641/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.8058\n",
      "Epoch 642/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.8058\n",
      "Epoch 643/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.8057\n",
      "Epoch 644/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.8057\n",
      "Epoch 645/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.8057\n",
      "Epoch 646/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.8057\n",
      "Epoch 647/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.8056\n",
      "Epoch 648/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6302 - val_loss: 0.8056\n",
      "Epoch 649/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6302 - val_loss: 0.8056\n",
      "Epoch 650/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6302 - val_loss: 0.8056\n",
      "Epoch 651/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.8055\n",
      "Epoch 652/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.8055\n",
      "Epoch 653/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.8055\n",
      "Epoch 654/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6300 - val_loss: 0.8054\n",
      "Epoch 655/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6300 - val_loss: 0.8054\n",
      "Epoch 656/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6300 - val_loss: 0.8054\n",
      "Epoch 657/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.8054\n",
      "Epoch 658/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.8053\n",
      "Epoch 659/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.8053\n",
      "Epoch 660/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.8053\n",
      "Epoch 661/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.8052\n",
      "Epoch 662/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.8052\n",
      "Epoch 663/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.8052\n",
      "Epoch 664/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.8051\n",
      "Epoch 665/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.8051\n",
      "Epoch 666/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.8051\n",
      "Epoch 667/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.8051\n",
      "Epoch 668/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.8050\n",
      "Epoch 669/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6295 - val_loss: 0.8050\n",
      "Epoch 670/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6295 - val_loss: 0.8050\n",
      "Epoch 671/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6295 - val_loss: 0.8049\n",
      "Epoch 672/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.8049\n",
      "Epoch 673/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.8049\n",
      "Epoch 674/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.8048\n",
      "Epoch 675/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6293 - val_loss: 0.8048\n",
      "Epoch 676/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6293 - val_loss: 0.8048\n",
      "Epoch 677/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6293 - val_loss: 0.8047\n",
      "Epoch 678/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.8047\n",
      "Epoch 679/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.8047\n",
      "Epoch 680/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.8046\n",
      "Epoch 681/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.8046\n",
      "Epoch 682/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.8046\n",
      "Epoch 683/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8045\n",
      "Epoch 684/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8045\n",
      "Epoch 685/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.8045\n",
      "Epoch 686/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.8045\n",
      "Epoch 687/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.8044\n",
      "Epoch 688/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8044\n",
      "Epoch 689/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8044\n",
      "Epoch 690/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8043\n",
      "Epoch 691/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8043\n",
      "Epoch 692/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8043\n",
      "Epoch 693/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.8042\n",
      "Epoch 694/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.8042\n",
      "Epoch 695/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6285 - val_loss: 0.8042\n",
      "Epoch 696/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6285 - val_loss: 0.8041\n",
      "Epoch 697/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6285 - val_loss: 0.8041\n",
      "Epoch 698/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6284 - val_loss: 0.8041\n",
      "Epoch 699/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6284 - val_loss: 0.8040\n",
      "Epoch 700/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6283 - val_loss: 0.8040\n",
      "Epoch 701/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6283 - val_loss: 0.8040\n",
      "Epoch 702/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6283 - val_loss: 0.8039\n",
      "Epoch 703/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6282 - val_loss: 0.8039\n",
      "Epoch 704/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6282 - val_loss: 0.8039\n",
      "Epoch 705/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6281 - val_loss: 0.8038\n",
      "Epoch 706/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6281 - val_loss: 0.8038\n",
      "Epoch 707/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6280 - val_loss: 0.8038\n",
      "Epoch 708/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6280 - val_loss: 0.8037\n",
      "Epoch 709/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6280 - val_loss: 0.8037\n",
      "Epoch 710/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6279 - val_loss: 0.8037\n",
      "Epoch 711/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6279 - val_loss: 0.8036\n",
      "Epoch 712/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6278 - val_loss: 0.8036\n",
      "Epoch 713/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6278 - val_loss: 0.8036\n",
      "Epoch 714/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6277 - val_loss: 0.8035\n",
      "Epoch 715/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6277 - val_loss: 0.8035\n",
      "Epoch 716/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6277 - val_loss: 0.8035\n",
      "Epoch 717/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6276 - val_loss: 0.8034\n",
      "Epoch 718/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6276 - val_loss: 0.8034\n",
      "Epoch 719/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6275 - val_loss: 0.8034\n",
      "Epoch 720/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6275 - val_loss: 0.8033\n",
      "Epoch 721/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6274 - val_loss: 0.8033\n",
      "Epoch 722/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6274 - val_loss: 0.8033\n",
      "Epoch 723/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6274 - val_loss: 0.8033\n",
      "Epoch 724/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6273 - val_loss: 0.8032\n",
      "Epoch 725/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6273 - val_loss: 0.8032\n",
      "Epoch 726/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6272 - val_loss: 0.8032\n",
      "Epoch 727/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6272 - val_loss: 0.8031\n",
      "Epoch 728/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6271 - val_loss: 0.8031\n",
      "Epoch 729/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6271 - val_loss: 0.8031\n",
      "Epoch 730/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6270 - val_loss: 0.8031\n",
      "Epoch 731/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6270 - val_loss: 0.8030\n",
      "Epoch 732/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6270 - val_loss: 0.8030\n",
      "Epoch 733/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6269 - val_loss: 0.8030\n",
      "Epoch 734/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6269 - val_loss: 0.8029\n",
      "Epoch 735/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6268 - val_loss: 0.8029\n",
      "Epoch 736/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6268 - val_loss: 0.8029\n",
      "Epoch 737/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6267 - val_loss: 0.8029\n",
      "Epoch 738/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6267 - val_loss: 0.8028\n",
      "Epoch 739/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6266 - val_loss: 0.8028\n",
      "Epoch 740/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6266 - val_loss: 0.8028\n",
      "Epoch 741/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6266 - val_loss: 0.8028\n",
      "Epoch 742/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6265 - val_loss: 0.8027\n",
      "Epoch 743/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6265 - val_loss: 0.8027\n",
      "Epoch 744/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.8027\n",
      "Epoch 745/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.8027\n",
      "Epoch 746/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6263 - val_loss: 0.8026\n",
      "Epoch 747/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6263 - val_loss: 0.8026\n",
      "Epoch 748/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6262 - val_loss: 0.8026\n",
      "Epoch 749/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6262 - val_loss: 0.8026\n",
      "Epoch 750/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6262 - val_loss: 0.8025\n",
      "Epoch 751/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6261 - val_loss: 0.8025\n",
      "Epoch 752/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6261 - val_loss: 0.8025\n",
      "Epoch 753/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6260 - val_loss: 0.8025\n",
      "Epoch 754/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6260 - val_loss: 0.8024\n",
      "Epoch 755/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6259 - val_loss: 0.8024\n",
      "Epoch 756/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6259 - val_loss: 0.8024\n",
      "Epoch 757/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6258 - val_loss: 0.8024\n",
      "Epoch 758/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6258 - val_loss: 0.8024\n",
      "Epoch 759/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6257 - val_loss: 0.8023\n",
      "Epoch 760/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6257 - val_loss: 0.8023\n",
      "Epoch 761/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6257 - val_loss: 0.8023\n",
      "Epoch 762/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6256 - val_loss: 0.8023\n",
      "Epoch 763/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6256 - val_loss: 0.8023\n",
      "Epoch 764/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6255 - val_loss: 0.8022\n",
      "Epoch 765/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6255 - val_loss: 0.8022\n",
      "Epoch 766/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6254 - val_loss: 0.8022\n",
      "Epoch 767/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6254 - val_loss: 0.8022\n",
      "Epoch 768/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6254 - val_loss: 0.8022\n",
      "Epoch 769/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6253 - val_loss: 0.8022\n",
      "Epoch 770/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6253 - val_loss: 0.8021\n",
      "Epoch 771/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6252 - val_loss: 0.8021\n",
      "Epoch 772/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6252 - val_loss: 0.8021\n",
      "Epoch 773/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6251 - val_loss: 0.8021\n",
      "Epoch 774/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6251 - val_loss: 0.8021\n",
      "Epoch 775/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.8021\n",
      "Epoch 776/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.8021\n",
      "Epoch 777/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.8020\n",
      "Epoch 778/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.8020\n",
      "Epoch 779/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.8020\n",
      "Epoch 780/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6248 - val_loss: 0.8020\n",
      "Epoch 781/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6248 - val_loss: 0.8020\n",
      "Epoch 782/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6247 - val_loss: 0.8020\n",
      "Epoch 783/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6247 - val_loss: 0.8020\n",
      "Epoch 784/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6247 - val_loss: 0.8020\n",
      "Epoch 785/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6246 - val_loss: 0.8019\n",
      "Epoch 786/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6246 - val_loss: 0.8019\n",
      "Epoch 787/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6245 - val_loss: 0.8019\n",
      "Epoch 788/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6245 - val_loss: 0.8019\n",
      "Epoch 789/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6244 - val_loss: 0.8019\n",
      "Epoch 790/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6244 - val_loss: 0.8019\n",
      "Epoch 791/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6244 - val_loss: 0.8019\n",
      "Epoch 792/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6243 - val_loss: 0.8019\n",
      "Epoch 793/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6243 - val_loss: 0.8019\n",
      "Epoch 794/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6242 - val_loss: 0.8019\n",
      "Epoch 795/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6242 - val_loss: 0.8019\n",
      "Epoch 796/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6241 - val_loss: 0.8019\n",
      "Epoch 797/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6241 - val_loss: 0.8018\n",
      "Epoch 798/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6241 - val_loss: 0.8018\n",
      "Epoch 799/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6240 - val_loss: 0.8018\n",
      "Epoch 800/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6240 - val_loss: 0.8018\n",
      "Epoch 801/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.8018\n",
      "Epoch 802/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.8018\n",
      "Epoch 803/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.8018\n",
      "Epoch 804/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6238 - val_loss: 0.8018\n",
      "Epoch 805/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6238 - val_loss: 0.8018\n",
      "Epoch 806/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.8018\n",
      "Epoch 807/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.8018\n",
      "Epoch 808/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.8018\n",
      "Epoch 809/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6236 - val_loss: 0.8018\n",
      "Epoch 810/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6236 - val_loss: 0.8018\n",
      "Epoch 811/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6235 - val_loss: 0.8018\n",
      "Epoch 812/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6235 - val_loss: 0.8018\n",
      "Epoch 813/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6235 - val_loss: 0.8018\n",
      "Epoch 814/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6234 - val_loss: 0.8018\n",
      "Epoch 815/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6234 - val_loss: 0.8018\n",
      "Epoch 816/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6233 - val_loss: 0.8018\n",
      "Epoch 817/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6233 - val_loss: 0.8018\n",
      "Epoch 818/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6233 - val_loss: 0.8018\n",
      "Epoch 819/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6232 - val_loss: 0.8018\n",
      "Epoch 820/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6232 - val_loss: 0.8018\n",
      "Epoch 821/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6231 - val_loss: 0.8018\n",
      "Epoch 822/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6231 - val_loss: 0.8018\n",
      "Epoch 823/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6231 - val_loss: 0.8018\n",
      "Epoch 824/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6230 - val_loss: 0.8018\n",
      "Epoch 825/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6230 - val_loss: 0.8018\n",
      "Epoch 826/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6230 - val_loss: 0.8018\n",
      "Epoch 827/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6229 - val_loss: 0.8018\n",
      "Epoch 828/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6229 - val_loss: 0.8018\n",
      "Epoch 829/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6228 - val_loss: 0.8019\n",
      "Epoch 830/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6228 - val_loss: 0.8019\n",
      "Epoch 831/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6228 - val_loss: 0.8019\n",
      "Epoch 832/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.8019\n",
      "Epoch 833/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.8019\n",
      "Epoch 834/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.8019\n",
      "Epoch 835/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6226 - val_loss: 0.8019\n",
      "Epoch 836/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6226 - val_loss: 0.8019\n",
      "Epoch 837/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6226 - val_loss: 0.8019\n",
      "Epoch 838/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6225 - val_loss: 0.8019\n",
      "Epoch 839/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6225 - val_loss: 0.8019\n",
      "Epoch 840/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6224 - val_loss: 0.8019\n",
      "Epoch 841/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6224 - val_loss: 0.8019\n",
      "Epoch 842/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6224 - val_loss: 0.8020\n",
      "Epoch 843/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6223 - val_loss: 0.8020\n",
      "Epoch 844/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6223 - val_loss: 0.8020\n",
      "Epoch 845/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6223 - val_loss: 0.8020\n",
      "Epoch 846/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6222 - val_loss: 0.8020\n",
      "Epoch 847/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6222 - val_loss: 0.8020\n",
      "Epoch 848/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6222 - val_loss: 0.8020\n",
      "Epoch 849/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6221 - val_loss: 0.8020\n",
      "Epoch 850/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6221 - val_loss: 0.8021\n",
      "Epoch 851/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6221 - val_loss: 0.8021\n",
      "Epoch 852/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6220 - val_loss: 0.8021\n",
      "Epoch 853/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6220 - val_loss: 0.8021\n",
      "Epoch 854/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6220 - val_loss: 0.8021\n",
      "Epoch 855/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6219 - val_loss: 0.8021\n",
      "Epoch 856/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6219 - val_loss: 0.8021\n",
      "Epoch 857/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6219 - val_loss: 0.8021\n",
      "Epoch 858/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6218 - val_loss: 0.8022\n",
      "Epoch 859/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6218 - val_loss: 0.8022\n",
      "Epoch 860/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6218 - val_loss: 0.8022\n",
      "Epoch 861/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6217 - val_loss: 0.8022\n",
      "Epoch 862/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6217 - val_loss: 0.8022\n",
      "Epoch 863/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6217 - val_loss: 0.8022\n",
      "Epoch 864/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6216 - val_loss: 0.8023\n",
      "Epoch 865/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6216 - val_loss: 0.8023\n",
      "Epoch 866/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6216 - val_loss: 0.8023\n",
      "Epoch 867/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6216 - val_loss: 0.8023\n",
      "Epoch 868/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6215 - val_loss: 0.8023\n",
      "Epoch 869/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6215 - val_loss: 0.8023\n",
      "Epoch 870/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6215 - val_loss: 0.8024\n",
      "Epoch 871/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6214 - val_loss: 0.8024\n",
      "Epoch 872/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6214 - val_loss: 0.8024\n",
      "Epoch 873/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6214 - val_loss: 0.8024\n",
      "Epoch 874/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6213 - val_loss: 0.8024\n",
      "Epoch 875/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6213 - val_loss: 0.8025\n",
      "Epoch 876/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6213 - val_loss: 0.8025\n",
      "Epoch 877/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6213 - val_loss: 0.8025\n",
      "Epoch 878/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6212 - val_loss: 0.8025\n",
      "Epoch 879/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6212 - val_loss: 0.8025\n",
      "Epoch 880/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6212 - val_loss: 0.8026\n",
      "Epoch 881/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6211 - val_loss: 0.8026\n",
      "Epoch 882/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6211 - val_loss: 0.8026\n",
      "Epoch 883/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6211 - val_loss: 0.8026\n",
      "Epoch 884/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6211 - val_loss: 0.8026\n",
      "Epoch 885/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6210 - val_loss: 0.8027\n",
      "Epoch 886/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6210 - val_loss: 0.8027\n",
      "Epoch 887/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6210 - val_loss: 0.8027\n",
      "Epoch 888/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6209 - val_loss: 0.8027\n",
      "Epoch 889/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6209 - val_loss: 0.8027\n",
      "Epoch 890/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6209 - val_loss: 0.8028\n",
      "Epoch 891/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6209 - val_loss: 0.8028\n",
      "Epoch 892/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6208 - val_loss: 0.8028\n",
      "Epoch 893/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6208 - val_loss: 0.8028\n",
      "Epoch 894/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6208 - val_loss: 0.8029\n",
      "Epoch 895/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6208 - val_loss: 0.8029\n",
      "Epoch 896/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6207 - val_loss: 0.8029\n",
      "Epoch 897/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6207 - val_loss: 0.8029\n",
      "Epoch 898/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6207 - val_loss: 0.8030\n",
      "Epoch 899/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6206 - val_loss: 0.8030\n",
      "Epoch 900/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6206 - val_loss: 0.8030\n",
      "Epoch 901/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6206 - val_loss: 0.8030\n",
      "Epoch 902/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6206 - val_loss: 0.8030\n",
      "Epoch 903/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6205 - val_loss: 0.8031\n",
      "Epoch 904/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6205 - val_loss: 0.8031\n",
      "Epoch 905/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6205 - val_loss: 0.8031\n",
      "Epoch 906/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6205 - val_loss: 0.8031\n",
      "Epoch 907/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 0.8032\n",
      "Epoch 908/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 0.8032\n",
      "Epoch 909/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 0.8032\n",
      "Epoch 910/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 0.8032\n",
      "Epoch 911/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 0.8033\n",
      "Epoch 912/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6203 - val_loss: 0.8033\n",
      "Epoch 913/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6203 - val_loss: 0.8033\n",
      "Epoch 914/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6203 - val_loss: 0.8034\n",
      "Epoch 915/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6203 - val_loss: 0.8034\n",
      "Epoch 916/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 0.8034\n",
      "Epoch 917/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 0.8034\n",
      "Epoch 918/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 0.8035\n",
      "Epoch 919/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 0.8035\n",
      "Epoch 920/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.8035\n",
      "Epoch 921/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.8035\n",
      "Epoch 922/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.8036\n",
      "Epoch 923/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.8036\n",
      "Epoch 924/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.8036\n",
      "Epoch 925/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.8037\n",
      "Epoch 926/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.8037\n",
      "Epoch 927/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.8037\n",
      "Epoch 928/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.8037\n",
      "Epoch 929/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.8038\n",
      "Epoch 930/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6199 - val_loss: 0.8038\n",
      "Epoch 931/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6199 - val_loss: 0.8038\n",
      "Epoch 932/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6199 - val_loss: 0.8038\n",
      "Epoch 933/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6199 - val_loss: 0.8039\n",
      "Epoch 934/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6198 - val_loss: 0.8039\n",
      "Epoch 935/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6198 - val_loss: 0.8039\n",
      "Epoch 936/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6198 - val_loss: 0.8040\n",
      "Epoch 937/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6198 - val_loss: 0.8040\n",
      "Epoch 938/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6198 - val_loss: 0.8040\n",
      "Epoch 939/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6197 - val_loss: 0.8040\n",
      "Epoch 940/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6197 - val_loss: 0.8041\n",
      "Epoch 941/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6197 - val_loss: 0.8041\n",
      "Epoch 942/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6197 - val_loss: 0.8041\n",
      "Epoch 943/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6197 - val_loss: 0.8042\n",
      "Epoch 944/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.8042\n",
      "Epoch 945/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.8042\n",
      "Epoch 946/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.8042\n",
      "Epoch 947/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.8043\n",
      "Epoch 948/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.8043\n",
      "Epoch 949/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.8043\n",
      "Epoch 950/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6195 - val_loss: 0.8044\n",
      "Epoch 951/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6195 - val_loss: 0.8044\n",
      "Epoch 952/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6195 - val_loss: 0.8044\n",
      "Epoch 953/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6195 - val_loss: 0.8045\n",
      "Epoch 954/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6195 - val_loss: 0.8045\n",
      "Epoch 955/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.8045\n",
      "Epoch 956/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.8045\n",
      "Epoch 957/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.8046\n",
      "Epoch 958/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.8046\n",
      "Epoch 959/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.8046\n",
      "Epoch 960/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.8047\n",
      "Epoch 961/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.8047\n",
      "Epoch 962/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.8047\n",
      "Epoch 963/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.8048\n",
      "Epoch 964/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.8048\n",
      "Epoch 965/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.8048\n",
      "Epoch 966/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6192 - val_loss: 0.8048\n",
      "Epoch 967/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6192 - val_loss: 0.8049\n",
      "Epoch 968/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6192 - val_loss: 0.8049\n",
      "Epoch 969/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6192 - val_loss: 0.8049\n",
      "Epoch 970/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6192 - val_loss: 0.8050\n",
      "Epoch 971/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6192 - val_loss: 0.8050\n",
      "Epoch 972/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.8050\n",
      "Epoch 973/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.8051\n",
      "Epoch 974/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.8051\n",
      "Epoch 975/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.8051\n",
      "Epoch 976/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.8052\n",
      "Epoch 977/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.8052\n",
      "Epoch 978/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.8052\n",
      "Epoch 979/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.8053\n",
      "Epoch 980/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.8053\n",
      "Epoch 981/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.8053\n",
      "Epoch 982/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.8053\n",
      "Epoch 983/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.8054\n",
      "Epoch 984/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.8054\n",
      "Epoch 985/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.8054\n",
      "Epoch 986/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.8055\n",
      "Epoch 987/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.8055\n",
      "Epoch 988/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.8055\n",
      "Epoch 989/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.8056\n",
      "Epoch 990/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.8056\n",
      "Epoch 991/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.8056\n",
      "Epoch 992/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.8057\n",
      "Epoch 993/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.8057\n",
      "Epoch 994/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.8057\n",
      "Epoch 995/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.8058\n",
      "Epoch 996/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.8058\n",
      "Epoch 997/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.8058\n",
      "Epoch 998/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6187 - val_loss: 0.8058\n",
      "Epoch 999/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6187 - val_loss: 0.8059\n",
      "Epoch 1000/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6187 - val_loss: 0.8059\n"
     ]
    }
   ],
   "source": [
    "epocas = 1000\n",
    "history= modelo2.fit(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size = lote,\n",
    "    epochs = epocas,\n",
    "    shuffle = False,\n",
    "    validation_data = (x_val,y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b592b210>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos multivariables (2 variables - Precio y mes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diesel = pd.read_csv('data/data_diesel_diff.csv', sep=',')\n",
    "data_diesel = data_diesel.drop(['anio'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_diesel_scaled = scaler.fit_transform(data_diesel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "entrenamiento = round(0.6 * len(data_diesel_scaled))\n",
    "val_prueba = round(0.2 * len(data_diesel_scaled))\n",
    "\n",
    "train = data_diesel_scaled[:entrenamiento]\n",
    "validation = data_diesel_scaled[entrenamiento:entrenamiento+val_prueba]\n",
    "test = data_diesel_scaled[entrenamiento+val_prueba:]\n",
    "\n",
    "train = np.insert(train, 0, [0, 0], axis=0)\n",
    "\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisada_multi(serie, retrasos=1):\n",
    "    serie_x = []\n",
    "    serie_y = []\n",
    "    for i in range(len(serie)-retrasos):\n",
    "        valor = serie[i:(i+retrasos), :]\n",
    "        valor_sig = serie[i+retrasos, :]\n",
    "        serie_x.append(valor)\n",
    "        serie_y.append(valor_sig[1])  \n",
    "    return np.array(serie_x), np.array(serie_y)\n",
    "\n",
    "x_train, y_train = supervisada_multi(train)\n",
    "x_val, y_val = supervisada_multi(validation)\n",
    "x_test, y_test = supervisada_multi(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, 2))\n",
    "x_val = np.reshape(x_val, (x_val.shape[0], 1, 2))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_33 (LSTM)              (1, 1)                    16        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (1, 1)                    2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18 (72.00 Byte)\n",
      "Trainable params: 18 (72.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo3 = Sequential()\n",
    "lote = 1\n",
    "paso = 1\n",
    "caracteristicas = 2\n",
    "modelo3.add(LSTM(lote, batch_input_shape=(lote, paso, caracteristicas), stateful=True))\n",
    "modelo3.add(Dense(1))\n",
    "modelo3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo3.compile(loss='mean_squared_error', optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "161/161 [==============================] - 1s 2ms/step - loss: 1.0946 - val_loss: 1.2915\n",
      "Epoch 2/1000\n",
      "161/161 [==============================] - 0s 914us/step - loss: 1.0776 - val_loss: 1.2733\n",
      "Epoch 3/1000\n",
      "161/161 [==============================] - 0s 806us/step - loss: 1.0635 - val_loss: 1.2579\n",
      "Epoch 4/1000\n",
      "161/161 [==============================] - 0s 793us/step - loss: 1.0516 - val_loss: 1.2451\n",
      "Epoch 5/1000\n",
      "161/161 [==============================] - 0s 836us/step - loss: 1.0417 - val_loss: 1.2345\n",
      "Epoch 6/1000\n",
      "161/161 [==============================] - 0s 932us/step - loss: 1.0335 - val_loss: 1.2258\n",
      "Epoch 7/1000\n",
      "161/161 [==============================] - 0s 913us/step - loss: 1.0267 - val_loss: 1.2187\n",
      "Epoch 8/1000\n",
      "161/161 [==============================] - 0s 840us/step - loss: 1.0211 - val_loss: 1.2128\n",
      "Epoch 9/1000\n",
      "161/161 [==============================] - 0s 845us/step - loss: 1.0164 - val_loss: 1.2078\n",
      "Epoch 10/1000\n",
      "161/161 [==============================] - 0s 886us/step - loss: 1.0121 - val_loss: 1.2034\n",
      "Epoch 11/1000\n",
      "161/161 [==============================] - 0s 785us/step - loss: 1.0080 - val_loss: 1.1992\n",
      "Epoch 12/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 1.0040 - val_loss: 1.1950\n",
      "Epoch 13/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.9998 - val_loss: 1.1907\n",
      "Epoch 14/1000\n",
      "161/161 [==============================] - 0s 801us/step - loss: 0.9955 - val_loss: 1.1861\n",
      "Epoch 15/1000\n",
      "161/161 [==============================] - 0s 871us/step - loss: 0.9910 - val_loss: 1.1812\n",
      "Epoch 16/1000\n",
      "161/161 [==============================] - 0s 869us/step - loss: 0.9862 - val_loss: 1.1759\n",
      "Epoch 17/1000\n",
      "161/161 [==============================] - 0s 902us/step - loss: 0.9812 - val_loss: 1.1702\n",
      "Epoch 18/1000\n",
      "161/161 [==============================] - 0s 820us/step - loss: 0.9759 - val_loss: 1.1640\n",
      "Epoch 19/1000\n",
      "161/161 [==============================] - 0s 895us/step - loss: 0.9702 - val_loss: 1.1572\n",
      "Epoch 20/1000\n",
      "161/161 [==============================] - 0s 778us/step - loss: 0.9639 - val_loss: 1.1498\n",
      "Epoch 21/1000\n",
      "161/161 [==============================] - 0s 781us/step - loss: 0.9570 - val_loss: 1.1419\n",
      "Epoch 22/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.9497 - val_loss: 1.1337\n",
      "Epoch 23/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.9420 - val_loss: 1.1252\n",
      "Epoch 24/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.9343 - val_loss: 1.1166\n",
      "Epoch 25/1000\n",
      "161/161 [==============================] - 0s 787us/step - loss: 0.9264 - val_loss: 1.1081\n",
      "Epoch 26/1000\n",
      "161/161 [==============================] - 0s 783us/step - loss: 0.9187 - val_loss: 1.0995\n",
      "Epoch 27/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.9110 - val_loss: 1.0911\n",
      "Epoch 28/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.9035 - val_loss: 1.0829\n",
      "Epoch 29/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.8962 - val_loss: 1.0749\n",
      "Epoch 30/1000\n",
      "161/161 [==============================] - 0s 861us/step - loss: 0.8891 - val_loss: 1.0671\n",
      "Epoch 31/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.8823 - val_loss: 1.0595\n",
      "Epoch 32/1000\n",
      "161/161 [==============================] - 0s 789us/step - loss: 0.8758 - val_loss: 1.0522\n",
      "Epoch 33/1000\n",
      "161/161 [==============================] - 0s 796us/step - loss: 0.8695 - val_loss: 1.0451\n",
      "Epoch 34/1000\n",
      "161/161 [==============================] - 0s 841us/step - loss: 0.8634 - val_loss: 1.0383\n",
      "Epoch 35/1000\n",
      "161/161 [==============================] - 0s 802us/step - loss: 0.8576 - val_loss: 1.0318\n",
      "Epoch 36/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.8521 - val_loss: 1.0255\n",
      "Epoch 37/1000\n",
      "161/161 [==============================] - 0s 796us/step - loss: 0.8468 - val_loss: 1.0194\n",
      "Epoch 38/1000\n",
      "161/161 [==============================] - 0s 797us/step - loss: 0.8417 - val_loss: 1.0136\n",
      "Epoch 39/1000\n",
      "161/161 [==============================] - 0s 797us/step - loss: 0.8369 - val_loss: 1.0080\n",
      "Epoch 40/1000\n",
      "161/161 [==============================] - 0s 876us/step - loss: 0.8322 - val_loss: 1.0026\n",
      "Epoch 41/1000\n",
      "161/161 [==============================] - 0s 830us/step - loss: 0.8278 - val_loss: 0.9974\n",
      "Epoch 42/1000\n",
      "161/161 [==============================] - 0s 788us/step - loss: 0.8236 - val_loss: 0.9924\n",
      "Epoch 43/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.8195 - val_loss: 0.9876\n",
      "Epoch 44/1000\n",
      "161/161 [==============================] - 0s 785us/step - loss: 0.8156 - val_loss: 0.9830\n",
      "Epoch 45/1000\n",
      "161/161 [==============================] - 0s 795us/step - loss: 0.8119 - val_loss: 0.9786\n",
      "Epoch 46/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.8084 - val_loss: 0.9744\n",
      "Epoch 47/1000\n",
      "161/161 [==============================] - 0s 838us/step - loss: 0.8050 - val_loss: 0.9703\n",
      "Epoch 48/1000\n",
      "161/161 [==============================] - 0s 939us/step - loss: 0.8018 - val_loss: 0.9664\n",
      "Epoch 49/1000\n",
      "161/161 [==============================] - 0s 973us/step - loss: 0.7986 - val_loss: 0.9626\n",
      "Epoch 50/1000\n",
      "161/161 [==============================] - 0s 849us/step - loss: 0.7957 - val_loss: 0.9590\n",
      "Epoch 51/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.7928 - val_loss: 0.9555\n",
      "Epoch 52/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.7901 - val_loss: 0.9521\n",
      "Epoch 53/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7874 - val_loss: 0.9489\n",
      "Epoch 54/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.7849 - val_loss: 0.9457\n",
      "Epoch 55/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.7825 - val_loss: 0.9427\n",
      "Epoch 56/1000\n",
      "161/161 [==============================] - 0s 779us/step - loss: 0.7801 - val_loss: 0.9398\n",
      "Epoch 57/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7779 - val_loss: 0.9370\n",
      "Epoch 58/1000\n",
      "161/161 [==============================] - 0s 854us/step - loss: 0.7757 - val_loss: 0.9343\n",
      "Epoch 59/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7736 - val_loss: 0.9317\n",
      "Epoch 60/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7716 - val_loss: 0.9292\n",
      "Epoch 61/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7697 - val_loss: 0.9267\n",
      "Epoch 62/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.7678 - val_loss: 0.9243\n",
      "Epoch 63/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.7660 - val_loss: 0.9220\n",
      "Epoch 64/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7643 - val_loss: 0.9198\n",
      "Epoch 65/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7626 - val_loss: 0.9177\n",
      "Epoch 66/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.7610 - val_loss: 0.9156\n",
      "Epoch 67/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7594 - val_loss: 0.9135\n",
      "Epoch 68/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7579 - val_loss: 0.9115\n",
      "Epoch 69/1000\n",
      "161/161 [==============================] - 0s 859us/step - loss: 0.7564 - val_loss: 0.9096\n",
      "Epoch 70/1000\n",
      "161/161 [==============================] - 0s 779us/step - loss: 0.7550 - val_loss: 0.9078\n",
      "Epoch 71/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.7536 - val_loss: 0.9059\n",
      "Epoch 72/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7522 - val_loss: 0.9042\n",
      "Epoch 73/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.7509 - val_loss: 0.9024\n",
      "Epoch 74/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.7496 - val_loss: 0.9008\n",
      "Epoch 75/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.7484 - val_loss: 0.8991\n",
      "Epoch 76/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7472 - val_loss: 0.8975\n",
      "Epoch 77/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7460 - val_loss: 0.8960\n",
      "Epoch 78/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.7449 - val_loss: 0.8944\n",
      "Epoch 79/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7438 - val_loss: 0.8929\n",
      "Epoch 80/1000\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.7427 - val_loss: 0.8915\n",
      "Epoch 81/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7417 - val_loss: 0.8901\n",
      "Epoch 82/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7406 - val_loss: 0.8887\n",
      "Epoch 83/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7397 - val_loss: 0.8873\n",
      "Epoch 84/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7387 - val_loss: 0.8860\n",
      "Epoch 85/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7377 - val_loss: 0.8847\n",
      "Epoch 86/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.7368 - val_loss: 0.8834\n",
      "Epoch 87/1000\n",
      "161/161 [==============================] - 0s 803us/step - loss: 0.7359 - val_loss: 0.8822\n",
      "Epoch 88/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7350 - val_loss: 0.8810\n",
      "Epoch 89/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7342 - val_loss: 0.8798\n",
      "Epoch 90/1000\n",
      "161/161 [==============================] - 0s 857us/step - loss: 0.7333 - val_loss: 0.8787\n",
      "Epoch 91/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7325 - val_loss: 0.8775\n",
      "Epoch 92/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.7317 - val_loss: 0.8764\n",
      "Epoch 93/1000\n",
      "161/161 [==============================] - 0s 796us/step - loss: 0.7309 - val_loss: 0.8753\n",
      "Epoch 94/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7302 - val_loss: 0.8743\n",
      "Epoch 95/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7294 - val_loss: 0.8733\n",
      "Epoch 96/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7287 - val_loss: 0.8722\n",
      "Epoch 97/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7280 - val_loss: 0.8713\n",
      "Epoch 98/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7273 - val_loss: 0.8703\n",
      "Epoch 99/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.7266 - val_loss: 0.8693\n",
      "Epoch 100/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7259 - val_loss: 0.8684\n",
      "Epoch 101/1000\n",
      "161/161 [==============================] - 0s 861us/step - loss: 0.7252 - val_loss: 0.8675\n",
      "Epoch 102/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.7246 - val_loss: 0.8666\n",
      "Epoch 103/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7239 - val_loss: 0.8658\n",
      "Epoch 104/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7233 - val_loss: 0.8649\n",
      "Epoch 105/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7227 - val_loss: 0.8641\n",
      "Epoch 106/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.7221 - val_loss: 0.8633\n",
      "Epoch 107/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7215 - val_loss: 0.8625\n",
      "Epoch 108/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7209 - val_loss: 0.8617\n",
      "Epoch 109/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7203 - val_loss: 0.8609\n",
      "Epoch 110/1000\n",
      "161/161 [==============================] - 0s 779us/step - loss: 0.7198 - val_loss: 0.8602\n",
      "Epoch 111/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7192 - val_loss: 0.8595\n",
      "Epoch 112/1000\n",
      "161/161 [==============================] - 0s 866us/step - loss: 0.7187 - val_loss: 0.8588\n",
      "Epoch 113/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.7181 - val_loss: 0.8581\n",
      "Epoch 114/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7176 - val_loss: 0.8574\n",
      "Epoch 115/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7171 - val_loss: 0.8567\n",
      "Epoch 116/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7166 - val_loss: 0.8561\n",
      "Epoch 117/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7161 - val_loss: 0.8554\n",
      "Epoch 118/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7156 - val_loss: 0.8548\n",
      "Epoch 119/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7151 - val_loss: 0.8542\n",
      "Epoch 120/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.7146 - val_loss: 0.8536\n",
      "Epoch 121/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7141 - val_loss: 0.8530\n",
      "Epoch 122/1000\n",
      "161/161 [==============================] - 0s 849us/step - loss: 0.7136 - val_loss: 0.8524\n",
      "Epoch 123/1000\n",
      "161/161 [==============================] - 0s 779us/step - loss: 0.7132 - val_loss: 0.8518\n",
      "Epoch 124/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7127 - val_loss: 0.8513\n",
      "Epoch 125/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7123 - val_loss: 0.8507\n",
      "Epoch 126/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7118 - val_loss: 0.8502\n",
      "Epoch 127/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7114 - val_loss: 0.8497\n",
      "Epoch 128/1000\n",
      "161/161 [==============================] - 0s 798us/step - loss: 0.7109 - val_loss: 0.8491\n",
      "Epoch 129/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7105 - val_loss: 0.8486\n",
      "Epoch 130/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7101 - val_loss: 0.8481\n",
      "Epoch 131/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7096 - val_loss: 0.8476\n",
      "Epoch 132/1000\n",
      "161/161 [==============================] - 0s 864us/step - loss: 0.7092 - val_loss: 0.8472\n",
      "Epoch 133/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7088 - val_loss: 0.8467\n",
      "Epoch 134/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7084 - val_loss: 0.8462\n",
      "Epoch 135/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7080 - val_loss: 0.8457\n",
      "Epoch 136/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7076 - val_loss: 0.8453\n",
      "Epoch 137/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7072 - val_loss: 0.8448\n",
      "Epoch 138/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7068 - val_loss: 0.8444\n",
      "Epoch 139/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7064 - val_loss: 0.8440\n",
      "Epoch 140/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7060 - val_loss: 0.8435\n",
      "Epoch 141/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7056 - val_loss: 0.8431\n",
      "Epoch 142/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7052 - val_loss: 0.8427\n",
      "Epoch 143/1000\n",
      "161/161 [==============================] - 0s 849us/step - loss: 0.7048 - val_loss: 0.8423\n",
      "Epoch 144/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7045 - val_loss: 0.8419\n",
      "Epoch 145/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7041 - val_loss: 0.8415\n",
      "Epoch 146/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7037 - val_loss: 0.8411\n",
      "Epoch 147/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7034 - val_loss: 0.8407\n",
      "Epoch 148/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7030 - val_loss: 0.8403\n",
      "Epoch 149/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7026 - val_loss: 0.8399\n",
      "Epoch 150/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7023 - val_loss: 0.8396\n",
      "Epoch 151/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7019 - val_loss: 0.8392\n",
      "Epoch 152/1000\n",
      "161/161 [==============================] - 0s 854us/step - loss: 0.7016 - val_loss: 0.8388\n",
      "Epoch 153/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7012 - val_loss: 0.8385\n",
      "Epoch 154/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7009 - val_loss: 0.8381\n",
      "Epoch 155/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7006 - val_loss: 0.8377\n",
      "Epoch 156/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7002 - val_loss: 0.8374\n",
      "Epoch 157/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6999 - val_loss: 0.8370\n",
      "Epoch 158/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6996 - val_loss: 0.8367\n",
      "Epoch 159/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6992 - val_loss: 0.8364\n",
      "Epoch 160/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.6989 - val_loss: 0.8360\n",
      "Epoch 161/1000\n",
      "161/161 [==============================] - 0s 856us/step - loss: 0.6986 - val_loss: 0.8357\n",
      "Epoch 162/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6983 - val_loss: 0.8354\n",
      "Epoch 163/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6980 - val_loss: 0.8350\n",
      "Epoch 164/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6976 - val_loss: 0.8347\n",
      "Epoch 165/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6973 - val_loss: 0.8344\n",
      "Epoch 166/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6970 - val_loss: 0.8341\n",
      "Epoch 167/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6967 - val_loss: 0.8338\n",
      "Epoch 168/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.6964 - val_loss: 0.8334\n",
      "Epoch 169/1000\n",
      "161/161 [==============================] - 0s 800us/step - loss: 0.6961 - val_loss: 0.8331\n",
      "Epoch 170/1000\n",
      "161/161 [==============================] - 0s 850us/step - loss: 0.6958 - val_loss: 0.8328\n",
      "Epoch 171/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.6955 - val_loss: 0.8325\n",
      "Epoch 172/1000\n",
      "161/161 [==============================] - 0s 779us/step - loss: 0.6953 - val_loss: 0.8322\n",
      "Epoch 173/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6950 - val_loss: 0.8319\n",
      "Epoch 174/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6947 - val_loss: 0.8316\n",
      "Epoch 175/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6944 - val_loss: 0.8313\n",
      "Epoch 176/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6941 - val_loss: 0.8310\n",
      "Epoch 177/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6939 - val_loss: 0.8308\n",
      "Epoch 178/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6936 - val_loss: 0.8305\n",
      "Epoch 179/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6933 - val_loss: 0.8302\n",
      "Epoch 180/1000\n",
      "161/161 [==============================] - 0s 847us/step - loss: 0.6931 - val_loss: 0.8299\n",
      "Epoch 181/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6928 - val_loss: 0.8296\n",
      "Epoch 182/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6926 - val_loss: 0.8294\n",
      "Epoch 183/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6923 - val_loss: 0.8291\n",
      "Epoch 184/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.6920 - val_loss: 0.8288\n",
      "Epoch 185/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.6918 - val_loss: 0.8286\n",
      "Epoch 186/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6916 - val_loss: 0.8283\n",
      "Epoch 187/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6913 - val_loss: 0.8280\n",
      "Epoch 188/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.6911 - val_loss: 0.8278\n",
      "Epoch 189/1000\n",
      "161/161 [==============================] - 0s 844us/step - loss: 0.6909 - val_loss: 0.8275\n",
      "Epoch 190/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6906 - val_loss: 0.8273\n",
      "Epoch 191/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6904 - val_loss: 0.8270\n",
      "Epoch 192/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6902 - val_loss: 0.8268\n",
      "Epoch 193/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6900 - val_loss: 0.8265\n",
      "Epoch 194/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6897 - val_loss: 0.8263\n",
      "Epoch 195/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.6895 - val_loss: 0.8261\n",
      "Epoch 196/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6893 - val_loss: 0.8258\n",
      "Epoch 197/1000\n",
      "161/161 [==============================] - 0s 822us/step - loss: 0.6891 - val_loss: 0.8256\n",
      "Epoch 198/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6889 - val_loss: 0.8254\n",
      "Epoch 199/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6887 - val_loss: 0.8251\n",
      "Epoch 200/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6885 - val_loss: 0.8249\n",
      "Epoch 201/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6883 - val_loss: 0.8247\n",
      "Epoch 202/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6881 - val_loss: 0.8245\n",
      "Epoch 203/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6879 - val_loss: 0.8242\n",
      "Epoch 204/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6878 - val_loss: 0.8240\n",
      "Epoch 205/1000\n",
      "161/161 [==============================] - 0s 806us/step - loss: 0.6876 - val_loss: 0.8238\n",
      "Epoch 206/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6874 - val_loss: 0.8236\n",
      "Epoch 207/1000\n",
      "161/161 [==============================] - 0s 853us/step - loss: 0.6872 - val_loss: 0.8234\n",
      "Epoch 208/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6871 - val_loss: 0.8232\n",
      "Epoch 209/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6869 - val_loss: 0.8230\n",
      "Epoch 210/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6867 - val_loss: 0.8228\n",
      "Epoch 211/1000\n",
      "161/161 [==============================] - 0s 778us/step - loss: 0.6866 - val_loss: 0.8226\n",
      "Epoch 212/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6864 - val_loss: 0.8224\n",
      "Epoch 213/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6863 - val_loss: 0.8222\n",
      "Epoch 214/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6861 - val_loss: 0.8220\n",
      "Epoch 215/1000\n",
      "161/161 [==============================] - 0s 851us/step - loss: 0.6860 - val_loss: 0.8218\n",
      "Epoch 216/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6858 - val_loss: 0.8216\n",
      "Epoch 217/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6857 - val_loss: 0.8214\n",
      "Epoch 218/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6856 - val_loss: 0.8212\n",
      "Epoch 219/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6854 - val_loss: 0.8210\n",
      "Epoch 220/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6853 - val_loss: 0.8208\n",
      "Epoch 221/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6852 - val_loss: 0.8206\n",
      "Epoch 222/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6851 - val_loss: 0.8205\n",
      "Epoch 223/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.6850 - val_loss: 0.8203\n",
      "Epoch 224/1000\n",
      "161/161 [==============================] - 0s 857us/step - loss: 0.6848 - val_loss: 0.8201\n",
      "Epoch 225/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6847 - val_loss: 0.8199\n",
      "Epoch 226/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6846 - val_loss: 0.8198\n",
      "Epoch 227/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6845 - val_loss: 0.8196\n",
      "Epoch 228/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6844 - val_loss: 0.8194\n",
      "Epoch 229/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.6843 - val_loss: 0.8193\n",
      "Epoch 230/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6843 - val_loss: 0.8191\n",
      "Epoch 231/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6842 - val_loss: 0.8189\n",
      "Epoch 232/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.6841 - val_loss: 0.8188\n",
      "Epoch 233/1000\n",
      "161/161 [==============================] - 0s 843us/step - loss: 0.6840 - val_loss: 0.8186\n",
      "Epoch 234/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6840 - val_loss: 0.8185\n",
      "Epoch 235/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.6839 - val_loss: 0.8183\n",
      "Epoch 236/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6838 - val_loss: 0.8182\n",
      "Epoch 237/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6838 - val_loss: 0.8180\n",
      "Epoch 238/1000\n",
      "161/161 [==============================] - 0s 797us/step - loss: 0.6837 - val_loss: 0.8179\n",
      "Epoch 239/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.6837 - val_loss: 0.8178\n",
      "Epoch 240/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.6837 - val_loss: 0.8176\n",
      "Epoch 241/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6837 - val_loss: 0.8175\n",
      "Epoch 242/1000\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.6836 - val_loss: 0.8174\n",
      "Epoch 243/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.6836 - val_loss: 0.8173\n",
      "Epoch 244/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6836 - val_loss: 0.8171\n",
      "Epoch 245/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6836 - val_loss: 0.8170\n",
      "Epoch 246/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6836 - val_loss: 0.8169\n",
      "Epoch 247/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6836 - val_loss: 0.8168\n",
      "Epoch 248/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6837 - val_loss: 0.8167\n",
      "Epoch 249/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6837 - val_loss: 0.8166\n",
      "Epoch 250/1000\n",
      "161/161 [==============================] - 0s 859us/step - loss: 0.6837 - val_loss: 0.8165\n",
      "Epoch 251/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6838 - val_loss: 0.8164\n",
      "Epoch 252/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6838 - val_loss: 0.8163\n",
      "Epoch 253/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6839 - val_loss: 0.8163\n",
      "Epoch 254/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.6839 - val_loss: 0.8162\n",
      "Epoch 255/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6840 - val_loss: 0.8161\n",
      "Epoch 256/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6841 - val_loss: 0.8161\n",
      "Epoch 257/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6842 - val_loss: 0.8160\n",
      "Epoch 258/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6842 - val_loss: 0.8160\n",
      "Epoch 259/1000\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.6843 - val_loss: 0.8159\n",
      "Epoch 260/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6844 - val_loss: 0.8159\n",
      "Epoch 261/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6845 - val_loss: 0.8159\n",
      "Epoch 262/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6847 - val_loss: 0.8159\n",
      "Epoch 263/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6848 - val_loss: 0.8159\n",
      "Epoch 264/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6849 - val_loss: 0.8159\n",
      "Epoch 265/1000\n",
      "161/161 [==============================] - 0s 796us/step - loss: 0.6850 - val_loss: 0.8159\n",
      "Epoch 266/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6852 - val_loss: 0.8159\n",
      "Epoch 267/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.6853 - val_loss: 0.8159\n",
      "Epoch 268/1000\n",
      "161/161 [==============================] - 0s 854us/step - loss: 0.6855 - val_loss: 0.8160\n",
      "Epoch 269/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6856 - val_loss: 0.8160\n",
      "Epoch 270/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6858 - val_loss: 0.8161\n",
      "Epoch 271/1000\n",
      "161/161 [==============================] - 0s 779us/step - loss: 0.6860 - val_loss: 0.8161\n",
      "Epoch 272/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6862 - val_loss: 0.8162\n",
      "Epoch 273/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6863 - val_loss: 0.8163\n",
      "Epoch 274/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6865 - val_loss: 0.8164\n",
      "Epoch 275/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6867 - val_loss: 0.8165\n",
      "Epoch 276/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6869 - val_loss: 0.8166\n",
      "Epoch 277/1000\n",
      "161/161 [==============================] - 0s 851us/step - loss: 0.6871 - val_loss: 0.8167\n",
      "Epoch 278/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6874 - val_loss: 0.8168\n",
      "Epoch 279/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6876 - val_loss: 0.8170\n",
      "Epoch 280/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.6878 - val_loss: 0.8171\n",
      "Epoch 281/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6881 - val_loss: 0.8173\n",
      "Epoch 282/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.6883 - val_loss: 0.8175\n",
      "Epoch 283/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.6886 - val_loss: 0.8176\n",
      "Epoch 284/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6888 - val_loss: 0.8178\n",
      "Epoch 285/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6891 - val_loss: 0.8180\n",
      "Epoch 286/1000\n",
      "161/161 [==============================] - 0s 853us/step - loss: 0.6894 - val_loss: 0.8182\n",
      "Epoch 287/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6897 - val_loss: 0.8185\n",
      "Epoch 288/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6900 - val_loss: 0.8187\n",
      "Epoch 289/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6903 - val_loss: 0.8189\n",
      "Epoch 290/1000\n",
      "161/161 [==============================] - 0s 811us/step - loss: 0.6906 - val_loss: 0.8192\n",
      "Epoch 291/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6910 - val_loss: 0.8194\n",
      "Epoch 292/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6913 - val_loss: 0.8197\n",
      "Epoch 293/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6917 - val_loss: 0.8200\n",
      "Epoch 294/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6921 - val_loss: 0.8202\n",
      "Epoch 295/1000\n",
      "161/161 [==============================] - 0s 845us/step - loss: 0.6924 - val_loss: 0.8205\n",
      "Epoch 296/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.6928 - val_loss: 0.8208\n",
      "Epoch 297/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6932 - val_loss: 0.8212\n",
      "Epoch 298/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6936 - val_loss: 0.8215\n",
      "Epoch 299/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6941 - val_loss: 0.8218\n",
      "Epoch 300/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6945 - val_loss: 0.8222\n",
      "Epoch 301/1000\n",
      "161/161 [==============================] - 0s 781us/step - loss: 0.6950 - val_loss: 0.8225\n",
      "Epoch 302/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6954 - val_loss: 0.8229\n",
      "Epoch 303/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6959 - val_loss: 0.8233\n",
      "Epoch 304/1000\n",
      "161/161 [==============================] - 0s 850us/step - loss: 0.6964 - val_loss: 0.8237\n",
      "Epoch 305/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6969 - val_loss: 0.8241\n",
      "Epoch 306/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6974 - val_loss: 0.8245\n",
      "Epoch 307/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6979 - val_loss: 0.8249\n",
      "Epoch 308/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.6985 - val_loss: 0.8254\n",
      "Epoch 309/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6990 - val_loss: 0.8258\n",
      "Epoch 310/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6996 - val_loss: 0.8263\n",
      "Epoch 311/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7002 - val_loss: 0.8268\n",
      "Epoch 312/1000\n",
      "161/161 [==============================] - 0s 849us/step - loss: 0.7007 - val_loss: 0.8273\n",
      "Epoch 313/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7013 - val_loss: 0.8278\n",
      "Epoch 314/1000\n",
      "161/161 [==============================] - 0s 802us/step - loss: 0.7019 - val_loss: 0.8283\n",
      "Epoch 315/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7025 - val_loss: 0.8288\n",
      "Epoch 316/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7032 - val_loss: 0.8294\n",
      "Epoch 317/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7038 - val_loss: 0.8299\n",
      "Epoch 318/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.7044 - val_loss: 0.8305\n",
      "Epoch 319/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7051 - val_loss: 0.8310\n",
      "Epoch 320/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7057 - val_loss: 0.8316\n",
      "Epoch 321/1000\n",
      "161/161 [==============================] - 0s 840us/step - loss: 0.7064 - val_loss: 0.8322\n",
      "Epoch 322/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7070 - val_loss: 0.8328\n",
      "Epoch 323/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7077 - val_loss: 0.8334\n",
      "Epoch 324/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.7084 - val_loss: 0.8340\n",
      "Epoch 325/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7090 - val_loss: 0.8346\n",
      "Epoch 326/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7097 - val_loss: 0.8352\n",
      "Epoch 327/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7104 - val_loss: 0.8359\n",
      "Epoch 328/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.7111 - val_loss: 0.8365\n",
      "Epoch 329/1000\n",
      "161/161 [==============================] - 0s 844us/step - loss: 0.7117 - val_loss: 0.8372\n",
      "Epoch 330/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7124 - val_loss: 0.8378\n",
      "Epoch 331/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7131 - val_loss: 0.8385\n",
      "Epoch 332/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7138 - val_loss: 0.8391\n",
      "Epoch 333/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.7145 - val_loss: 0.8398\n",
      "Epoch 334/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7152 - val_loss: 0.8405\n",
      "Epoch 335/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7158 - val_loss: 0.8412\n",
      "Epoch 336/1000\n",
      "161/161 [==============================] - 0s 848us/step - loss: 0.7165 - val_loss: 0.8418\n",
      "Epoch 337/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7172 - val_loss: 0.8425\n",
      "Epoch 338/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7179 - val_loss: 0.8432\n",
      "Epoch 339/1000\n",
      "161/161 [==============================] - 0s 797us/step - loss: 0.7186 - val_loss: 0.8439\n",
      "Epoch 340/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7192 - val_loss: 0.8446\n",
      "Epoch 341/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7199 - val_loss: 0.8453\n",
      "Epoch 342/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7206 - val_loss: 0.8460\n",
      "Epoch 343/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7213 - val_loss: 0.8466\n",
      "Epoch 344/1000\n",
      "161/161 [==============================] - 0s 852us/step - loss: 0.7219 - val_loss: 0.8473\n",
      "Epoch 345/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7226 - val_loss: 0.8480\n",
      "Epoch 346/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7232 - val_loss: 0.8487\n",
      "Epoch 347/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.7239 - val_loss: 0.8494\n",
      "Epoch 348/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7245 - val_loss: 0.8501\n",
      "Epoch 349/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7252 - val_loss: 0.8507\n",
      "Epoch 350/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7258 - val_loss: 0.8514\n",
      "Epoch 351/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7265 - val_loss: 0.8521\n",
      "Epoch 352/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.7271 - val_loss: 0.8528\n",
      "Epoch 353/1000\n",
      "161/161 [==============================] - 0s 856us/step - loss: 0.7277 - val_loss: 0.8534\n",
      "Epoch 354/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7284 - val_loss: 0.8541\n",
      "Epoch 355/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.7290 - val_loss: 0.8548\n",
      "Epoch 356/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7296 - val_loss: 0.8554\n",
      "Epoch 357/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7302 - val_loss: 0.8561\n",
      "Epoch 358/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.7308 - val_loss: 0.8567\n",
      "Epoch 359/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7314 - val_loss: 0.8574\n",
      "Epoch 360/1000\n",
      "161/161 [==============================] - 0s 905us/step - loss: 0.7320 - val_loss: 0.8580\n",
      "Epoch 361/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7326 - val_loss: 0.8586\n",
      "Epoch 362/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7332 - val_loss: 0.8593\n",
      "Epoch 363/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7338 - val_loss: 0.8599\n",
      "Epoch 364/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7344 - val_loss: 0.8605\n",
      "Epoch 365/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7350 - val_loss: 0.8611\n",
      "Epoch 366/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7355 - val_loss: 0.8617\n",
      "Epoch 367/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.7361 - val_loss: 0.8624\n",
      "Epoch 368/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7367 - val_loss: 0.8630\n",
      "Epoch 369/1000\n",
      "161/161 [==============================] - 0s 860us/step - loss: 0.7372 - val_loss: 0.8636\n",
      "Epoch 370/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7378 - val_loss: 0.8641\n",
      "Epoch 371/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7383 - val_loss: 0.8647\n",
      "Epoch 372/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7389 - val_loss: 0.8653\n",
      "Epoch 373/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.7394 - val_loss: 0.8659\n",
      "Epoch 374/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7399 - val_loss: 0.8665\n",
      "Epoch 375/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7405 - val_loss: 0.8670\n",
      "Epoch 376/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7410 - val_loss: 0.8676\n",
      "Epoch 377/1000\n",
      "161/161 [==============================] - 0s 842us/step - loss: 0.7415 - val_loss: 0.8682\n",
      "Epoch 378/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7421 - val_loss: 0.8687\n",
      "Epoch 379/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7426 - val_loss: 0.8693\n",
      "Epoch 380/1000\n",
      "161/161 [==============================] - 0s 797us/step - loss: 0.7431 - val_loss: 0.8698\n",
      "Epoch 381/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.7436 - val_loss: 0.8704\n",
      "Epoch 382/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7441 - val_loss: 0.8709\n",
      "Epoch 383/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7446 - val_loss: 0.8714\n",
      "Epoch 384/1000\n",
      "161/161 [==============================] - 0s 778us/step - loss: 0.7451 - val_loss: 0.8719\n",
      "Epoch 385/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.7456 - val_loss: 0.8725\n",
      "Epoch 386/1000\n",
      "161/161 [==============================] - 0s 833us/step - loss: 0.7461 - val_loss: 0.8730\n",
      "Epoch 387/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7466 - val_loss: 0.8735\n",
      "Epoch 388/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7471 - val_loss: 0.8740\n",
      "Epoch 389/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7476 - val_loss: 0.8745\n",
      "Epoch 390/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7481 - val_loss: 0.8750\n",
      "Epoch 391/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7486 - val_loss: 0.8755\n",
      "Epoch 392/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7490 - val_loss: 0.8760\n",
      "Epoch 393/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7495 - val_loss: 0.8765\n",
      "Epoch 394/1000\n",
      "161/161 [==============================] - 0s 851us/step - loss: 0.7500 - val_loss: 0.8769\n",
      "Epoch 395/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7504 - val_loss: 0.8774\n",
      "Epoch 396/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7509 - val_loss: 0.8779\n",
      "Epoch 397/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7514 - val_loss: 0.8784\n",
      "Epoch 398/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7518 - val_loss: 0.8788\n",
      "Epoch 399/1000\n",
      "161/161 [==============================] - 0s 802us/step - loss: 0.7523 - val_loss: 0.8793\n",
      "Epoch 400/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.7527 - val_loss: 0.8797\n",
      "Epoch 401/1000\n",
      "161/161 [==============================] - 0s 854us/step - loss: 0.7532 - val_loss: 0.8802\n",
      "Epoch 402/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7536 - val_loss: 0.8806\n",
      "Epoch 403/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7541 - val_loss: 0.8810\n",
      "Epoch 404/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7545 - val_loss: 0.8815\n",
      "Epoch 405/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7550 - val_loss: 0.8819\n",
      "Epoch 406/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7554 - val_loss: 0.8823\n",
      "Epoch 407/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7558 - val_loss: 0.8827\n",
      "Epoch 408/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7563 - val_loss: 0.8831\n",
      "Epoch 409/1000\n",
      "161/161 [==============================] - 0s 863us/step - loss: 0.7567 - val_loss: 0.8835\n",
      "Epoch 410/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7571 - val_loss: 0.8839\n",
      "Epoch 411/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7575 - val_loss: 0.8843\n",
      "Epoch 412/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7580 - val_loss: 0.8847\n",
      "Epoch 413/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7584 - val_loss: 0.8851\n",
      "Epoch 414/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7588 - val_loss: 0.8855\n",
      "Epoch 415/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7592 - val_loss: 0.8859\n",
      "Epoch 416/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7596 - val_loss: 0.8863\n",
      "Epoch 417/1000\n",
      "161/161 [==============================] - 0s 868us/step - loss: 0.7600 - val_loss: 0.8866\n",
      "Epoch 418/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7605 - val_loss: 0.8870\n",
      "Epoch 419/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7609 - val_loss: 0.8874\n",
      "Epoch 420/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7613 - val_loss: 0.8877\n",
      "Epoch 421/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7617 - val_loss: 0.8881\n",
      "Epoch 422/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.7621 - val_loss: 0.8884\n",
      "Epoch 423/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7625 - val_loss: 0.8888\n",
      "Epoch 424/1000\n",
      "161/161 [==============================] - 0s 849us/step - loss: 0.7629 - val_loss: 0.8891\n",
      "Epoch 425/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7633 - val_loss: 0.8895\n",
      "Epoch 426/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7637 - val_loss: 0.8898\n",
      "Epoch 427/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7641 - val_loss: 0.8902\n",
      "Epoch 428/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7645 - val_loss: 0.8905\n",
      "Epoch 429/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.7649 - val_loss: 0.8908\n",
      "Epoch 430/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7653 - val_loss: 0.8912\n",
      "Epoch 431/1000\n",
      "161/161 [==============================] - 0s 861us/step - loss: 0.7657 - val_loss: 0.8915\n",
      "Epoch 432/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7661 - val_loss: 0.8918\n",
      "Epoch 433/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7665 - val_loss: 0.8921\n",
      "Epoch 434/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7669 - val_loss: 0.8925\n",
      "Epoch 435/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.7674 - val_loss: 0.8928\n",
      "Epoch 436/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7678 - val_loss: 0.8931\n",
      "Epoch 437/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.7682 - val_loss: 0.8934\n",
      "Epoch 438/1000\n",
      "161/161 [==============================] - 0s 855us/step - loss: 0.7686 - val_loss: 0.8938\n",
      "Epoch 439/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7690 - val_loss: 0.8941\n",
      "Epoch 440/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7694 - val_loss: 0.8944\n",
      "Epoch 441/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7698 - val_loss: 0.8947\n",
      "Epoch 442/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7703 - val_loss: 0.8951\n",
      "Epoch 443/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7707 - val_loss: 0.8954\n",
      "Epoch 444/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7711 - val_loss: 0.8957\n",
      "Epoch 445/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7716 - val_loss: 0.8961\n",
      "Epoch 446/1000\n",
      "161/161 [==============================] - 0s 846us/step - loss: 0.7720 - val_loss: 0.8964\n",
      "Epoch 447/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7724 - val_loss: 0.8968\n",
      "Epoch 448/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7729 - val_loss: 0.8971\n",
      "Epoch 449/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.7733 - val_loss: 0.8975\n",
      "Epoch 450/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.7738 - val_loss: 0.8978\n",
      "Epoch 451/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.7742 - val_loss: 0.8982\n",
      "Epoch 452/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.7747 - val_loss: 0.8986\n",
      "Epoch 453/1000\n",
      "161/161 [==============================] - 0s 834us/step - loss: 0.7751 - val_loss: 0.8989\n",
      "Epoch 454/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7756 - val_loss: 0.8993\n",
      "Epoch 455/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7761 - val_loss: 0.8997\n",
      "Epoch 456/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.7765 - val_loss: 0.9001\n",
      "Epoch 457/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.7770 - val_loss: 0.9005\n",
      "Epoch 458/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.7775 - val_loss: 0.9010\n",
      "Epoch 459/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.7780 - val_loss: 0.9014\n",
      "Epoch 460/1000\n",
      "161/161 [==============================] - 0s 837us/step - loss: 0.7784 - val_loss: 0.9018\n",
      "Epoch 461/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7789 - val_loss: 0.9023\n",
      "Epoch 462/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7794 - val_loss: 0.9028\n",
      "Epoch 463/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7798 - val_loss: 0.9033\n",
      "Epoch 464/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7803 - val_loss: 0.9038\n",
      "Epoch 465/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.7808 - val_loss: 0.9043\n",
      "Epoch 466/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7812 - val_loss: 0.9048\n",
      "Epoch 467/1000\n",
      "161/161 [==============================] - 0s 847us/step - loss: 0.7817 - val_loss: 0.9053\n",
      "Epoch 468/1000\n",
      "161/161 [==============================] - 0s 810us/step - loss: 0.7821 - val_loss: 0.9059\n",
      "Epoch 469/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7826 - val_loss: 0.9065\n",
      "Epoch 470/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7830 - val_loss: 0.9071\n",
      "Epoch 471/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7834 - val_loss: 0.9077\n",
      "Epoch 472/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7838 - val_loss: 0.9083\n",
      "Epoch 473/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.7842 - val_loss: 0.9089\n",
      "Epoch 474/1000\n",
      "161/161 [==============================] - 0s 854us/step - loss: 0.7846 - val_loss: 0.9096\n",
      "Epoch 475/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7850 - val_loss: 0.9102\n",
      "Epoch 476/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7853 - val_loss: 0.9109\n",
      "Epoch 477/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7857 - val_loss: 0.9116\n",
      "Epoch 478/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7860 - val_loss: 0.9123\n",
      "Epoch 479/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7863 - val_loss: 0.9130\n",
      "Epoch 480/1000\n",
      "161/161 [==============================] - 0s 841us/step - loss: 0.7866 - val_loss: 0.9137\n",
      "Epoch 481/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.7869 - val_loss: 0.9144\n",
      "Epoch 482/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7872 - val_loss: 0.9151\n",
      "Epoch 483/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7874 - val_loss: 0.9158\n",
      "Epoch 484/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.7876 - val_loss: 0.9166\n",
      "Epoch 485/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7878 - val_loss: 0.9173\n",
      "Epoch 486/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7880 - val_loss: 0.9180\n",
      "Epoch 487/1000\n",
      "161/161 [==============================] - 0s 844us/step - loss: 0.7882 - val_loss: 0.9187\n",
      "Epoch 488/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.7883 - val_loss: 0.9194\n",
      "Epoch 489/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7885 - val_loss: 0.9201\n",
      "Epoch 490/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7886 - val_loss: 0.9208\n",
      "Epoch 491/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.7887 - val_loss: 0.9214\n",
      "Epoch 492/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.7887 - val_loss: 0.9221\n",
      "Epoch 493/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7888 - val_loss: 0.9227\n",
      "Epoch 494/1000\n",
      "161/161 [==============================] - 0s 847us/step - loss: 0.7888 - val_loss: 0.9233\n",
      "Epoch 495/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7888 - val_loss: 0.9239\n",
      "Epoch 496/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.7888 - val_loss: 0.9245\n",
      "Epoch 497/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7888 - val_loss: 0.9250\n",
      "Epoch 498/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7887 - val_loss: 0.9255\n",
      "Epoch 499/1000\n",
      "161/161 [==============================] - 0s 793us/step - loss: 0.7887 - val_loss: 0.9260\n",
      "Epoch 500/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7886 - val_loss: 0.9265\n",
      "Epoch 501/1000\n",
      "161/161 [==============================] - 0s 848us/step - loss: 0.7885 - val_loss: 0.9270\n",
      "Epoch 502/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7884 - val_loss: 0.9274\n",
      "Epoch 503/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7883 - val_loss: 0.9278\n",
      "Epoch 504/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7882 - val_loss: 0.9282\n",
      "Epoch 505/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7881 - val_loss: 0.9286\n",
      "Epoch 506/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.7879 - val_loss: 0.9289\n",
      "Epoch 507/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7878 - val_loss: 0.9292\n",
      "Epoch 508/1000\n",
      "161/161 [==============================] - 0s 863us/step - loss: 0.7876 - val_loss: 0.9295\n",
      "Epoch 509/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7874 - val_loss: 0.9298\n",
      "Epoch 510/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.7872 - val_loss: 0.9300\n",
      "Epoch 511/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7870 - val_loss: 0.9303\n",
      "Epoch 512/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7868 - val_loss: 0.9305\n",
      "Epoch 513/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7865 - val_loss: 0.9306\n",
      "Epoch 514/1000\n",
      "161/161 [==============================] - 0s 879us/step - loss: 0.7863 - val_loss: 0.9308\n",
      "Epoch 515/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7860 - val_loss: 0.9310\n",
      "Epoch 516/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.7858 - val_loss: 0.9311\n",
      "Epoch 517/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7855 - val_loss: 0.9312\n",
      "Epoch 518/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7852 - val_loss: 0.9313\n",
      "Epoch 519/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7849 - val_loss: 0.9313\n",
      "Epoch 520/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7846 - val_loss: 0.9314\n",
      "Epoch 521/1000\n",
      "161/161 [==============================] - 0s 863us/step - loss: 0.7843 - val_loss: 0.9314\n",
      "Epoch 522/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7840 - val_loss: 0.9314\n",
      "Epoch 523/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7837 - val_loss: 0.9314\n",
      "Epoch 524/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7833 - val_loss: 0.9314\n",
      "Epoch 525/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7829 - val_loss: 0.9313\n",
      "Epoch 526/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7826 - val_loss: 0.9312\n",
      "Epoch 527/1000\n",
      "161/161 [==============================] - 0s 829us/step - loss: 0.7822 - val_loss: 0.9312\n",
      "Epoch 528/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7818 - val_loss: 0.9310\n",
      "Epoch 529/1000\n",
      "161/161 [==============================] - 0s 800us/step - loss: 0.7814 - val_loss: 0.9309\n",
      "Epoch 530/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.7809 - val_loss: 0.9308\n",
      "Epoch 531/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7805 - val_loss: 0.9306\n",
      "Epoch 532/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7801 - val_loss: 0.9304\n",
      "Epoch 533/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7796 - val_loss: 0.9302\n",
      "Epoch 534/1000\n",
      "161/161 [==============================] - 0s 832us/step - loss: 0.7791 - val_loss: 0.9300\n",
      "Epoch 535/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7786 - val_loss: 0.9297\n",
      "Epoch 536/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7781 - val_loss: 0.9295\n",
      "Epoch 537/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7776 - val_loss: 0.9292\n",
      "Epoch 538/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7770 - val_loss: 0.9289\n",
      "Epoch 539/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7764 - val_loss: 0.9285\n",
      "Epoch 540/1000\n",
      "161/161 [==============================] - 0s 855us/step - loss: 0.7759 - val_loss: 0.9282\n",
      "Epoch 541/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7753 - val_loss: 0.9278\n",
      "Epoch 542/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7746 - val_loss: 0.9274\n",
      "Epoch 543/1000\n",
      "161/161 [==============================] - 0s 793us/step - loss: 0.7740 - val_loss: 0.9270\n",
      "Epoch 544/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.7733 - val_loss: 0.9265\n",
      "Epoch 545/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7726 - val_loss: 0.9261\n",
      "Epoch 546/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.7719 - val_loss: 0.9256\n",
      "Epoch 547/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7712 - val_loss: 0.9251\n",
      "Epoch 548/1000\n",
      "161/161 [==============================] - 0s 851us/step - loss: 0.7704 - val_loss: 0.9245\n",
      "Epoch 549/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.7696 - val_loss: 0.9239\n",
      "Epoch 550/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7688 - val_loss: 0.9233\n",
      "Epoch 551/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7680 - val_loss: 0.9227\n",
      "Epoch 552/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7671 - val_loss: 0.9221\n",
      "Epoch 553/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7662 - val_loss: 0.9214\n",
      "Epoch 554/1000\n",
      "161/161 [==============================] - 0s 850us/step - loss: 0.7652 - val_loss: 0.9207\n",
      "Epoch 555/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.7643 - val_loss: 0.9199\n",
      "Epoch 556/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7633 - val_loss: 0.9192\n",
      "Epoch 557/1000\n",
      "161/161 [==============================] - 0s 803us/step - loss: 0.7622 - val_loss: 0.9184\n",
      "Epoch 558/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7612 - val_loss: 0.9175\n",
      "Epoch 559/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7601 - val_loss: 0.9167\n",
      "Epoch 560/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7589 - val_loss: 0.9158\n",
      "Epoch 561/1000\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.7578 - val_loss: 0.9149\n",
      "Epoch 562/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7565 - val_loss: 0.9139\n",
      "Epoch 563/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.7553 - val_loss: 0.9129\n",
      "Epoch 564/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7540 - val_loss: 0.9119\n",
      "Epoch 565/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7527 - val_loss: 0.9109\n",
      "Epoch 566/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.7513 - val_loss: 0.9098\n",
      "Epoch 567/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7499 - val_loss: 0.9087\n",
      "Epoch 568/1000\n",
      "161/161 [==============================] - 0s 846us/step - loss: 0.7484 - val_loss: 0.9076\n",
      "Epoch 569/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7469 - val_loss: 0.9065\n",
      "Epoch 570/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.7454 - val_loss: 0.9053\n",
      "Epoch 571/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7438 - val_loss: 0.9041\n",
      "Epoch 572/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7422 - val_loss: 0.9029\n",
      "Epoch 573/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7406 - val_loss: 0.9016\n",
      "Epoch 574/1000\n",
      "161/161 [==============================] - 0s 815us/step - loss: 0.7389 - val_loss: 0.9004\n",
      "Epoch 575/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7372 - val_loss: 0.8991\n",
      "Epoch 576/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.7355 - val_loss: 0.8978\n",
      "Epoch 577/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7338 - val_loss: 0.8965\n",
      "Epoch 578/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.7320 - val_loss: 0.8953\n",
      "Epoch 579/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.7303 - val_loss: 0.8940\n",
      "Epoch 580/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7285 - val_loss: 0.8927\n",
      "Epoch 581/1000\n",
      "161/161 [==============================] - 0s 850us/step - loss: 0.7268 - val_loss: 0.8914\n",
      "Epoch 582/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.7250 - val_loss: 0.8901\n",
      "Epoch 583/1000\n",
      "161/161 [==============================] - 0s 784us/step - loss: 0.7233 - val_loss: 0.8888\n",
      "Epoch 584/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.7216 - val_loss: 0.8875\n",
      "Epoch 585/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.7198 - val_loss: 0.8862\n",
      "Epoch 586/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.7182 - val_loss: 0.8850\n",
      "Epoch 587/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7165 - val_loss: 0.8837\n",
      "Epoch 588/1000\n",
      "161/161 [==============================] - 0s 850us/step - loss: 0.7149 - val_loss: 0.8825\n",
      "Epoch 589/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7133 - val_loss: 0.8813\n",
      "Epoch 590/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7118 - val_loss: 0.8801\n",
      "Epoch 591/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.7102 - val_loss: 0.8790\n",
      "Epoch 592/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.7088 - val_loss: 0.8778\n",
      "Epoch 593/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.7073 - val_loss: 0.8767\n",
      "Epoch 594/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7059 - val_loss: 0.8756\n",
      "Epoch 595/1000\n",
      "161/161 [==============================] - 0s 889us/step - loss: 0.7045 - val_loss: 0.8745\n",
      "Epoch 596/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.7032 - val_loss: 0.8734\n",
      "Epoch 597/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.7018 - val_loss: 0.8723\n",
      "Epoch 598/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.7005 - val_loss: 0.8712\n",
      "Epoch 599/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6992 - val_loss: 0.8701\n",
      "Epoch 600/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6980 - val_loss: 0.8691\n",
      "Epoch 601/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6967 - val_loss: 0.8680\n",
      "Epoch 602/1000\n",
      "161/161 [==============================] - 0s 852us/step - loss: 0.6955 - val_loss: 0.8670\n",
      "Epoch 603/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6943 - val_loss: 0.8660\n",
      "Epoch 604/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6931 - val_loss: 0.8649\n",
      "Epoch 605/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.6920 - val_loss: 0.8639\n",
      "Epoch 606/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6908 - val_loss: 0.8629\n",
      "Epoch 607/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6897 - val_loss: 0.8619\n",
      "Epoch 608/1000\n",
      "161/161 [==============================] - 0s 790us/step - loss: 0.6886 - val_loss: 0.8609\n",
      "Epoch 609/1000\n",
      "161/161 [==============================] - 0s 845us/step - loss: 0.6874 - val_loss: 0.8599\n",
      "Epoch 610/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6864 - val_loss: 0.8589\n",
      "Epoch 611/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6853 - val_loss: 0.8579\n",
      "Epoch 612/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6842 - val_loss: 0.8570\n",
      "Epoch 613/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6832 - val_loss: 0.8560\n",
      "Epoch 614/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6821 - val_loss: 0.8551\n",
      "Epoch 615/1000\n",
      "161/161 [==============================] - 0s 855us/step - loss: 0.6811 - val_loss: 0.8541\n",
      "Epoch 616/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6801 - val_loss: 0.8532\n",
      "Epoch 617/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6791 - val_loss: 0.8523\n",
      "Epoch 618/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.6781 - val_loss: 0.8513\n",
      "Epoch 619/1000\n",
      "161/161 [==============================] - 0s 800us/step - loss: 0.6771 - val_loss: 0.8504\n",
      "Epoch 620/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6762 - val_loss: 0.8495\n",
      "Epoch 621/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6752 - val_loss: 0.8486\n",
      "Epoch 622/1000\n",
      "161/161 [==============================] - 0s 859us/step - loss: 0.6743 - val_loss: 0.8478\n",
      "Epoch 623/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.6734 - val_loss: 0.8469\n",
      "Epoch 624/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6725 - val_loss: 0.8460\n",
      "Epoch 625/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6716 - val_loss: 0.8452\n",
      "Epoch 626/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6707 - val_loss: 0.8443\n",
      "Epoch 627/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6699 - val_loss: 0.8435\n",
      "Epoch 628/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6690 - val_loss: 0.8427\n",
      "Epoch 629/1000\n",
      "161/161 [==============================] - 0s 845us/step - loss: 0.6682 - val_loss: 0.8419\n",
      "Epoch 630/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6673 - val_loss: 0.8411\n",
      "Epoch 631/1000\n",
      "161/161 [==============================] - 0s 794us/step - loss: 0.6665 - val_loss: 0.8403\n",
      "Epoch 632/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6657 - val_loss: 0.8395\n",
      "Epoch 633/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.6649 - val_loss: 0.8387\n",
      "Epoch 634/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6641 - val_loss: 0.8380\n",
      "Epoch 635/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6634 - val_loss: 0.8372\n",
      "Epoch 636/1000\n",
      "161/161 [==============================] - 0s 857us/step - loss: 0.6626 - val_loss: 0.8365\n",
      "Epoch 637/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6618 - val_loss: 0.8358\n",
      "Epoch 638/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6611 - val_loss: 0.8351\n",
      "Epoch 639/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6604 - val_loss: 0.8344\n",
      "Epoch 640/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6597 - val_loss: 0.8337\n",
      "Epoch 641/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6589 - val_loss: 0.8330\n",
      "Epoch 642/1000\n",
      "161/161 [==============================] - 0s 865us/step - loss: 0.6583 - val_loss: 0.8323\n",
      "Epoch 643/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6576 - val_loss: 0.8316\n",
      "Epoch 644/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.6569 - val_loss: 0.8310\n",
      "Epoch 645/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6562 - val_loss: 0.8303\n",
      "Epoch 646/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6556 - val_loss: 0.8297\n",
      "Epoch 647/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6549 - val_loss: 0.8291\n",
      "Epoch 648/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6543 - val_loss: 0.8285\n",
      "Epoch 649/1000\n",
      "161/161 [==============================] - 0s 860us/step - loss: 0.6536 - val_loss: 0.8279\n",
      "Epoch 650/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6530 - val_loss: 0.8273\n",
      "Epoch 651/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6524 - val_loss: 0.8267\n",
      "Epoch 652/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6518 - val_loss: 0.8261\n",
      "Epoch 653/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6512 - val_loss: 0.8255\n",
      "Epoch 654/1000\n",
      "161/161 [==============================] - 0s 796us/step - loss: 0.6506 - val_loss: 0.8250\n",
      "Epoch 655/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6501 - val_loss: 0.8244\n",
      "Epoch 656/1000\n",
      "161/161 [==============================] - 0s 842us/step - loss: 0.6495 - val_loss: 0.8239\n",
      "Epoch 657/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6489 - val_loss: 0.8233\n",
      "Epoch 658/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6484 - val_loss: 0.8228\n",
      "Epoch 659/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.6478 - val_loss: 0.8223\n",
      "Epoch 660/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6473 - val_loss: 0.8218\n",
      "Epoch 661/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6468 - val_loss: 0.8213\n",
      "Epoch 662/1000\n",
      "161/161 [==============================] - 0s 840us/step - loss: 0.6462 - val_loss: 0.8208\n",
      "Epoch 663/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6457 - val_loss: 0.8203\n",
      "Epoch 664/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6452 - val_loss: 0.8198\n",
      "Epoch 665/1000\n",
      "161/161 [==============================] - 0s 802us/step - loss: 0.6447 - val_loss: 0.8193\n",
      "Epoch 666/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6442 - val_loss: 0.8189\n",
      "Epoch 667/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6437 - val_loss: 0.8184\n",
      "Epoch 668/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6433 - val_loss: 0.8180\n",
      "Epoch 669/1000\n",
      "161/161 [==============================] - 0s 859us/step - loss: 0.6428 - val_loss: 0.8175\n",
      "Epoch 670/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6423 - val_loss: 0.8171\n",
      "Epoch 671/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6418 - val_loss: 0.8166\n",
      "Epoch 672/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6414 - val_loss: 0.8162\n",
      "Epoch 673/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.6409 - val_loss: 0.8158\n",
      "Epoch 674/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6405 - val_loss: 0.8154\n",
      "Epoch 675/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6401 - val_loss: 0.8150\n",
      "Epoch 676/1000\n",
      "161/161 [==============================] - 0s 904us/step - loss: 0.6396 - val_loss: 0.8146\n",
      "Epoch 677/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.6392 - val_loss: 0.8142\n",
      "Epoch 678/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6388 - val_loss: 0.8138\n",
      "Epoch 679/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6384 - val_loss: 0.8134\n",
      "Epoch 680/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6380 - val_loss: 0.8130\n",
      "Epoch 681/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6375 - val_loss: 0.8126\n",
      "Epoch 682/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6371 - val_loss: 0.8123\n",
      "Epoch 683/1000\n",
      "161/161 [==============================] - 0s 871us/step - loss: 0.6368 - val_loss: 0.8119\n",
      "Epoch 684/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6364 - val_loss: 0.8115\n",
      "Epoch 685/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.6360 - val_loss: 0.8112\n",
      "Epoch 686/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6356 - val_loss: 0.8108\n",
      "Epoch 687/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6352 - val_loss: 0.8105\n",
      "Epoch 688/1000\n",
      "161/161 [==============================] - 0s 795us/step - loss: 0.6348 - val_loss: 0.8102\n",
      "Epoch 689/1000\n",
      "161/161 [==============================] - 0s 829us/step - loss: 0.6345 - val_loss: 0.8098\n",
      "Epoch 690/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6341 - val_loss: 0.8095\n",
      "Epoch 691/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6338 - val_loss: 0.8092\n",
      "Epoch 692/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6334 - val_loss: 0.8088\n",
      "Epoch 693/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.6331 - val_loss: 0.8085\n",
      "Epoch 694/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6327 - val_loss: 0.8082\n",
      "Epoch 695/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6324 - val_loss: 0.8079\n",
      "Epoch 696/1000\n",
      "161/161 [==============================] - 0s 862us/step - loss: 0.6320 - val_loss: 0.8076\n",
      "Epoch 697/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6317 - val_loss: 0.8073\n",
      "Epoch 698/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.6314 - val_loss: 0.8070\n",
      "Epoch 699/1000\n",
      "161/161 [==============================] - 0s 794us/step - loss: 0.6310 - val_loss: 0.8067\n",
      "Epoch 700/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6307 - val_loss: 0.8064\n",
      "Epoch 701/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6304 - val_loss: 0.8061\n",
      "Epoch 702/1000\n",
      "161/161 [==============================] - 0s 836us/step - loss: 0.6301 - val_loss: 0.8058\n",
      "Epoch 703/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6297 - val_loss: 0.8055\n",
      "Epoch 704/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6294 - val_loss: 0.8052\n",
      "Epoch 705/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.6291 - val_loss: 0.8049\n",
      "Epoch 706/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6288 - val_loss: 0.8047\n",
      "Epoch 707/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6285 - val_loss: 0.8044\n",
      "Epoch 708/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.6282 - val_loss: 0.8041\n",
      "Epoch 709/1000\n",
      "161/161 [==============================] - 0s 888us/step - loss: 0.6279 - val_loss: 0.8039\n",
      "Epoch 710/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6276 - val_loss: 0.8036\n",
      "Epoch 711/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6273 - val_loss: 0.8033\n",
      "Epoch 712/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.6271 - val_loss: 0.8031\n",
      "Epoch 713/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6268 - val_loss: 0.8028\n",
      "Epoch 714/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6265 - val_loss: 0.8025\n",
      "Epoch 715/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.6262 - val_loss: 0.8023\n",
      "Epoch 716/1000\n",
      "161/161 [==============================] - 0s 853us/step - loss: 0.6259 - val_loss: 0.8020\n",
      "Epoch 717/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6256 - val_loss: 0.8018\n",
      "Epoch 718/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6254 - val_loss: 0.8015\n",
      "Epoch 719/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.6251 - val_loss: 0.8013\n",
      "Epoch 720/1000\n",
      "161/161 [==============================] - 0s 800us/step - loss: 0.6248 - val_loss: 0.8011\n",
      "Epoch 721/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6246 - val_loss: 0.8008\n",
      "Epoch 722/1000\n",
      "161/161 [==============================] - 0s 848us/step - loss: 0.6243 - val_loss: 0.8006\n",
      "Epoch 723/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6240 - val_loss: 0.8003\n",
      "Epoch 724/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.6238 - val_loss: 0.8001\n",
      "Epoch 725/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6235 - val_loss: 0.7999\n",
      "Epoch 726/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6233 - val_loss: 0.7996\n",
      "Epoch 727/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.6230 - val_loss: 0.7994\n",
      "Epoch 728/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.6228 - val_loss: 0.7992\n",
      "Epoch 729/1000\n",
      "161/161 [==============================] - 0s 855us/step - loss: 0.6225 - val_loss: 0.7989\n",
      "Epoch 730/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6223 - val_loss: 0.7987\n",
      "Epoch 731/1000\n",
      "161/161 [==============================] - 0s 793us/step - loss: 0.6220 - val_loss: 0.7985\n",
      "Epoch 732/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.6218 - val_loss: 0.7983\n",
      "Epoch 733/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.6215 - val_loss: 0.7980\n",
      "Epoch 734/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6213 - val_loss: 0.7978\n",
      "Epoch 735/1000\n",
      "161/161 [==============================] - 0s 842us/step - loss: 0.6211 - val_loss: 0.7976\n",
      "Epoch 736/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6208 - val_loss: 0.7974\n",
      "Epoch 737/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6206 - val_loss: 0.7971\n",
      "Epoch 738/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6204 - val_loss: 0.7969\n",
      "Epoch 739/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.6201 - val_loss: 0.7967\n",
      "Epoch 740/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.6199 - val_loss: 0.7965\n",
      "Epoch 741/1000\n",
      "161/161 [==============================] - 0s 790us/step - loss: 0.6197 - val_loss: 0.7962\n",
      "Epoch 742/1000\n",
      "161/161 [==============================] - 0s 845us/step - loss: 0.6194 - val_loss: 0.7960\n",
      "Epoch 743/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6192 - val_loss: 0.7958\n",
      "Epoch 744/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.6190 - val_loss: 0.7956\n",
      "Epoch 745/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6188 - val_loss: 0.7954\n",
      "Epoch 746/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6185 - val_loss: 0.7952\n",
      "Epoch 747/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.6183 - val_loss: 0.7949\n",
      "Epoch 748/1000\n",
      "161/161 [==============================] - 0s 853us/step - loss: 0.6181 - val_loss: 0.7947\n",
      "Epoch 749/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6179 - val_loss: 0.7945\n",
      "Epoch 750/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6177 - val_loss: 0.7943\n",
      "Epoch 751/1000\n",
      "161/161 [==============================] - 0s 804us/step - loss: 0.6174 - val_loss: 0.7941\n",
      "Epoch 752/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6172 - val_loss: 0.7938\n",
      "Epoch 753/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6170 - val_loss: 0.7936\n",
      "Epoch 754/1000\n",
      "161/161 [==============================] - 0s 861us/step - loss: 0.6168 - val_loss: 0.7934\n",
      "Epoch 755/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6166 - val_loss: 0.7932\n",
      "Epoch 756/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.6164 - val_loss: 0.7930\n",
      "Epoch 757/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6162 - val_loss: 0.7928\n",
      "Epoch 758/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6160 - val_loss: 0.7925\n",
      "Epoch 759/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6157 - val_loss: 0.7923\n",
      "Epoch 760/1000\n",
      "161/161 [==============================] - 0s 844us/step - loss: 0.6155 - val_loss: 0.7921\n",
      "Epoch 761/1000\n",
      "161/161 [==============================] - 0s 803us/step - loss: 0.6153 - val_loss: 0.7919\n",
      "Epoch 762/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6151 - val_loss: 0.7917\n",
      "Epoch 763/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6149 - val_loss: 0.7914\n",
      "Epoch 764/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.6147 - val_loss: 0.7912\n",
      "Epoch 765/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6145 - val_loss: 0.7910\n",
      "Epoch 766/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6143 - val_loss: 0.7908\n",
      "Epoch 767/1000\n",
      "161/161 [==============================] - 0s 847us/step - loss: 0.6141 - val_loss: 0.7906\n",
      "Epoch 768/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6139 - val_loss: 0.7903\n",
      "Epoch 769/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6137 - val_loss: 0.7901\n",
      "Epoch 770/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6135 - val_loss: 0.7899\n",
      "Epoch 771/1000\n",
      "161/161 [==============================] - 0s 794us/step - loss: 0.6133 - val_loss: 0.7897\n",
      "Epoch 772/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.6131 - val_loss: 0.7894\n",
      "Epoch 773/1000\n",
      "161/161 [==============================] - 0s 843us/step - loss: 0.6129 - val_loss: 0.7892\n",
      "Epoch 774/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6127 - val_loss: 0.7890\n",
      "Epoch 775/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6125 - val_loss: 0.7887\n",
      "Epoch 776/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.6123 - val_loss: 0.7885\n",
      "Epoch 777/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6121 - val_loss: 0.7883\n",
      "Epoch 778/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6119 - val_loss: 0.7881\n",
      "Epoch 779/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6118 - val_loss: 0.7878\n",
      "Epoch 780/1000\n",
      "161/161 [==============================] - 0s 893us/step - loss: 0.6116 - val_loss: 0.7876\n",
      "Epoch 781/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6114 - val_loss: 0.7874\n",
      "Epoch 782/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6112 - val_loss: 0.7871\n",
      "Epoch 783/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6110 - val_loss: 0.7869\n",
      "Epoch 784/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6108 - val_loss: 0.7867\n",
      "Epoch 785/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6106 - val_loss: 0.7864\n",
      "Epoch 786/1000\n",
      "161/161 [==============================] - 0s 855us/step - loss: 0.6104 - val_loss: 0.7862\n",
      "Epoch 787/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6102 - val_loss: 0.7859\n",
      "Epoch 788/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6100 - val_loss: 0.7857\n",
      "Epoch 789/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6098 - val_loss: 0.7855\n",
      "Epoch 790/1000\n",
      "161/161 [==============================] - 0s 789us/step - loss: 0.6097 - val_loss: 0.7852\n",
      "Epoch 791/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.6095 - val_loss: 0.7850\n",
      "Epoch 792/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6093 - val_loss: 0.7847\n",
      "Epoch 793/1000\n",
      "161/161 [==============================] - 0s 861us/step - loss: 0.6091 - val_loss: 0.7845\n",
      "Epoch 794/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.6089 - val_loss: 0.7843\n",
      "Epoch 795/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6087 - val_loss: 0.7840\n",
      "Epoch 796/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6085 - val_loss: 0.7838\n",
      "Epoch 797/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6084 - val_loss: 0.7835\n",
      "Epoch 798/1000\n",
      "161/161 [==============================] - 0s 855us/step - loss: 0.6082 - val_loss: 0.7833\n",
      "Epoch 799/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.6080 - val_loss: 0.7830\n",
      "Epoch 800/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6078 - val_loss: 0.7828\n",
      "Epoch 801/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6076 - val_loss: 0.7825\n",
      "Epoch 802/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6074 - val_loss: 0.7823\n",
      "Epoch 803/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.6073 - val_loss: 0.7820\n",
      "Epoch 804/1000\n",
      "161/161 [==============================] - 0s 855us/step - loss: 0.6071 - val_loss: 0.7818\n",
      "Epoch 805/1000\n",
      "161/161 [==============================] - 0s 773us/step - loss: 0.6069 - val_loss: 0.7815\n",
      "Epoch 806/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6067 - val_loss: 0.7813\n",
      "Epoch 807/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6065 - val_loss: 0.7810\n",
      "Epoch 808/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.6063 - val_loss: 0.7808\n",
      "Epoch 809/1000\n",
      "161/161 [==============================] - 0s 793us/step - loss: 0.6062 - val_loss: 0.7805\n",
      "Epoch 810/1000\n",
      "161/161 [==============================] - 0s 853us/step - loss: 0.6060 - val_loss: 0.7803\n",
      "Epoch 811/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6058 - val_loss: 0.7800\n",
      "Epoch 812/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.6056 - val_loss: 0.7798\n",
      "Epoch 813/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6054 - val_loss: 0.7795\n",
      "Epoch 814/1000\n",
      "161/161 [==============================] - 0s 756us/step - loss: 0.6053 - val_loss: 0.7793\n",
      "Epoch 815/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.6051 - val_loss: 0.7790\n",
      "Epoch 816/1000\n",
      "161/161 [==============================] - 0s 859us/step - loss: 0.6049 - val_loss: 0.7788\n",
      "Epoch 817/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.6047 - val_loss: 0.7785\n",
      "Epoch 818/1000\n",
      "161/161 [==============================] - 0s 794us/step - loss: 0.6045 - val_loss: 0.7783\n",
      "Epoch 819/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6044 - val_loss: 0.7780\n",
      "Epoch 820/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6042 - val_loss: 0.7778\n",
      "Epoch 821/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.6040 - val_loss: 0.7775\n",
      "Epoch 822/1000\n",
      "161/161 [==============================] - 0s 854us/step - loss: 0.6038 - val_loss: 0.7773\n",
      "Epoch 823/1000\n",
      "161/161 [==============================] - 0s 752us/step - loss: 0.6036 - val_loss: 0.7770\n",
      "Epoch 824/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6035 - val_loss: 0.7768\n",
      "Epoch 825/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.6033 - val_loss: 0.7765\n",
      "Epoch 826/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.6031 - val_loss: 0.7763\n",
      "Epoch 827/1000\n",
      "161/161 [==============================] - 0s 794us/step - loss: 0.6029 - val_loss: 0.7760\n",
      "Epoch 828/1000\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.6028 - val_loss: 0.7758\n",
      "Epoch 829/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.6026 - val_loss: 0.7755\n",
      "Epoch 830/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.6024 - val_loss: 0.7753\n",
      "Epoch 831/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.6022 - val_loss: 0.7751\n",
      "Epoch 832/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.6021 - val_loss: 0.7748\n",
      "Epoch 833/1000\n",
      "161/161 [==============================] - 0s 826us/step - loss: 0.6019 - val_loss: 0.7746\n",
      "Epoch 834/1000\n",
      "161/161 [==============================] - 0s 835us/step - loss: 0.6017 - val_loss: 0.7743\n",
      "Epoch 835/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.6015 - val_loss: 0.7741\n",
      "Epoch 836/1000\n",
      "161/161 [==============================] - 0s 811us/step - loss: 0.6014 - val_loss: 0.7738\n",
      "Epoch 837/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.6012 - val_loss: 0.7736\n",
      "Epoch 838/1000\n",
      "161/161 [==============================] - 0s 790us/step - loss: 0.6010 - val_loss: 0.7734\n",
      "Epoch 839/1000\n",
      "161/161 [==============================] - 0s 866us/step - loss: 0.6008 - val_loss: 0.7731\n",
      "Epoch 840/1000\n",
      "161/161 [==============================] - 0s 778us/step - loss: 0.6007 - val_loss: 0.7729\n",
      "Epoch 841/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.6005 - val_loss: 0.7727\n",
      "Epoch 842/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.6003 - val_loss: 0.7724\n",
      "Epoch 843/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.6001 - val_loss: 0.7722\n",
      "Epoch 844/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.6000 - val_loss: 0.7720\n",
      "Epoch 845/1000\n",
      "161/161 [==============================] - 0s 882us/step - loss: 0.5998 - val_loss: 0.7718\n",
      "Epoch 846/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5996 - val_loss: 0.7715\n",
      "Epoch 847/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5995 - val_loss: 0.7713\n",
      "Epoch 848/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5993 - val_loss: 0.7711\n",
      "Epoch 849/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.5991 - val_loss: 0.7709\n",
      "Epoch 850/1000\n",
      "161/161 [==============================] - 0s 853us/step - loss: 0.5989 - val_loss: 0.7706\n",
      "Epoch 851/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5988 - val_loss: 0.7704\n",
      "Epoch 852/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.5986 - val_loss: 0.7702\n",
      "Epoch 853/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5984 - val_loss: 0.7700\n",
      "Epoch 854/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.5983 - val_loss: 0.7698\n",
      "Epoch 855/1000\n",
      "161/161 [==============================] - 0s 809us/step - loss: 0.5981 - val_loss: 0.7696\n",
      "Epoch 856/1000\n",
      "161/161 [==============================] - 0s 852us/step - loss: 0.5979 - val_loss: 0.7694\n",
      "Epoch 857/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5978 - val_loss: 0.7692\n",
      "Epoch 858/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.5976 - val_loss: 0.7690\n",
      "Epoch 859/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5974 - val_loss: 0.7687\n",
      "Epoch 860/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5973 - val_loss: 0.7685\n",
      "Epoch 861/1000\n",
      "161/161 [==============================] - 0s 867us/step - loss: 0.5971 - val_loss: 0.7683\n",
      "Epoch 862/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5969 - val_loss: 0.7681\n",
      "Epoch 863/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5968 - val_loss: 0.7679\n",
      "Epoch 864/1000\n",
      "161/161 [==============================] - 0s 797us/step - loss: 0.5966 - val_loss: 0.7678\n",
      "Epoch 865/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5964 - val_loss: 0.7676\n",
      "Epoch 866/1000\n",
      "161/161 [==============================] - 0s 851us/step - loss: 0.5963 - val_loss: 0.7674\n",
      "Epoch 867/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.5961 - val_loss: 0.7672\n",
      "Epoch 868/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5960 - val_loss: 0.7670\n",
      "Epoch 869/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5958 - val_loss: 0.7668\n",
      "Epoch 870/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5956 - val_loss: 0.7666\n",
      "Epoch 871/1000\n",
      "161/161 [==============================] - 0s 855us/step - loss: 0.5955 - val_loss: 0.7664\n",
      "Epoch 872/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5953 - val_loss: 0.7662\n",
      "Epoch 873/1000\n",
      "161/161 [==============================] - 0s 787us/step - loss: 0.5951 - val_loss: 0.7661\n",
      "Epoch 874/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5950 - val_loss: 0.7659\n",
      "Epoch 875/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.5948 - val_loss: 0.7657\n",
      "Epoch 876/1000\n",
      "161/161 [==============================] - 0s 853us/step - loss: 0.5947 - val_loss: 0.7655\n",
      "Epoch 877/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5945 - val_loss: 0.7654\n",
      "Epoch 878/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5944 - val_loss: 0.7652\n",
      "Epoch 879/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5942 - val_loss: 0.7650\n",
      "Epoch 880/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5940 - val_loss: 0.7649\n",
      "Epoch 881/1000\n",
      "161/161 [==============================] - 0s 876us/step - loss: 0.5939 - val_loss: 0.7647\n",
      "Epoch 882/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5937 - val_loss: 0.7645\n",
      "Epoch 883/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5936 - val_loss: 0.7644\n",
      "Epoch 884/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5934 - val_loss: 0.7642\n",
      "Epoch 885/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.5933 - val_loss: 0.7640\n",
      "Epoch 886/1000\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.5931 - val_loss: 0.7639\n",
      "Epoch 887/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5930 - val_loss: 0.7637\n",
      "Epoch 888/1000\n",
      "161/161 [==============================] - 0s 755us/step - loss: 0.5928 - val_loss: 0.7636\n",
      "Epoch 889/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.5926 - val_loss: 0.7634\n",
      "Epoch 890/1000\n",
      "161/161 [==============================] - 0s 799us/step - loss: 0.5925 - val_loss: 0.7633\n",
      "Epoch 891/1000\n",
      "161/161 [==============================] - 0s 848us/step - loss: 0.5923 - val_loss: 0.7631\n",
      "Epoch 892/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5922 - val_loss: 0.7629\n",
      "Epoch 893/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5920 - val_loss: 0.7628\n",
      "Epoch 894/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5919 - val_loss: 0.7627\n",
      "Epoch 895/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5917 - val_loss: 0.7625\n",
      "Epoch 896/1000\n",
      "161/161 [==============================] - 0s 850us/step - loss: 0.5916 - val_loss: 0.7624\n",
      "Epoch 897/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5914 - val_loss: 0.7622\n",
      "Epoch 898/1000\n",
      "161/161 [==============================] - 0s 795us/step - loss: 0.5913 - val_loss: 0.7621\n",
      "Epoch 899/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5912 - val_loss: 0.7619\n",
      "Epoch 900/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5910 - val_loss: 0.7618\n",
      "Epoch 901/1000\n",
      "161/161 [==============================] - 0s 844us/step - loss: 0.5909 - val_loss: 0.7617\n",
      "Epoch 902/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5907 - val_loss: 0.7615\n",
      "Epoch 903/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5906 - val_loss: 0.7614\n",
      "Epoch 904/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5904 - val_loss: 0.7613\n",
      "Epoch 905/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5903 - val_loss: 0.7611\n",
      "Epoch 906/1000\n",
      "161/161 [==============================] - 0s 881us/step - loss: 0.5901 - val_loss: 0.7610\n",
      "Epoch 907/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5900 - val_loss: 0.7609\n",
      "Epoch 908/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5898 - val_loss: 0.7607\n",
      "Epoch 909/1000\n",
      "161/161 [==============================] - 0s 775us/step - loss: 0.5897 - val_loss: 0.7606\n",
      "Epoch 910/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5896 - val_loss: 0.7605\n",
      "Epoch 911/1000\n",
      "161/161 [==============================] - 0s 855us/step - loss: 0.5894 - val_loss: 0.7603\n",
      "Epoch 912/1000\n",
      "161/161 [==============================] - 0s 772us/step - loss: 0.5893 - val_loss: 0.7602\n",
      "Epoch 913/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5891 - val_loss: 0.7601\n",
      "Epoch 914/1000\n",
      "161/161 [==============================] - 0s 780us/step - loss: 0.5890 - val_loss: 0.7600\n",
      "Epoch 915/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5889 - val_loss: 0.7599\n",
      "Epoch 916/1000\n",
      "161/161 [==============================] - 0s 836us/step - loss: 0.5887 - val_loss: 0.7597\n",
      "Epoch 917/1000\n",
      "161/161 [==============================] - 0s 782us/step - loss: 0.5886 - val_loss: 0.7596\n",
      "Epoch 918/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.5884 - val_loss: 0.7595\n",
      "Epoch 919/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5883 - val_loss: 0.7594\n",
      "Epoch 920/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5882 - val_loss: 0.7593\n",
      "Epoch 921/1000\n",
      "161/161 [==============================] - 0s 861us/step - loss: 0.5880 - val_loss: 0.7592\n",
      "Epoch 922/1000\n",
      "161/161 [==============================] - 0s 808us/step - loss: 0.5879 - val_loss: 0.7590\n",
      "Epoch 923/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5877 - val_loss: 0.7589\n",
      "Epoch 924/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5876 - val_loss: 0.7588\n",
      "Epoch 925/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5875 - val_loss: 0.7587\n",
      "Epoch 926/1000\n",
      "161/161 [==============================] - 0s 861us/step - loss: 0.5873 - val_loss: 0.7586\n",
      "Epoch 927/1000\n",
      "161/161 [==============================] - 0s 776us/step - loss: 0.5872 - val_loss: 0.7585\n",
      "Epoch 928/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5871 - val_loss: 0.7584\n",
      "Epoch 929/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.5869 - val_loss: 0.7583\n",
      "Epoch 930/1000\n",
      "161/161 [==============================] - 0s 801us/step - loss: 0.5868 - val_loss: 0.7582\n",
      "Epoch 931/1000\n",
      "161/161 [==============================] - 0s 856us/step - loss: 0.5867 - val_loss: 0.7581\n",
      "Epoch 932/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5865 - val_loss: 0.7579\n",
      "Epoch 933/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5864 - val_loss: 0.7578\n",
      "Epoch 934/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5863 - val_loss: 0.7577\n",
      "Epoch 935/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5861 - val_loss: 0.7576\n",
      "Epoch 936/1000\n",
      "161/161 [==============================] - 0s 849us/step - loss: 0.5860 - val_loss: 0.7575\n",
      "Epoch 937/1000\n",
      "161/161 [==============================] - 0s 797us/step - loss: 0.5859 - val_loss: 0.7574\n",
      "Epoch 938/1000\n",
      "161/161 [==============================] - 0s 770us/step - loss: 0.5857 - val_loss: 0.7573\n",
      "Epoch 939/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5856 - val_loss: 0.7572\n",
      "Epoch 940/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.5855 - val_loss: 0.7571\n",
      "Epoch 941/1000\n",
      "161/161 [==============================] - 0s 853us/step - loss: 0.5853 - val_loss: 0.7570\n",
      "Epoch 942/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.5852 - val_loss: 0.7569\n",
      "Epoch 943/1000\n",
      "161/161 [==============================] - 0s 757us/step - loss: 0.5851 - val_loss: 0.7568\n",
      "Epoch 944/1000\n",
      "161/161 [==============================] - 0s 771us/step - loss: 0.5849 - val_loss: 0.7567\n",
      "Epoch 945/1000\n",
      "161/161 [==============================] - 0s 800us/step - loss: 0.5848 - val_loss: 0.7566\n",
      "Epoch 946/1000\n",
      "161/161 [==============================] - 0s 861us/step - loss: 0.5847 - val_loss: 0.7566\n",
      "Epoch 947/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5846 - val_loss: 0.7565\n",
      "Epoch 948/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5844 - val_loss: 0.7564\n",
      "Epoch 949/1000\n",
      "161/161 [==============================] - 0s 763us/step - loss: 0.5843 - val_loss: 0.7563\n",
      "Epoch 950/1000\n",
      "161/161 [==============================] - 0s 777us/step - loss: 0.5842 - val_loss: 0.7562\n",
      "Epoch 951/1000\n",
      "161/161 [==============================] - 0s 840us/step - loss: 0.5840 - val_loss: 0.7561\n",
      "Epoch 952/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5839 - val_loss: 0.7560\n",
      "Epoch 953/1000\n",
      "161/161 [==============================] - 0s 798us/step - loss: 0.5838 - val_loss: 0.7559\n",
      "Epoch 954/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5837 - val_loss: 0.7558\n",
      "Epoch 955/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5835 - val_loss: 0.7557\n",
      "Epoch 956/1000\n",
      "161/161 [==============================] - 0s 844us/step - loss: 0.5834 - val_loss: 0.7556\n",
      "Epoch 957/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5833 - val_loss: 0.7556\n",
      "Epoch 958/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5832 - val_loss: 0.7555\n",
      "Epoch 959/1000\n",
      "161/161 [==============================] - 0s 754us/step - loss: 0.5830 - val_loss: 0.7554\n",
      "Epoch 960/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5829 - val_loss: 0.7553\n",
      "Epoch 961/1000\n",
      "161/161 [==============================] - 0s 907us/step - loss: 0.5828 - val_loss: 0.7552\n",
      "Epoch 962/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5827 - val_loss: 0.7551\n",
      "Epoch 963/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5825 - val_loss: 0.7550\n",
      "Epoch 964/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5824 - val_loss: 0.7550\n",
      "Epoch 965/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5823 - val_loss: 0.7549\n",
      "Epoch 966/1000\n",
      "161/161 [==============================] - 0s 851us/step - loss: 0.5822 - val_loss: 0.7548\n",
      "Epoch 967/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5820 - val_loss: 0.7547\n",
      "Epoch 968/1000\n",
      "161/161 [==============================] - 0s 788us/step - loss: 0.5819 - val_loss: 0.7546\n",
      "Epoch 969/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5818 - val_loss: 0.7545\n",
      "Epoch 970/1000\n",
      "161/161 [==============================] - 0s 765us/step - loss: 0.5817 - val_loss: 0.7545\n",
      "Epoch 971/1000\n",
      "161/161 [==============================] - 0s 849us/step - loss: 0.5816 - val_loss: 0.7544\n",
      "Epoch 972/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5814 - val_loss: 0.7543\n",
      "Epoch 973/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5813 - val_loss: 0.7542\n",
      "Epoch 974/1000\n",
      "161/161 [==============================] - 0s 762us/step - loss: 0.5812 - val_loss: 0.7541\n",
      "Epoch 975/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5811 - val_loss: 0.7541\n",
      "Epoch 976/1000\n",
      "161/161 [==============================] - 0s 885us/step - loss: 0.5809 - val_loss: 0.7540\n",
      "Epoch 977/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5808 - val_loss: 0.7539\n",
      "Epoch 978/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5807 - val_loss: 0.7538\n",
      "Epoch 979/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5806 - val_loss: 0.7538\n",
      "Epoch 980/1000\n",
      "161/161 [==============================] - 0s 766us/step - loss: 0.5805 - val_loss: 0.7537\n",
      "Epoch 981/1000\n",
      "161/161 [==============================] - 0s 850us/step - loss: 0.5803 - val_loss: 0.7536\n",
      "Epoch 982/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5802 - val_loss: 0.7535\n",
      "Epoch 983/1000\n",
      "161/161 [==============================] - 0s 753us/step - loss: 0.5801 - val_loss: 0.7535\n",
      "Epoch 984/1000\n",
      "161/161 [==============================] - 0s 784us/step - loss: 0.5800 - val_loss: 0.7534\n",
      "Epoch 985/1000\n",
      "161/161 [==============================] - 0s 758us/step - loss: 0.5799 - val_loss: 0.7533\n",
      "Epoch 986/1000\n",
      "161/161 [==============================] - 0s 851us/step - loss: 0.5797 - val_loss: 0.7532\n",
      "Epoch 987/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5796 - val_loss: 0.7532\n",
      "Epoch 988/1000\n",
      "161/161 [==============================] - 0s 764us/step - loss: 0.5795 - val_loss: 0.7531\n",
      "Epoch 989/1000\n",
      "161/161 [==============================] - 0s 760us/step - loss: 0.5794 - val_loss: 0.7530\n",
      "Epoch 990/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5793 - val_loss: 0.7529\n",
      "Epoch 991/1000\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.5792 - val_loss: 0.7529\n",
      "Epoch 992/1000\n",
      "161/161 [==============================] - 0s 793us/step - loss: 0.5790 - val_loss: 0.7528\n",
      "Epoch 993/1000\n",
      "161/161 [==============================] - 0s 767us/step - loss: 0.5789 - val_loss: 0.7527\n",
      "Epoch 994/1000\n",
      "161/161 [==============================] - 0s 774us/step - loss: 0.5788 - val_loss: 0.7527\n",
      "Epoch 995/1000\n",
      "161/161 [==============================] - 0s 769us/step - loss: 0.5787 - val_loss: 0.7526\n",
      "Epoch 996/1000\n",
      "161/161 [==============================] - 0s 846us/step - loss: 0.5786 - val_loss: 0.7525\n",
      "Epoch 997/1000\n",
      "161/161 [==============================] - 0s 768us/step - loss: 0.5785 - val_loss: 0.7524\n",
      "Epoch 998/1000\n",
      "161/161 [==============================] - 0s 761us/step - loss: 0.5783 - val_loss: 0.7524\n",
      "Epoch 999/1000\n",
      "161/161 [==============================] - 0s 789us/step - loss: 0.5782 - val_loss: 0.7523\n",
      "Epoch 1000/1000\n",
      "161/161 [==============================] - 0s 759us/step - loss: 0.5781 - val_loss: 0.7522\n"
     ]
    }
   ],
   "source": [
    "epocas = 1000\n",
    "history = modelo3.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=lote,\n",
    "    epochs=epocas,\n",
    "    shuffle=False,\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo4 = Sequential()\n",
    "lote = 1\n",
    "paso = 1\n",
    "caracteristicas = 2\n",
    "modelo4.add(LSTM(lote, batch_input_shape=(lote, paso, caracteristicas), return_sequences=True, stateful=True))\n",
    "modelo4.add(LSTM(lote, return_sequences=True, stateful=True))\n",
    "modelo4.add(LSTM(lote, return_sequences=True, stateful=True))\n",
    "modelo4.add(LSTM(lote, stateful=True))\n",
    "modelo4.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo4.compile(loss='mean_squared_error', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "161/161 [==============================] - 3s 6ms/step - loss: 1.0131 - val_loss: 1.2009\n",
      "Epoch 2/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0130 - val_loss: 1.2007\n",
      "Epoch 3/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0129 - val_loss: 1.2006\n",
      "Epoch 4/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.2006\n",
      "Epoch 5/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.2006\n",
      "Epoch 6/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.2007\n",
      "Epoch 7/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.2007\n",
      "Epoch 8/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.2007\n",
      "Epoch 9/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.2008\n",
      "Epoch 10/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.2008\n",
      "Epoch 11/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.2008\n",
      "Epoch 12/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.2009\n",
      "Epoch 13/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0127 - val_loss: 1.2008\n",
      "Epoch 14/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0126 - val_loss: 1.2008\n",
      "Epoch 15/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0125 - val_loss: 1.2008\n",
      "Epoch 16/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0124 - val_loss: 1.2007\n",
      "Epoch 17/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0122 - val_loss: 1.2005\n",
      "Epoch 18/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0119 - val_loss: 1.2003\n",
      "Epoch 19/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0116 - val_loss: 1.2000\n",
      "Epoch 20/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0113 - val_loss: 1.1996\n",
      "Epoch 21/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0108 - val_loss: 1.1991\n",
      "Epoch 22/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0102 - val_loss: 1.1985\n",
      "Epoch 23/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0095 - val_loss: 1.1976\n",
      "Epoch 24/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0086 - val_loss: 1.1965\n",
      "Epoch 25/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0075 - val_loss: 1.1951\n",
      "Epoch 26/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0061 - val_loss: 1.1933\n",
      "Epoch 27/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0044 - val_loss: 1.1909\n",
      "Epoch 28/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 1.0023 - val_loss: 1.1878\n",
      "Epoch 29/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.1838\n",
      "Epoch 30/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 1.1788\n",
      "Epoch 31/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.1727\n",
      "Epoch 32/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9881 - val_loss: 1.1652\n",
      "Epoch 33/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9821 - val_loss: 1.1562\n",
      "Epoch 34/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9745 - val_loss: 1.1463\n",
      "Epoch 35/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9651 - val_loss: 1.1360\n",
      "Epoch 36/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 1.1253\n",
      "Epoch 37/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 1.1139\n",
      "Epoch 38/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 1.1018\n",
      "Epoch 39/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9150 - val_loss: 1.0890\n",
      "Epoch 40/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.9008 - val_loss: 1.0758\n",
      "Epoch 41/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8867 - val_loss: 1.0624\n",
      "Epoch 42/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8730 - val_loss: 1.0491\n",
      "Epoch 43/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8600 - val_loss: 1.0362\n",
      "Epoch 44/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8478 - val_loss: 1.0241\n",
      "Epoch 45/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8365 - val_loss: 1.0129\n",
      "Epoch 46/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8261 - val_loss: 1.0028\n",
      "Epoch 47/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8166 - val_loss: 0.9940\n",
      "Epoch 48/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8080 - val_loss: 0.9866\n",
      "Epoch 49/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.8004 - val_loss: 0.9805\n",
      "Epoch 50/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7937 - val_loss: 0.9756\n",
      "Epoch 51/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7879 - val_loss: 0.9717\n",
      "Epoch 52/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7829 - val_loss: 0.9687\n",
      "Epoch 53/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7786 - val_loss: 0.9662\n",
      "Epoch 54/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7748 - val_loss: 0.9643\n",
      "Epoch 55/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7716 - val_loss: 0.9628\n",
      "Epoch 56/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7688 - val_loss: 0.9617\n",
      "Epoch 57/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7664 - val_loss: 0.9609\n",
      "Epoch 58/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7643 - val_loss: 0.9604\n",
      "Epoch 59/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7625 - val_loss: 0.9602\n",
      "Epoch 60/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7609 - val_loss: 0.9602\n",
      "Epoch 61/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7596 - val_loss: 0.9605\n",
      "Epoch 62/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7584 - val_loss: 0.9610\n",
      "Epoch 63/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7573 - val_loss: 0.9617\n",
      "Epoch 64/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7562 - val_loss: 0.9624\n",
      "Epoch 65/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7552 - val_loss: 0.9632\n",
      "Epoch 66/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7543 - val_loss: 0.9639\n",
      "Epoch 67/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.9644\n",
      "Epoch 68/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7527 - val_loss: 0.9648\n",
      "Epoch 69/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7520 - val_loss: 0.9652\n",
      "Epoch 70/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7514 - val_loss: 0.9654\n",
      "Epoch 71/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7509 - val_loss: 0.9656\n",
      "Epoch 72/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7503 - val_loss: 0.9657\n",
      "Epoch 73/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7499 - val_loss: 0.9658\n",
      "Epoch 74/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7494 - val_loss: 0.9659\n",
      "Epoch 75/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7490 - val_loss: 0.9659\n",
      "Epoch 76/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7486 - val_loss: 0.9659\n",
      "Epoch 77/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7482 - val_loss: 0.9658\n",
      "Epoch 78/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7478 - val_loss: 0.9657\n",
      "Epoch 79/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7474 - val_loss: 0.9655\n",
      "Epoch 80/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7471 - val_loss: 0.9653\n",
      "Epoch 81/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7467 - val_loss: 0.9651\n",
      "Epoch 82/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7463 - val_loss: 0.9648\n",
      "Epoch 83/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7459 - val_loss: 0.9645\n",
      "Epoch 84/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7455 - val_loss: 0.9641\n",
      "Epoch 85/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7451 - val_loss: 0.9637\n",
      "Epoch 86/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7448 - val_loss: 0.9633\n",
      "Epoch 87/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7444 - val_loss: 0.9629\n",
      "Epoch 88/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7440 - val_loss: 0.9624\n",
      "Epoch 89/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7436 - val_loss: 0.9619\n",
      "Epoch 90/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7432 - val_loss: 0.9614\n",
      "Epoch 91/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7428 - val_loss: 0.9608\n",
      "Epoch 92/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7424 - val_loss: 0.9602\n",
      "Epoch 93/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7420 - val_loss: 0.9596\n",
      "Epoch 94/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7416 - val_loss: 0.9590\n",
      "Epoch 95/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7412 - val_loss: 0.9584\n",
      "Epoch 96/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7407 - val_loss: 0.9577\n",
      "Epoch 97/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7403 - val_loss: 0.9570\n",
      "Epoch 98/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7399 - val_loss: 0.9564\n",
      "Epoch 99/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7395 - val_loss: 0.9556\n",
      "Epoch 100/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7391 - val_loss: 0.9549\n",
      "Epoch 101/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7387 - val_loss: 0.9542\n",
      "Epoch 102/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7382 - val_loss: 0.9534\n",
      "Epoch 103/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7378 - val_loss: 0.9527\n",
      "Epoch 104/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7374 - val_loss: 0.9519\n",
      "Epoch 105/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7369 - val_loss: 0.9511\n",
      "Epoch 106/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7365 - val_loss: 0.9503\n",
      "Epoch 107/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7361 - val_loss: 0.9495\n",
      "Epoch 108/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7357 - val_loss: 0.9487\n",
      "Epoch 109/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7352 - val_loss: 0.9479\n",
      "Epoch 110/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7348 - val_loss: 0.9471\n",
      "Epoch 111/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7344 - val_loss: 0.9462\n",
      "Epoch 112/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7339 - val_loss: 0.9454\n",
      "Epoch 113/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7335 - val_loss: 0.9446\n",
      "Epoch 114/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7331 - val_loss: 0.9438\n",
      "Epoch 115/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7327 - val_loss: 0.9429\n",
      "Epoch 116/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7322 - val_loss: 0.9421\n",
      "Epoch 117/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7318 - val_loss: 0.9413\n",
      "Epoch 118/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7314 - val_loss: 0.9405\n",
      "Epoch 119/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7310 - val_loss: 0.9396\n",
      "Epoch 120/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7306 - val_loss: 0.9388\n",
      "Epoch 121/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7302 - val_loss: 0.9380\n",
      "Epoch 122/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7298 - val_loss: 0.9372\n",
      "Epoch 123/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7293 - val_loss: 0.9364\n",
      "Epoch 124/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7290 - val_loss: 0.9356\n",
      "Epoch 125/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7286 - val_loss: 0.9349\n",
      "Epoch 126/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7282 - val_loss: 0.9341\n",
      "Epoch 127/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7278 - val_loss: 0.9333\n",
      "Epoch 128/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7274 - val_loss: 0.9326\n",
      "Epoch 129/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7270 - val_loss: 0.9319\n",
      "Epoch 130/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7267 - val_loss: 0.9311\n",
      "Epoch 131/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7263 - val_loss: 0.9304\n",
      "Epoch 132/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7259 - val_loss: 0.9297\n",
      "Epoch 133/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7256 - val_loss: 0.9290\n",
      "Epoch 134/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7252 - val_loss: 0.9283\n",
      "Epoch 135/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7249 - val_loss: 0.9277\n",
      "Epoch 136/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7245 - val_loss: 0.9270\n",
      "Epoch 137/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7242 - val_loss: 0.9264\n",
      "Epoch 138/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7239 - val_loss: 0.9258\n",
      "Epoch 139/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7235 - val_loss: 0.9251\n",
      "Epoch 140/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7232 - val_loss: 0.9245\n",
      "Epoch 141/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7229 - val_loss: 0.9239\n",
      "Epoch 142/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7226 - val_loss: 0.9234\n",
      "Epoch 143/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7223 - val_loss: 0.9228\n",
      "Epoch 144/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7219 - val_loss: 0.9222\n",
      "Epoch 145/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7216 - val_loss: 0.9217\n",
      "Epoch 146/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7213 - val_loss: 0.9211\n",
      "Epoch 147/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7210 - val_loss: 0.9206\n",
      "Epoch 148/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7207 - val_loss: 0.9201\n",
      "Epoch 149/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7204 - val_loss: 0.9196\n",
      "Epoch 150/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7201 - val_loss: 0.9191\n",
      "Epoch 151/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7199 - val_loss: 0.9186\n",
      "Epoch 152/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7196 - val_loss: 0.9181\n",
      "Epoch 153/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7193 - val_loss: 0.9177\n",
      "Epoch 154/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7190 - val_loss: 0.9172\n",
      "Epoch 155/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7187 - val_loss: 0.9168\n",
      "Epoch 156/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7184 - val_loss: 0.9163\n",
      "Epoch 157/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7181 - val_loss: 0.9159\n",
      "Epoch 158/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7179 - val_loss: 0.9155\n",
      "Epoch 159/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7176 - val_loss: 0.9151\n",
      "Epoch 160/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7173 - val_loss: 0.9147\n",
      "Epoch 161/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7170 - val_loss: 0.9143\n",
      "Epoch 162/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7167 - val_loss: 0.9139\n",
      "Epoch 163/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7164 - val_loss: 0.9135\n",
      "Epoch 164/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7162 - val_loss: 0.9132\n",
      "Epoch 165/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7159 - val_loss: 0.9128\n",
      "Epoch 166/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7156 - val_loss: 0.9124\n",
      "Epoch 167/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7153 - val_loss: 0.9121\n",
      "Epoch 168/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7150 - val_loss: 0.9118\n",
      "Epoch 169/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7147 - val_loss: 0.9115\n",
      "Epoch 170/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7145 - val_loss: 0.9112\n",
      "Epoch 171/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7142 - val_loss: 0.9109\n",
      "Epoch 172/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7139 - val_loss: 0.9106\n",
      "Epoch 173/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7136 - val_loss: 0.9103\n",
      "Epoch 174/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7133 - val_loss: 0.9100\n",
      "Epoch 175/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7130 - val_loss: 0.9098\n",
      "Epoch 176/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7127 - val_loss: 0.9095\n",
      "Epoch 177/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7124 - val_loss: 0.9093\n",
      "Epoch 178/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7121 - val_loss: 0.9090\n",
      "Epoch 179/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7118 - val_loss: 0.9088\n",
      "Epoch 180/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7115 - val_loss: 0.9086\n",
      "Epoch 181/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7112 - val_loss: 0.9084\n",
      "Epoch 182/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7109 - val_loss: 0.9082\n",
      "Epoch 183/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7106 - val_loss: 0.9081\n",
      "Epoch 184/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7103 - val_loss: 0.9079\n",
      "Epoch 185/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7100 - val_loss: 0.9078\n",
      "Epoch 186/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7097 - val_loss: 0.9076\n",
      "Epoch 187/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7094 - val_loss: 0.9075\n",
      "Epoch 188/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7091 - val_loss: 0.9074\n",
      "Epoch 189/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7088 - val_loss: 0.9073\n",
      "Epoch 190/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7085 - val_loss: 0.9071\n",
      "Epoch 191/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7082 - val_loss: 0.9071\n",
      "Epoch 192/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7079 - val_loss: 0.9070\n",
      "Epoch 193/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7076 - val_loss: 0.9069\n",
      "Epoch 194/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7073 - val_loss: 0.9068\n",
      "Epoch 195/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7071 - val_loss: 0.9068\n",
      "Epoch 196/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7068 - val_loss: 0.9067\n",
      "Epoch 197/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7065 - val_loss: 0.9067\n",
      "Epoch 198/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7062 - val_loss: 0.9066\n",
      "Epoch 199/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7059 - val_loss: 0.9066\n",
      "Epoch 200/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7057 - val_loss: 0.9066\n",
      "Epoch 201/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.7054 - val_loss: 0.9066\n",
      "Epoch 202/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7051 - val_loss: 0.9066\n",
      "Epoch 203/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7049 - val_loss: 0.9066\n",
      "Epoch 204/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7046 - val_loss: 0.9066\n",
      "Epoch 205/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7044 - val_loss: 0.9066\n",
      "Epoch 206/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7041 - val_loss: 0.9066\n",
      "Epoch 207/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7039 - val_loss: 0.9066\n",
      "Epoch 208/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7036 - val_loss: 0.9066\n",
      "Epoch 209/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7034 - val_loss: 0.9067\n",
      "Epoch 210/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7032 - val_loss: 0.9067\n",
      "Epoch 211/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7030 - val_loss: 0.9067\n",
      "Epoch 212/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7028 - val_loss: 0.9068\n",
      "Epoch 213/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7026 - val_loss: 0.9068\n",
      "Epoch 214/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7024 - val_loss: 0.9069\n",
      "Epoch 215/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7022 - val_loss: 0.9069\n",
      "Epoch 216/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7020 - val_loss: 0.9070\n",
      "Epoch 217/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7018 - val_loss: 0.9071\n",
      "Epoch 218/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7016 - val_loss: 0.9071\n",
      "Epoch 219/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 0.9072\n",
      "Epoch 220/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7013 - val_loss: 0.9073\n",
      "Epoch 221/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7011 - val_loss: 0.9074\n",
      "Epoch 222/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7009 - val_loss: 0.9074\n",
      "Epoch 223/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7008 - val_loss: 0.9075\n",
      "Epoch 224/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7006 - val_loss: 0.9076\n",
      "Epoch 225/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7005 - val_loss: 0.9077\n",
      "Epoch 226/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7003 - val_loss: 0.9078\n",
      "Epoch 227/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7002 - val_loss: 0.9079\n",
      "Epoch 228/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.7000 - val_loss: 0.9080\n",
      "Epoch 229/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6999 - val_loss: 0.9081\n",
      "Epoch 230/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6998 - val_loss: 0.9082\n",
      "Epoch 231/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6996 - val_loss: 0.9082\n",
      "Epoch 232/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6995 - val_loss: 0.9083\n",
      "Epoch 233/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6994 - val_loss: 0.9084\n",
      "Epoch 234/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6992 - val_loss: 0.9086\n",
      "Epoch 235/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6991 - val_loss: 0.9087\n",
      "Epoch 236/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6990 - val_loss: 0.9088\n",
      "Epoch 237/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6988 - val_loss: 0.9089\n",
      "Epoch 238/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6987 - val_loss: 0.9090\n",
      "Epoch 239/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6986 - val_loss: 0.9091\n",
      "Epoch 240/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6984 - val_loss: 0.9092\n",
      "Epoch 241/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6983 - val_loss: 0.9093\n",
      "Epoch 242/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6982 - val_loss: 0.9094\n",
      "Epoch 243/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6981 - val_loss: 0.9095\n",
      "Epoch 244/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6979 - val_loss: 0.9096\n",
      "Epoch 245/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6978 - val_loss: 0.9097\n",
      "Epoch 246/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6977 - val_loss: 0.9099\n",
      "Epoch 247/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6976 - val_loss: 0.9100\n",
      "Epoch 248/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6974 - val_loss: 0.9101\n",
      "Epoch 249/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6973 - val_loss: 0.9102\n",
      "Epoch 250/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6972 - val_loss: 0.9103\n",
      "Epoch 251/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6970 - val_loss: 0.9104\n",
      "Epoch 252/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6969 - val_loss: 0.9106\n",
      "Epoch 253/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6968 - val_loss: 0.9107\n",
      "Epoch 254/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6967 - val_loss: 0.9108\n",
      "Epoch 255/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6965 - val_loss: 0.9109\n",
      "Epoch 256/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6964 - val_loss: 0.9110\n",
      "Epoch 257/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6963 - val_loss: 0.9111\n",
      "Epoch 258/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 0.9113\n",
      "Epoch 259/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 0.9114\n",
      "Epoch 260/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6959 - val_loss: 0.9115\n",
      "Epoch 261/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6957 - val_loss: 0.9116\n",
      "Epoch 262/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6956 - val_loss: 0.9117\n",
      "Epoch 263/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6954 - val_loss: 0.9118\n",
      "Epoch 264/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6953 - val_loss: 0.9119\n",
      "Epoch 265/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6952 - val_loss: 0.9120\n",
      "Epoch 266/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6950 - val_loss: 0.9121\n",
      "Epoch 267/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6949 - val_loss: 0.9122\n",
      "Epoch 268/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6948 - val_loss: 0.9123\n",
      "Epoch 269/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6946 - val_loss: 0.9124\n",
      "Epoch 270/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6945 - val_loss: 0.9124\n",
      "Epoch 271/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6944 - val_loss: 0.9125\n",
      "Epoch 272/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6942 - val_loss: 0.9125\n",
      "Epoch 273/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6941 - val_loss: 0.9126\n",
      "Epoch 274/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6940 - val_loss: 0.9126\n",
      "Epoch 275/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6938 - val_loss: 0.9126\n",
      "Epoch 276/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6937 - val_loss: 0.9126\n",
      "Epoch 277/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6936 - val_loss: 0.9126\n",
      "Epoch 278/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6935 - val_loss: 0.9126\n",
      "Epoch 279/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6933 - val_loss: 0.9126\n",
      "Epoch 280/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6932 - val_loss: 0.9125\n",
      "Epoch 281/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6931 - val_loss: 0.9124\n",
      "Epoch 282/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6930 - val_loss: 0.9123\n",
      "Epoch 283/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6929 - val_loss: 0.9122\n",
      "Epoch 284/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6927 - val_loss: 0.9121\n",
      "Epoch 285/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6926 - val_loss: 0.9119\n",
      "Epoch 286/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6925 - val_loss: 0.9117\n",
      "Epoch 287/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6924 - val_loss: 0.9115\n",
      "Epoch 288/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6923 - val_loss: 0.9113\n",
      "Epoch 289/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6922 - val_loss: 0.9110\n",
      "Epoch 290/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6920 - val_loss: 0.9107\n",
      "Epoch 291/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6919 - val_loss: 0.9103\n",
      "Epoch 292/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6918 - val_loss: 0.9100\n",
      "Epoch 293/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6917 - val_loss: 0.9096\n",
      "Epoch 294/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6916 - val_loss: 0.9091\n",
      "Epoch 295/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6914 - val_loss: 0.9086\n",
      "Epoch 296/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6913 - val_loss: 0.9081\n",
      "Epoch 297/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6912 - val_loss: 0.9076\n",
      "Epoch 298/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6910 - val_loss: 0.9070\n",
      "Epoch 299/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6909 - val_loss: 0.9064\n",
      "Epoch 300/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6907 - val_loss: 0.9057\n",
      "Epoch 301/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6906 - val_loss: 0.9050\n",
      "Epoch 302/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6904 - val_loss: 0.9043\n",
      "Epoch 303/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6902 - val_loss: 0.9035\n",
      "Epoch 304/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6900 - val_loss: 0.9027\n",
      "Epoch 305/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.9018\n",
      "Epoch 306/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6897 - val_loss: 0.9010\n",
      "Epoch 307/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6895 - val_loss: 0.9001\n",
      "Epoch 308/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6893 - val_loss: 0.8992\n",
      "Epoch 309/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6890 - val_loss: 0.8983\n",
      "Epoch 310/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6888 - val_loss: 0.8973\n",
      "Epoch 311/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6886 - val_loss: 0.8964\n",
      "Epoch 312/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6884 - val_loss: 0.8954\n",
      "Epoch 313/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6881 - val_loss: 0.8944\n",
      "Epoch 314/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6879 - val_loss: 0.8935\n",
      "Epoch 315/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6876 - val_loss: 0.8925\n",
      "Epoch 316/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6874 - val_loss: 0.8916\n",
      "Epoch 317/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6871 - val_loss: 0.8906\n",
      "Epoch 318/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6868 - val_loss: 0.8897\n",
      "Epoch 319/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6866 - val_loss: 0.8888\n",
      "Epoch 320/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6863 - val_loss: 0.8879\n",
      "Epoch 321/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6860 - val_loss: 0.8870\n",
      "Epoch 322/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6857 - val_loss: 0.8861\n",
      "Epoch 323/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6855 - val_loss: 0.8853\n",
      "Epoch 324/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6852 - val_loss: 0.8845\n",
      "Epoch 325/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6849 - val_loss: 0.8837\n",
      "Epoch 326/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6847 - val_loss: 0.8829\n",
      "Epoch 327/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6844 - val_loss: 0.8822\n",
      "Epoch 328/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6841 - val_loss: 0.8815\n",
      "Epoch 329/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6839 - val_loss: 0.8808\n",
      "Epoch 330/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6837 - val_loss: 0.8801\n",
      "Epoch 331/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6834 - val_loss: 0.8794\n",
      "Epoch 332/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6832 - val_loss: 0.8788\n",
      "Epoch 333/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6830 - val_loss: 0.8781\n",
      "Epoch 334/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6828 - val_loss: 0.8775\n",
      "Epoch 335/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6826 - val_loss: 0.8769\n",
      "Epoch 336/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6825 - val_loss: 0.8763\n",
      "Epoch 337/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6823 - val_loss: 0.8757\n",
      "Epoch 338/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6822 - val_loss: 0.8752\n",
      "Epoch 339/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6820 - val_loss: 0.8746\n",
      "Epoch 340/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6819 - val_loss: 0.8740\n",
      "Epoch 341/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6818 - val_loss: 0.8735\n",
      "Epoch 342/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6817 - val_loss: 0.8729\n",
      "Epoch 343/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6816 - val_loss: 0.8724\n",
      "Epoch 344/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6816 - val_loss: 0.8718\n",
      "Epoch 345/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6815 - val_loss: 0.8713\n",
      "Epoch 346/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6815 - val_loss: 0.8707\n",
      "Epoch 347/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6815 - val_loss: 0.8702\n",
      "Epoch 348/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6815 - val_loss: 0.8697\n",
      "Epoch 349/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6815 - val_loss: 0.8692\n",
      "Epoch 350/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6815 - val_loss: 0.8687\n",
      "Epoch 351/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6816 - val_loss: 0.8682\n",
      "Epoch 352/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6816 - val_loss: 0.8677\n",
      "Epoch 353/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6817 - val_loss: 0.8673\n",
      "Epoch 354/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6818 - val_loss: 0.8669\n",
      "Epoch 355/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6819 - val_loss: 0.8665\n",
      "Epoch 356/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6820 - val_loss: 0.8661\n",
      "Epoch 357/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6822 - val_loss: 0.8657\n",
      "Epoch 358/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6824 - val_loss: 0.8654\n",
      "Epoch 359/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6825 - val_loss: 0.8651\n",
      "Epoch 360/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6827 - val_loss: 0.8648\n",
      "Epoch 361/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6829 - val_loss: 0.8646\n",
      "Epoch 362/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6832 - val_loss: 0.8644\n",
      "Epoch 363/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6834 - val_loss: 0.8643\n",
      "Epoch 364/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6836 - val_loss: 0.8642\n",
      "Epoch 365/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6839 - val_loss: 0.8641\n",
      "Epoch 366/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6842 - val_loss: 0.8641\n",
      "Epoch 367/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6845 - val_loss: 0.8641\n",
      "Epoch 368/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6848 - val_loss: 0.8642\n",
      "Epoch 369/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6851 - val_loss: 0.8644\n",
      "Epoch 370/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6854 - val_loss: 0.8646\n",
      "Epoch 371/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6857 - val_loss: 0.8649\n",
      "Epoch 372/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6861 - val_loss: 0.8653\n",
      "Epoch 373/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6865 - val_loss: 0.8657\n",
      "Epoch 374/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6868 - val_loss: 0.8663\n",
      "Epoch 375/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6872 - val_loss: 0.8668\n",
      "Epoch 376/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6876 - val_loss: 0.8675\n",
      "Epoch 377/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6880 - val_loss: 0.8682\n",
      "Epoch 378/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6884 - val_loss: 0.8690\n",
      "Epoch 379/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6889 - val_loss: 0.8698\n",
      "Epoch 380/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6893 - val_loss: 0.8707\n",
      "Epoch 381/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6897 - val_loss: 0.8717\n",
      "Epoch 382/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6901 - val_loss: 0.8728\n",
      "Epoch 383/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6905 - val_loss: 0.8738\n",
      "Epoch 384/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6909 - val_loss: 0.8750\n",
      "Epoch 385/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6913 - val_loss: 0.8762\n",
      "Epoch 386/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6917 - val_loss: 0.8774\n",
      "Epoch 387/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6921 - val_loss: 0.8787\n",
      "Epoch 388/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6924 - val_loss: 0.8800\n",
      "Epoch 389/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6928 - val_loss: 0.8814\n",
      "Epoch 390/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6931 - val_loss: 0.8829\n",
      "Epoch 391/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6933 - val_loss: 0.8843\n",
      "Epoch 392/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6936 - val_loss: 0.8858\n",
      "Epoch 393/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6938 - val_loss: 0.8874\n",
      "Epoch 394/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6940 - val_loss: 0.8889\n",
      "Epoch 395/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6941 - val_loss: 0.8905\n",
      "Epoch 396/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6942 - val_loss: 0.8921\n",
      "Epoch 397/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6943 - val_loss: 0.8937\n",
      "Epoch 398/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6944 - val_loss: 0.8953\n",
      "Epoch 399/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6944 - val_loss: 0.8969\n",
      "Epoch 400/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6944 - val_loss: 0.8984\n",
      "Epoch 401/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6944 - val_loss: 0.9000\n",
      "Epoch 402/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6944 - val_loss: 0.9014\n",
      "Epoch 403/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6943 - val_loss: 0.9029\n",
      "Epoch 404/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6942 - val_loss: 0.9043\n",
      "Epoch 405/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6941 - val_loss: 0.9056\n",
      "Epoch 406/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6940 - val_loss: 0.9068\n",
      "Epoch 407/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6939 - val_loss: 0.9080\n",
      "Epoch 408/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6938 - val_loss: 0.9092\n",
      "Epoch 409/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6936 - val_loss: 0.9102\n",
      "Epoch 410/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6935 - val_loss: 0.9112\n",
      "Epoch 411/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6934 - val_loss: 0.9121\n",
      "Epoch 412/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6932 - val_loss: 0.9130\n",
      "Epoch 413/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6931 - val_loss: 0.9138\n",
      "Epoch 414/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6929 - val_loss: 0.9145\n",
      "Epoch 415/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6928 - val_loss: 0.9152\n",
      "Epoch 416/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6927 - val_loss: 0.9158\n",
      "Epoch 417/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6925 - val_loss: 0.9163\n",
      "Epoch 418/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6924 - val_loss: 0.9168\n",
      "Epoch 419/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6923 - val_loss: 0.9172\n",
      "Epoch 420/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6921 - val_loss: 0.9175\n",
      "Epoch 421/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6920 - val_loss: 0.9179\n",
      "Epoch 422/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6919 - val_loss: 0.9181\n",
      "Epoch 423/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6918 - val_loss: 0.9183\n",
      "Epoch 424/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6917 - val_loss: 0.9185\n",
      "Epoch 425/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6916 - val_loss: 0.9187\n",
      "Epoch 426/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6915 - val_loss: 0.9188\n",
      "Epoch 427/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6914 - val_loss: 0.9188\n",
      "Epoch 428/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6913 - val_loss: 0.9189\n",
      "Epoch 429/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6912 - val_loss: 0.9189\n",
      "Epoch 430/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6911 - val_loss: 0.9189\n",
      "Epoch 431/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6910 - val_loss: 0.9188\n",
      "Epoch 432/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6909 - val_loss: 0.9188\n",
      "Epoch 433/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6908 - val_loss: 0.9187\n",
      "Epoch 434/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6907 - val_loss: 0.9186\n",
      "Epoch 435/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6906 - val_loss: 0.9184\n",
      "Epoch 436/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6905 - val_loss: 0.9183\n",
      "Epoch 437/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6905 - val_loss: 0.9182\n",
      "Epoch 438/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6904 - val_loss: 0.9180\n",
      "Epoch 439/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6903 - val_loss: 0.9178\n",
      "Epoch 440/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6902 - val_loss: 0.9176\n",
      "Epoch 441/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6902 - val_loss: 0.9174\n",
      "Epoch 442/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6901 - val_loss: 0.9172\n",
      "Epoch 443/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6900 - val_loss: 0.9170\n",
      "Epoch 444/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.9168\n",
      "Epoch 445/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.9166\n",
      "Epoch 446/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.9164\n",
      "Epoch 447/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6897 - val_loss: 0.9162\n",
      "Epoch 448/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6896 - val_loss: 0.9160\n",
      "Epoch 449/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6896 - val_loss: 0.9157\n",
      "Epoch 450/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6895 - val_loss: 0.9155\n",
      "Epoch 451/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6894 - val_loss: 0.9153\n",
      "Epoch 452/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6893 - val_loss: 0.9151\n",
      "Epoch 453/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6893 - val_loss: 0.9149\n",
      "Epoch 454/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6892 - val_loss: 0.9146\n",
      "Epoch 455/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6891 - val_loss: 0.9144\n",
      "Epoch 456/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6890 - val_loss: 0.9142\n",
      "Epoch 457/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6890 - val_loss: 0.9140\n",
      "Epoch 458/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6889 - val_loss: 0.9138\n",
      "Epoch 459/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6888 - val_loss: 0.9136\n",
      "Epoch 460/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6887 - val_loss: 0.9134\n",
      "Epoch 461/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6886 - val_loss: 0.9132\n",
      "Epoch 462/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6885 - val_loss: 0.9130\n",
      "Epoch 463/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6885 - val_loss: 0.9128\n",
      "Epoch 464/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6884 - val_loss: 0.9126\n",
      "Epoch 465/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6883 - val_loss: 0.9124\n",
      "Epoch 466/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6882 - val_loss: 0.9122\n",
      "Epoch 467/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6881 - val_loss: 0.9120\n",
      "Epoch 468/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6880 - val_loss: 0.9118\n",
      "Epoch 469/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6879 - val_loss: 0.9117\n",
      "Epoch 470/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6878 - val_loss: 0.9115\n",
      "Epoch 471/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6877 - val_loss: 0.9113\n",
      "Epoch 472/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6876 - val_loss: 0.9111\n",
      "Epoch 473/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6875 - val_loss: 0.9110\n",
      "Epoch 474/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6874 - val_loss: 0.9108\n",
      "Epoch 475/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6872 - val_loss: 0.9107\n",
      "Epoch 476/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6871 - val_loss: 0.9105\n",
      "Epoch 477/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6870 - val_loss: 0.9104\n",
      "Epoch 478/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6869 - val_loss: 0.9103\n",
      "Epoch 479/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6867 - val_loss: 0.9101\n",
      "Epoch 480/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6866 - val_loss: 0.9100\n",
      "Epoch 481/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6865 - val_loss: 0.9099\n",
      "Epoch 482/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6863 - val_loss: 0.9098\n",
      "Epoch 483/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6862 - val_loss: 0.9096\n",
      "Epoch 484/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6861 - val_loss: 0.9095\n",
      "Epoch 485/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6859 - val_loss: 0.9094\n",
      "Epoch 486/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6858 - val_loss: 0.9093\n",
      "Epoch 487/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6856 - val_loss: 0.9093\n",
      "Epoch 488/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6854 - val_loss: 0.9092\n",
      "Epoch 489/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6853 - val_loss: 0.9091\n",
      "Epoch 490/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6851 - val_loss: 0.9090\n",
      "Epoch 491/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6849 - val_loss: 0.9090\n",
      "Epoch 492/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6848 - val_loss: 0.9089\n",
      "Epoch 493/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6846 - val_loss: 0.9088\n",
      "Epoch 494/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6844 - val_loss: 0.9088\n",
      "Epoch 495/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6842 - val_loss: 0.9087\n",
      "Epoch 496/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6840 - val_loss: 0.9087\n",
      "Epoch 497/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6838 - val_loss: 0.9087\n",
      "Epoch 498/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6836 - val_loss: 0.9086\n",
      "Epoch 499/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6834 - val_loss: 0.9086\n",
      "Epoch 500/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6832 - val_loss: 0.9086\n",
      "Epoch 501/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6830 - val_loss: 0.9086\n",
      "Epoch 502/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6828 - val_loss: 0.9086\n",
      "Epoch 503/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6826 - val_loss: 0.9086\n",
      "Epoch 504/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6824 - val_loss: 0.9086\n",
      "Epoch 505/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6822 - val_loss: 0.9086\n",
      "Epoch 506/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6819 - val_loss: 0.9086\n",
      "Epoch 507/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6817 - val_loss: 0.9086\n",
      "Epoch 508/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6815 - val_loss: 0.9086\n",
      "Epoch 509/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6812 - val_loss: 0.9086\n",
      "Epoch 510/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6810 - val_loss: 0.9087\n",
      "Epoch 511/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6808 - val_loss: 0.9087\n",
      "Epoch 512/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6805 - val_loss: 0.9087\n",
      "Epoch 513/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6803 - val_loss: 0.9088\n",
      "Epoch 514/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6800 - val_loss: 0.9088\n",
      "Epoch 515/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6798 - val_loss: 0.9089\n",
      "Epoch 516/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6795 - val_loss: 0.9089\n",
      "Epoch 517/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6792 - val_loss: 0.9090\n",
      "Epoch 518/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6790 - val_loss: 0.9091\n",
      "Epoch 519/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6787 - val_loss: 0.9091\n",
      "Epoch 520/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6784 - val_loss: 0.9092\n",
      "Epoch 521/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6781 - val_loss: 0.9093\n",
      "Epoch 522/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 0.9094\n",
      "Epoch 523/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6776 - val_loss: 0.9095\n",
      "Epoch 524/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6773 - val_loss: 0.9095\n",
      "Epoch 525/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6770 - val_loss: 0.9096\n",
      "Epoch 526/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6767 - val_loss: 0.9097\n",
      "Epoch 527/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6764 - val_loss: 0.9098\n",
      "Epoch 528/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6761 - val_loss: 0.9099\n",
      "Epoch 529/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6758 - val_loss: 0.9100\n",
      "Epoch 530/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6755 - val_loss: 0.9101\n",
      "Epoch 531/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6752 - val_loss: 0.9102\n",
      "Epoch 532/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6749 - val_loss: 0.9103\n",
      "Epoch 533/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6746 - val_loss: 0.9104\n",
      "Epoch 534/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6743 - val_loss: 0.9106\n",
      "Epoch 535/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6740 - val_loss: 0.9107\n",
      "Epoch 536/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6737 - val_loss: 0.9108\n",
      "Epoch 537/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6734 - val_loss: 0.9109\n",
      "Epoch 538/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6731 - val_loss: 0.9110\n",
      "Epoch 539/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6728 - val_loss: 0.9111\n",
      "Epoch 540/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6724 - val_loss: 0.9113\n",
      "Epoch 541/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6721 - val_loss: 0.9114\n",
      "Epoch 542/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6718 - val_loss: 0.9115\n",
      "Epoch 543/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6715 - val_loss: 0.9116\n",
      "Epoch 544/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6712 - val_loss: 0.9117\n",
      "Epoch 545/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6709 - val_loss: 0.9119\n",
      "Epoch 546/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6705 - val_loss: 0.9120\n",
      "Epoch 547/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6702 - val_loss: 0.9121\n",
      "Epoch 548/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6699 - val_loss: 0.9122\n",
      "Epoch 549/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6696 - val_loss: 0.9124\n",
      "Epoch 550/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6692 - val_loss: 0.9125\n",
      "Epoch 551/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6689 - val_loss: 0.9126\n",
      "Epoch 552/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6686 - val_loss: 0.9127\n",
      "Epoch 553/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6683 - val_loss: 0.9129\n",
      "Epoch 554/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6680 - val_loss: 0.9130\n",
      "Epoch 555/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6676 - val_loss: 0.9131\n",
      "Epoch 556/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6673 - val_loss: 0.9132\n",
      "Epoch 557/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6670 - val_loss: 0.9134\n",
      "Epoch 558/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6667 - val_loss: 0.9135\n",
      "Epoch 559/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6664 - val_loss: 0.9136\n",
      "Epoch 560/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6660 - val_loss: 0.9137\n",
      "Epoch 561/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6657 - val_loss: 0.9138\n",
      "Epoch 562/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6654 - val_loss: 0.9140\n",
      "Epoch 563/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6651 - val_loss: 0.9141\n",
      "Epoch 564/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6648 - val_loss: 0.9142\n",
      "Epoch 565/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6645 - val_loss: 0.9143\n",
      "Epoch 566/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6642 - val_loss: 0.9144\n",
      "Epoch 567/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6639 - val_loss: 0.9145\n",
      "Epoch 568/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6636 - val_loss: 0.9146\n",
      "Epoch 569/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6633 - val_loss: 0.9147\n",
      "Epoch 570/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6630 - val_loss: 0.9148\n",
      "Epoch 571/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6627 - val_loss: 0.9149\n",
      "Epoch 572/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6624 - val_loss: 0.9150\n",
      "Epoch 573/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.9151\n",
      "Epoch 574/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6618 - val_loss: 0.9152\n",
      "Epoch 575/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6615 - val_loss: 0.9153\n",
      "Epoch 576/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6612 - val_loss: 0.9154\n",
      "Epoch 577/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6610 - val_loss: 0.9155\n",
      "Epoch 578/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6607 - val_loss: 0.9155\n",
      "Epoch 579/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6604 - val_loss: 0.9156\n",
      "Epoch 580/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6601 - val_loss: 0.9157\n",
      "Epoch 581/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6599 - val_loss: 0.9158\n",
      "Epoch 582/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6596 - val_loss: 0.9158\n",
      "Epoch 583/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6593 - val_loss: 0.9159\n",
      "Epoch 584/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6591 - val_loss: 0.9160\n",
      "Epoch 585/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6588 - val_loss: 0.9160\n",
      "Epoch 586/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6586 - val_loss: 0.9161\n",
      "Epoch 587/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6583 - val_loss: 0.9161\n",
      "Epoch 588/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6581 - val_loss: 0.9162\n",
      "Epoch 589/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6578 - val_loss: 0.9162\n",
      "Epoch 590/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6576 - val_loss: 0.9163\n",
      "Epoch 591/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6573 - val_loss: 0.9163\n",
      "Epoch 592/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6571 - val_loss: 0.9164\n",
      "Epoch 593/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6569 - val_loss: 0.9164\n",
      "Epoch 594/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6566 - val_loss: 0.9164\n",
      "Epoch 595/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6564 - val_loss: 0.9164\n",
      "Epoch 596/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6562 - val_loss: 0.9165\n",
      "Epoch 597/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6560 - val_loss: 0.9165\n",
      "Epoch 598/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6558 - val_loss: 0.9165\n",
      "Epoch 599/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6556 - val_loss: 0.9165\n",
      "Epoch 600/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6553 - val_loss: 0.9165\n",
      "Epoch 601/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.6551 - val_loss: 0.9166\n",
      "Epoch 602/1000\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.6549 - val_loss: 0.9166\n",
      "Epoch 603/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6547 - val_loss: 0.9166\n",
      "Epoch 604/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6545 - val_loss: 0.9166\n",
      "Epoch 605/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6544 - val_loss: 0.9166\n",
      "Epoch 606/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6542 - val_loss: 0.9165\n",
      "Epoch 607/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6540 - val_loss: 0.9165\n",
      "Epoch 608/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6538 - val_loss: 0.9165\n",
      "Epoch 609/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6536 - val_loss: 0.9165\n",
      "Epoch 610/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6534 - val_loss: 0.9165\n",
      "Epoch 611/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6533 - val_loss: 0.9164\n",
      "Epoch 612/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6531 - val_loss: 0.9164\n",
      "Epoch 613/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6529 - val_loss: 0.9164\n",
      "Epoch 614/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6528 - val_loss: 0.9163\n",
      "Epoch 615/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6526 - val_loss: 0.9163\n",
      "Epoch 616/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6524 - val_loss: 0.9163\n",
      "Epoch 617/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6523 - val_loss: 0.9162\n",
      "Epoch 618/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6521 - val_loss: 0.9162\n",
      "Epoch 619/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6520 - val_loss: 0.9161\n",
      "Epoch 620/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6518 - val_loss: 0.9161\n",
      "Epoch 621/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6517 - val_loss: 0.9160\n",
      "Epoch 622/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6515 - val_loss: 0.9159\n",
      "Epoch 623/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6514 - val_loss: 0.9159\n",
      "Epoch 624/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6513 - val_loss: 0.9158\n",
      "Epoch 625/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6511 - val_loss: 0.9157\n",
      "Epoch 626/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6510 - val_loss: 0.9156\n",
      "Epoch 627/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6509 - val_loss: 0.9156\n",
      "Epoch 628/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6507 - val_loss: 0.9155\n",
      "Epoch 629/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6506 - val_loss: 0.9154\n",
      "Epoch 630/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6505 - val_loss: 0.9153\n",
      "Epoch 631/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6504 - val_loss: 0.9152\n",
      "Epoch 632/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6502 - val_loss: 0.9151\n",
      "Epoch 633/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6501 - val_loss: 0.9150\n",
      "Epoch 634/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6500 - val_loss: 0.9149\n",
      "Epoch 635/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6499 - val_loss: 0.9148\n",
      "Epoch 636/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6498 - val_loss: 0.9147\n",
      "Epoch 637/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6496 - val_loss: 0.9146\n",
      "Epoch 638/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6495 - val_loss: 0.9144\n",
      "Epoch 639/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6494 - val_loss: 0.9143\n",
      "Epoch 640/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6493 - val_loss: 0.9142\n",
      "Epoch 641/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6492 - val_loss: 0.9141\n",
      "Epoch 642/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6491 - val_loss: 0.9139\n",
      "Epoch 643/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6490 - val_loss: 0.9138\n",
      "Epoch 644/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6489 - val_loss: 0.9137\n",
      "Epoch 645/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6488 - val_loss: 0.9135\n",
      "Epoch 646/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6487 - val_loss: 0.9134\n",
      "Epoch 647/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6486 - val_loss: 0.9132\n",
      "Epoch 648/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6485 - val_loss: 0.9131\n",
      "Epoch 649/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6484 - val_loss: 0.9129\n",
      "Epoch 650/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6483 - val_loss: 0.9128\n",
      "Epoch 651/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6482 - val_loss: 0.9126\n",
      "Epoch 652/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6481 - val_loss: 0.9125\n",
      "Epoch 653/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6480 - val_loss: 0.9123\n",
      "Epoch 654/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6479 - val_loss: 0.9121\n",
      "Epoch 655/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6478 - val_loss: 0.9120\n",
      "Epoch 656/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6477 - val_loss: 0.9118\n",
      "Epoch 657/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6476 - val_loss: 0.9116\n",
      "Epoch 658/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6475 - val_loss: 0.9114\n",
      "Epoch 659/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6474 - val_loss: 0.9113\n",
      "Epoch 660/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6473 - val_loss: 0.9111\n",
      "Epoch 661/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6472 - val_loss: 0.9109\n",
      "Epoch 662/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6471 - val_loss: 0.9107\n",
      "Epoch 663/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6470 - val_loss: 0.9105\n",
      "Epoch 664/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6469 - val_loss: 0.9103\n",
      "Epoch 665/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6468 - val_loss: 0.9101\n",
      "Epoch 666/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6468 - val_loss: 0.9099\n",
      "Epoch 667/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6467 - val_loss: 0.9097\n",
      "Epoch 668/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6466 - val_loss: 0.9095\n",
      "Epoch 669/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6465 - val_loss: 0.9093\n",
      "Epoch 670/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6464 - val_loss: 0.9091\n",
      "Epoch 671/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6463 - val_loss: 0.9089\n",
      "Epoch 672/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6462 - val_loss: 0.9087\n",
      "Epoch 673/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6461 - val_loss: 0.9085\n",
      "Epoch 674/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6460 - val_loss: 0.9083\n",
      "Epoch 675/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6459 - val_loss: 0.9081\n",
      "Epoch 676/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6459 - val_loss: 0.9079\n",
      "Epoch 677/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6458 - val_loss: 0.9077\n",
      "Epoch 678/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6457 - val_loss: 0.9074\n",
      "Epoch 679/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6456 - val_loss: 0.9072\n",
      "Epoch 680/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6455 - val_loss: 0.9070\n",
      "Epoch 681/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6454 - val_loss: 0.9068\n",
      "Epoch 682/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6453 - val_loss: 0.9066\n",
      "Epoch 683/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6452 - val_loss: 0.9063\n",
      "Epoch 684/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6452 - val_loss: 0.9061\n",
      "Epoch 685/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6451 - val_loss: 0.9059\n",
      "Epoch 686/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6450 - val_loss: 0.9057\n",
      "Epoch 687/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6449 - val_loss: 0.9054\n",
      "Epoch 688/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6448 - val_loss: 0.9052\n",
      "Epoch 689/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6447 - val_loss: 0.9050\n",
      "Epoch 690/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6446 - val_loss: 0.9048\n",
      "Epoch 691/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6446 - val_loss: 0.9045\n",
      "Epoch 692/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6445 - val_loss: 0.9043\n",
      "Epoch 693/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6444 - val_loss: 0.9041\n",
      "Epoch 694/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6443 - val_loss: 0.9039\n",
      "Epoch 695/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6442 - val_loss: 0.9036\n",
      "Epoch 696/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6441 - val_loss: 0.9034\n",
      "Epoch 697/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6440 - val_loss: 0.9032\n",
      "Epoch 698/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6439 - val_loss: 0.9029\n",
      "Epoch 699/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6439 - val_loss: 0.9027\n",
      "Epoch 700/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6438 - val_loss: 0.9025\n",
      "Epoch 701/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6437 - val_loss: 0.9023\n",
      "Epoch 702/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6436 - val_loss: 0.9020\n",
      "Epoch 703/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6435 - val_loss: 0.9018\n",
      "Epoch 704/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6434 - val_loss: 0.9016\n",
      "Epoch 705/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6433 - val_loss: 0.9013\n",
      "Epoch 706/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6433 - val_loss: 0.9011\n",
      "Epoch 707/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6432 - val_loss: 0.9009\n",
      "Epoch 708/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6431 - val_loss: 0.9007\n",
      "Epoch 709/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6430 - val_loss: 0.9004\n",
      "Epoch 710/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6429 - val_loss: 0.9002\n",
      "Epoch 711/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6428 - val_loss: 0.9000\n",
      "Epoch 712/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6427 - val_loss: 0.8998\n",
      "Epoch 713/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6427 - val_loss: 0.8995\n",
      "Epoch 714/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6426 - val_loss: 0.8993\n",
      "Epoch 715/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6425 - val_loss: 0.8991\n",
      "Epoch 716/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6424 - val_loss: 0.8989\n",
      "Epoch 717/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6423 - val_loss: 0.8986\n",
      "Epoch 718/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6422 - val_loss: 0.8984\n",
      "Epoch 719/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6421 - val_loss: 0.8982\n",
      "Epoch 720/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6421 - val_loss: 0.8980\n",
      "Epoch 721/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6420 - val_loss: 0.8978\n",
      "Epoch 722/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6419 - val_loss: 0.8975\n",
      "Epoch 723/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6418 - val_loss: 0.8973\n",
      "Epoch 724/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6417 - val_loss: 0.8971\n",
      "Epoch 725/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6416 - val_loss: 0.8969\n",
      "Epoch 726/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6415 - val_loss: 0.8967\n",
      "Epoch 727/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6415 - val_loss: 0.8965\n",
      "Epoch 728/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6414 - val_loss: 0.8963\n",
      "Epoch 729/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6413 - val_loss: 0.8960\n",
      "Epoch 730/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6412 - val_loss: 0.8958\n",
      "Epoch 731/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6411 - val_loss: 0.8956\n",
      "Epoch 732/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6410 - val_loss: 0.8954\n",
      "Epoch 733/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6410 - val_loss: 0.8952\n",
      "Epoch 734/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6409 - val_loss: 0.8950\n",
      "Epoch 735/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6408 - val_loss: 0.8948\n",
      "Epoch 736/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6407 - val_loss: 0.8946\n",
      "Epoch 737/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6406 - val_loss: 0.8944\n",
      "Epoch 738/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6405 - val_loss: 0.8942\n",
      "Epoch 739/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6405 - val_loss: 0.8940\n",
      "Epoch 740/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6404 - val_loss: 0.8938\n",
      "Epoch 741/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6403 - val_loss: 0.8936\n",
      "Epoch 742/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6402 - val_loss: 0.8934\n",
      "Epoch 743/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6401 - val_loss: 0.8932\n",
      "Epoch 744/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6400 - val_loss: 0.8930\n",
      "Epoch 745/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6400 - val_loss: 0.8928\n",
      "Epoch 746/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6399 - val_loss: 0.8926\n",
      "Epoch 747/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6398 - val_loss: 0.8924\n",
      "Epoch 748/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6397 - val_loss: 0.8922\n",
      "Epoch 749/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6396 - val_loss: 0.8920\n",
      "Epoch 750/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6396 - val_loss: 0.8918\n",
      "Epoch 751/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6395 - val_loss: 0.8916\n",
      "Epoch 752/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6394 - val_loss: 0.8914\n",
      "Epoch 753/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6393 - val_loss: 0.8912\n",
      "Epoch 754/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6392 - val_loss: 0.8910\n",
      "Epoch 755/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6392 - val_loss: 0.8909\n",
      "Epoch 756/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6391 - val_loss: 0.8907\n",
      "Epoch 757/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6390 - val_loss: 0.8905\n",
      "Epoch 758/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6389 - val_loss: 0.8903\n",
      "Epoch 759/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6388 - val_loss: 0.8901\n",
      "Epoch 760/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6388 - val_loss: 0.8899\n",
      "Epoch 761/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6387 - val_loss: 0.8897\n",
      "Epoch 762/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6386 - val_loss: 0.8895\n",
      "Epoch 763/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6385 - val_loss: 0.8894\n",
      "Epoch 764/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6384 - val_loss: 0.8892\n",
      "Epoch 765/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6384 - val_loss: 0.8890\n",
      "Epoch 766/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6383 - val_loss: 0.8888\n",
      "Epoch 767/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6382 - val_loss: 0.8886\n",
      "Epoch 768/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6381 - val_loss: 0.8884\n",
      "Epoch 769/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6381 - val_loss: 0.8883\n",
      "Epoch 770/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6380 - val_loss: 0.8881\n",
      "Epoch 771/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6379 - val_loss: 0.8879\n",
      "Epoch 772/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6378 - val_loss: 0.8877\n",
      "Epoch 773/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6377 - val_loss: 0.8875\n",
      "Epoch 774/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6377 - val_loss: 0.8874\n",
      "Epoch 775/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6376 - val_loss: 0.8872\n",
      "Epoch 776/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6375 - val_loss: 0.8870\n",
      "Epoch 777/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6374 - val_loss: 0.8868\n",
      "Epoch 778/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6374 - val_loss: 0.8866\n",
      "Epoch 779/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6373 - val_loss: 0.8865\n",
      "Epoch 780/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6372 - val_loss: 0.8863\n",
      "Epoch 781/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6372 - val_loss: 0.8861\n",
      "Epoch 782/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6371 - val_loss: 0.8859\n",
      "Epoch 783/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6370 - val_loss: 0.8857\n",
      "Epoch 784/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6369 - val_loss: 0.8856\n",
      "Epoch 785/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6369 - val_loss: 0.8854\n",
      "Epoch 786/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6368 - val_loss: 0.8852\n",
      "Epoch 787/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6367 - val_loss: 0.8850\n",
      "Epoch 788/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6366 - val_loss: 0.8848\n",
      "Epoch 789/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6366 - val_loss: 0.8847\n",
      "Epoch 790/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6365 - val_loss: 0.8845\n",
      "Epoch 791/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6364 - val_loss: 0.8843\n",
      "Epoch 792/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6364 - val_loss: 0.8841\n",
      "Epoch 793/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6363 - val_loss: 0.8839\n",
      "Epoch 794/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6362 - val_loss: 0.8838\n",
      "Epoch 795/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6361 - val_loss: 0.8836\n",
      "Epoch 796/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6361 - val_loss: 0.8834\n",
      "Epoch 797/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6360 - val_loss: 0.8832\n",
      "Epoch 798/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6359 - val_loss: 0.8830\n",
      "Epoch 799/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6359 - val_loss: 0.8829\n",
      "Epoch 800/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6358 - val_loss: 0.8827\n",
      "Epoch 801/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6357 - val_loss: 0.8825\n",
      "Epoch 802/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6357 - val_loss: 0.8823\n",
      "Epoch 803/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6356 - val_loss: 0.8821\n",
      "Epoch 804/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6355 - val_loss: 0.8820\n",
      "Epoch 805/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6355 - val_loss: 0.8818\n",
      "Epoch 806/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6354 - val_loss: 0.8816\n",
      "Epoch 807/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6353 - val_loss: 0.8814\n",
      "Epoch 808/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6353 - val_loss: 0.8812\n",
      "Epoch 809/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6352 - val_loss: 0.8810\n",
      "Epoch 810/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6351 - val_loss: 0.8809\n",
      "Epoch 811/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6351 - val_loss: 0.8807\n",
      "Epoch 812/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6350 - val_loss: 0.8805\n",
      "Epoch 813/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6349 - val_loss: 0.8803\n",
      "Epoch 814/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6349 - val_loss: 0.8801\n",
      "Epoch 815/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6348 - val_loss: 0.8799\n",
      "Epoch 816/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6347 - val_loss: 0.8798\n",
      "Epoch 817/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6347 - val_loss: 0.8796\n",
      "Epoch 818/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6346 - val_loss: 0.8794\n",
      "Epoch 819/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6345 - val_loss: 0.8792\n",
      "Epoch 820/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6345 - val_loss: 0.8790\n",
      "Epoch 821/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6344 - val_loss: 0.8788\n",
      "Epoch 822/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6344 - val_loss: 0.8787\n",
      "Epoch 823/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6343 - val_loss: 0.8785\n",
      "Epoch 824/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6342 - val_loss: 0.8783\n",
      "Epoch 825/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6342 - val_loss: 0.8781\n",
      "Epoch 826/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6341 - val_loss: 0.8779\n",
      "Epoch 827/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6340 - val_loss: 0.8777\n",
      "Epoch 828/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6340 - val_loss: 0.8775\n",
      "Epoch 829/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6339 - val_loss: 0.8773\n",
      "Epoch 830/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6339 - val_loss: 0.8772\n",
      "Epoch 831/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6338 - val_loss: 0.8770\n",
      "Epoch 832/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6337 - val_loss: 0.8768\n",
      "Epoch 833/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6337 - val_loss: 0.8766\n",
      "Epoch 834/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6336 - val_loss: 0.8764\n",
      "Epoch 835/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6336 - val_loss: 0.8762\n",
      "Epoch 836/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6335 - val_loss: 0.8760\n",
      "Epoch 837/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6334 - val_loss: 0.8758\n",
      "Epoch 838/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6334 - val_loss: 0.8757\n",
      "Epoch 839/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6333 - val_loss: 0.8755\n",
      "Epoch 840/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6333 - val_loss: 0.8753\n",
      "Epoch 841/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6332 - val_loss: 0.8751\n",
      "Epoch 842/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6331 - val_loss: 0.8749\n",
      "Epoch 843/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6331 - val_loss: 0.8747\n",
      "Epoch 844/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6330 - val_loss: 0.8745\n",
      "Epoch 845/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6330 - val_loss: 0.8743\n",
      "Epoch 846/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6329 - val_loss: 0.8741\n",
      "Epoch 847/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6329 - val_loss: 0.8740\n",
      "Epoch 848/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6328 - val_loss: 0.8738\n",
      "Epoch 849/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6327 - val_loss: 0.8736\n",
      "Epoch 850/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6327 - val_loss: 0.8734\n",
      "Epoch 851/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6326 - val_loss: 0.8732\n",
      "Epoch 852/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6326 - val_loss: 0.8730\n",
      "Epoch 853/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6325 - val_loss: 0.8728\n",
      "Epoch 854/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6325 - val_loss: 0.8726\n",
      "Epoch 855/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6324 - val_loss: 0.8724\n",
      "Epoch 856/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6324 - val_loss: 0.8722\n",
      "Epoch 857/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6323 - val_loss: 0.8720\n",
      "Epoch 858/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6322 - val_loss: 0.8719\n",
      "Epoch 859/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6322 - val_loss: 0.8717\n",
      "Epoch 860/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6321 - val_loss: 0.8715\n",
      "Epoch 861/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6321 - val_loss: 0.8713\n",
      "Epoch 862/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6320 - val_loss: 0.8711\n",
      "Epoch 863/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6320 - val_loss: 0.8709\n",
      "Epoch 864/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6319 - val_loss: 0.8707\n",
      "Epoch 865/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6319 - val_loss: 0.8705\n",
      "Epoch 866/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6318 - val_loss: 0.8703\n",
      "Epoch 867/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6318 - val_loss: 0.8701\n",
      "Epoch 868/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6317 - val_loss: 0.8699\n",
      "Epoch 869/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6317 - val_loss: 0.8697\n",
      "Epoch 870/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6316 - val_loss: 0.8695\n",
      "Epoch 871/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6316 - val_loss: 0.8694\n",
      "Epoch 872/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6315 - val_loss: 0.8692\n",
      "Epoch 873/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6315 - val_loss: 0.8690\n",
      "Epoch 874/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6314 - val_loss: 0.8688\n",
      "Epoch 875/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6314 - val_loss: 0.8686\n",
      "Epoch 876/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8684\n",
      "Epoch 877/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.8682\n",
      "Epoch 878/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8680\n",
      "Epoch 879/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.8678\n",
      "Epoch 880/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8676\n",
      "Epoch 881/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.8674\n",
      "Epoch 882/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8672\n",
      "Epoch 883/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6310 - val_loss: 0.8671\n",
      "Epoch 884/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8669\n",
      "Epoch 885/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.8667\n",
      "Epoch 886/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8665\n",
      "Epoch 887/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.8663\n",
      "Epoch 888/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.8661\n",
      "Epoch 889/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.8659\n",
      "Epoch 890/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8657\n",
      "Epoch 891/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.8655\n",
      "Epoch 892/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.8653\n",
      "Epoch 893/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.8652\n",
      "Epoch 894/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.8650\n",
      "Epoch 895/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.8648\n",
      "Epoch 896/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.8646\n",
      "Epoch 897/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.8644\n",
      "Epoch 898/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6302 - val_loss: 0.8642\n",
      "Epoch 899/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6302 - val_loss: 0.8640\n",
      "Epoch 900/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.8638\n",
      "Epoch 901/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.8636\n",
      "Epoch 902/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.8635\n",
      "Epoch 903/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6300 - val_loss: 0.8633\n",
      "Epoch 904/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6300 - val_loss: 0.8631\n",
      "Epoch 905/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.8629\n",
      "Epoch 906/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.8627\n",
      "Epoch 907/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.8625\n",
      "Epoch 908/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.8623\n",
      "Epoch 909/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.8621\n",
      "Epoch 910/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.8620\n",
      "Epoch 911/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.8618\n",
      "Epoch 912/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.8616\n",
      "Epoch 913/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.8614\n",
      "Epoch 914/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6295 - val_loss: 0.8612\n",
      "Epoch 915/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6295 - val_loss: 0.8610\n",
      "Epoch 916/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.8609\n",
      "Epoch 917/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.8607\n",
      "Epoch 918/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6293 - val_loss: 0.8605\n",
      "Epoch 919/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6293 - val_loss: 0.8603\n",
      "Epoch 920/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6293 - val_loss: 0.8601\n",
      "Epoch 921/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.8599\n",
      "Epoch 922/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.8598\n",
      "Epoch 923/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.8596\n",
      "Epoch 924/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.8594\n",
      "Epoch 925/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8592\n",
      "Epoch 926/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8590\n",
      "Epoch 927/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.8589\n",
      "Epoch 928/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.8587\n",
      "Epoch 929/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.8585\n",
      "Epoch 930/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8583\n",
      "Epoch 931/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8581\n",
      "Epoch 932/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.8580\n",
      "Epoch 933/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8578\n",
      "Epoch 934/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.8576\n",
      "Epoch 935/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.8574\n",
      "Epoch 936/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.8573\n",
      "Epoch 937/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.8571\n",
      "Epoch 938/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6285 - val_loss: 0.8569\n",
      "Epoch 939/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6285 - val_loss: 0.8567\n",
      "Epoch 940/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6284 - val_loss: 0.8566\n",
      "Epoch 941/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6284 - val_loss: 0.8564\n",
      "Epoch 942/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6284 - val_loss: 0.8562\n",
      "Epoch 943/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6283 - val_loss: 0.8560\n",
      "Epoch 944/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6283 - val_loss: 0.8559\n",
      "Epoch 945/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6282 - val_loss: 0.8557\n",
      "Epoch 946/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6282 - val_loss: 0.8555\n",
      "Epoch 947/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6282 - val_loss: 0.8553\n",
      "Epoch 948/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6281 - val_loss: 0.8552\n",
      "Epoch 949/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6281 - val_loss: 0.8550\n",
      "Epoch 950/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6281 - val_loss: 0.8548\n",
      "Epoch 951/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6280 - val_loss: 0.8547\n",
      "Epoch 952/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6280 - val_loss: 0.8545\n",
      "Epoch 953/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6279 - val_loss: 0.8543\n",
      "Epoch 954/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6279 - val_loss: 0.8542\n",
      "Epoch 955/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6279 - val_loss: 0.8540\n",
      "Epoch 956/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6278 - val_loss: 0.8538\n",
      "Epoch 957/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6278 - val_loss: 0.8537\n",
      "Epoch 958/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6278 - val_loss: 0.8535\n",
      "Epoch 959/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6277 - val_loss: 0.8533\n",
      "Epoch 960/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6277 - val_loss: 0.8532\n",
      "Epoch 961/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6276 - val_loss: 0.8530\n",
      "Epoch 962/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6276 - val_loss: 0.8528\n",
      "Epoch 963/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6276 - val_loss: 0.8527\n",
      "Epoch 964/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6275 - val_loss: 0.8525\n",
      "Epoch 965/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6275 - val_loss: 0.8524\n",
      "Epoch 966/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6275 - val_loss: 0.8522\n",
      "Epoch 967/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6274 - val_loss: 0.8520\n",
      "Epoch 968/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6274 - val_loss: 0.8519\n",
      "Epoch 969/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6274 - val_loss: 0.8517\n",
      "Epoch 970/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6273 - val_loss: 0.8516\n",
      "Epoch 971/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6273 - val_loss: 0.8514\n",
      "Epoch 972/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6273 - val_loss: 0.8512\n",
      "Epoch 973/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6272 - val_loss: 0.8511\n",
      "Epoch 974/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6272 - val_loss: 0.8509\n",
      "Epoch 975/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6272 - val_loss: 0.8508\n",
      "Epoch 976/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6271 - val_loss: 0.8506\n",
      "Epoch 977/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6271 - val_loss: 0.8505\n",
      "Epoch 978/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6271 - val_loss: 0.8503\n",
      "Epoch 979/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6270 - val_loss: 0.8502\n",
      "Epoch 980/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6270 - val_loss: 0.8500\n",
      "Epoch 981/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6270 - val_loss: 0.8499\n",
      "Epoch 982/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6269 - val_loss: 0.8497\n",
      "Epoch 983/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6269 - val_loss: 0.8496\n",
      "Epoch 984/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6269 - val_loss: 0.8494\n",
      "Epoch 985/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6268 - val_loss: 0.8493\n",
      "Epoch 986/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6268 - val_loss: 0.8491\n",
      "Epoch 987/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6268 - val_loss: 0.8490\n",
      "Epoch 988/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6267 - val_loss: 0.8488\n",
      "Epoch 989/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6267 - val_loss: 0.8487\n",
      "Epoch 990/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6267 - val_loss: 0.8485\n",
      "Epoch 991/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6266 - val_loss: 0.8484\n",
      "Epoch 992/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6266 - val_loss: 0.8482\n",
      "Epoch 993/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6266 - val_loss: 0.8481\n",
      "Epoch 994/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6265 - val_loss: 0.8479\n",
      "Epoch 995/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6265 - val_loss: 0.8478\n",
      "Epoch 996/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6265 - val_loss: 0.8476\n",
      "Epoch 997/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.8475\n",
      "Epoch 998/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.8474\n",
      "Epoch 999/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.8472\n",
      "Epoch 1000/1000\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.6263 - val_loss: 0.8471\n"
     ]
    }
   ],
   "source": [
    "epocas = 1000\n",
    "history = modelo4.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=lote,\n",
    "    epochs=epocas,\n",
    "    shuffle=False,\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de resultados\n",
    "### Comparación de modelos LSTM\n",
    "Basandose en los cuatro modelos LSTM generados, se pudo ver que mientras más capas de LSTM se implementaron hubo un menor sobreajuste, por tanto, se obtuvo una mayor precisión para los resultados pero el proceso fue más lento. Además, se observó que los modelos multivariables con las variables del precio de diesel y el mes de importación tuvieron resultados mejores que con solo una variable. Por otra parte, cabe resaltar que el mejor optimizador para las redes LSTM en este caso fue rmsprop.\n",
    "\n",
    "### Comparación del mejor modelo LSTM vs modelo SARIMAX\n",
    "Si comparamos al mejor modelo LSTM obtenido (4 capas lstm, una fully conected y optimizador rmsprop), hay una mejora notable ya que el valor del error es menor y no hay sobreajuste en el modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
